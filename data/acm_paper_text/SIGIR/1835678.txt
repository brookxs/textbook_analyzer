Multimedia information retrieval
This tutorial is concerned with creating the best possible multimedia search experience. The intriguing bit here is that the query itself can be a multimedia excerpt: For example, when you walk around in an unknown place and stumble across an interesting landmark, would it not be great if you could just take a picture with your mobile phone and send it to a service that finds a similar picture in a database and tells you more about the building - and about its significance for that matter? The ideas for this type of search have been around for a decade, but this tutorial will look at recent successes and take stock of the state-of-the-art. It examines the full matrix of a variety of query modes versus document types. How do you retrieve a music piece by humming? What if you want to find news video clips on forest fires using a still image? The tutorial discusses underlying techniques and common approaches to facilitate multimedia search engines: metadata driven search; piggy-back text search where automated processes create text surrogates for multimedia; automated image annotation; content-based search. The latter is studied in more depth looking at features and distances, and how to effectively combine them for efficient retrieval, to a point where the participants have the ingredients and recipe in their hands for building their own visual search engines. Supporting users in their resource discovery mission when hunting for multimedia material is not a technological indexing problem alone. We will briefly look at interactive ways of engaging with repositories through browsing and relevance feedback, roping in geographical context, and providing visual summaries for videos. The tutorial emphasises state-of-the-art research in the area of multimedia information retrieval, which gives an indication of the research and development trends and, thereby, a glimpse of the future world.