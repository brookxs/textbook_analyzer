organizing the oca : learning faceted subjects from a library of digital-books large-scale library digitization projects such as the open-content alliance are producing vast quantities of text , but little has been done to organize this data . subject-headings inherited from card catalogs are useful but limited , while full-text-indexing is most appropriate for readers who already know exactly what they want . statistical-topic-models provide a complementary function . these models can identify semantically coherent `` topics '' that are easily recognizable and meaningful to humans , but they have been too computationally intensive to run on library-scale corpora . this paper presents dcm-lda , a topic-model based on dirichlet compound multinomial distributions . this model is simultaneously better able to represent observed properties of text and more scalable to extremely large text collections . we train individual topic-models for each book based on the cooccurrence of words within pages . we then cluster topics across books . the resulting topical clusters can be interpreted as subject facets , allowing readers to browse the topics of a collection quickly , find relevant books using topically expanded keyword searches , and explore topical relationships between books . we demonstrate this method finding topics on a corpus of 1.49 billion words from 42,000 books in less than 20 hours , and it easily could scale well beyond this .