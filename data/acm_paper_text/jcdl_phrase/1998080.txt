word-order matters : measuring topic coherence with lexical argument-structure topic-models are emerging tools for improved browsing and searching within digital-libraries . these techniques collapse words within documents into unordered `` bags of words , '' ignoring word-order . in this paper , we present a method that examines syntactic-dependency parse trees from wikipedia article titles to learn expected patterns between relative lexical-arguments . this process is highly dependent on the global word-ordering of a sentence , modeling how each word interacts with other words to gain an aggregate perspective on how words interact over all 3.2 million titles . using this information , we analyze how coherent a given topic is by comparing the relative usage vectors between the top 5 words in a topic . results suggest that this technique can identify poor topics based on how well the relative usages align with each other within a topic , potentially aiding digital-library indexing .