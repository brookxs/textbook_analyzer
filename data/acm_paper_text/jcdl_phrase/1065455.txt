what 's there and what 's not ? : focused-crawling for missing documents in digital-libraries some large-scale topical digital-libraries , such as citeseer , harvest online academic documents by crawling open-access archives , university and author homepages , and authors ' self-submissions . while these approaches have so far built reasonable size libraries , they can suffer from having only a portion of the documents from specific publishing venues . we propose to use alternative online-resources and techniques that maximally exploit other resources to build the complete document-collection of any given publication venue.we investigate the feasibility of using publication metadata to guide the crawler towards authors ' homepages to harvest what is missing from a-digital library collection . we collect a real-world dataset from two computer-science publishing venues , involving a total of 593 unique authors over a time frame of 1998 to 2004 . we then identify the missing papers that are not indexed by citeseer . using a fully automatic heuristic-based system that has the capability of locating authors ' homepages and then using focused-crawling to download the desired papers , we demonstrate that it is practical to harvest using a focused-crawler academic-papers that are missing from our digital-library . our harvester achieves a performance with an average recall level of 0.82 overall and 0.75 for those missing documents . evaluation of the crawler 's performance based on the harvest rate shows definite advantages over other crawling approaches and consistently outperforms a defined baseline crawler on a number of measures .