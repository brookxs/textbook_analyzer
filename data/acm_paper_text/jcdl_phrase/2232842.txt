generating ground-truth for music-mood-classification using mechanical-turk mood is an important access-point in music-digital-libraries and online-music repositories , but generating ground-truth for evaluating various music-mood-classification algorithms is a challenging problem . this is because collecting enough human-judgments is time-consuming and costly due to the subjectivity of music-mood . in this study , we explore the viability of crowdsourcing music-mood-classification judgments using amazon-mechanical-turk (mturk) . specifically , we compare the mood classification judgments collected for the annual music-information-retrieval-evaluation exchange (mirex) with judgments collected using mturk . our data show that the overall distribution of mood clusters and agreement rates from mirex and mturk were comparable . however , turkers tended to agree less with the pre-labeled mood clusters than mirex evaluators . the system-evaluation results generated using both sets of data were mostly the same except for detecting one statistically significant pair using friedman 's test . we conclude that mturk can potentially serve as a viable alternative for ground-truth collection , with some reservation with regards to particular mood clusters .