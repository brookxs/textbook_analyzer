text-categorization for multi-page-documents : a hybrid-naive-bayes hmm approach text-categorization is typically formulated as a concept-learning prob lem where each instance is a single isolated document . in this paper we are interested in a more general formulation where documents are organized as page sequences , as naturally occurring in digital-libraries of scanned-books and magazines . we describe a method for classifying pages of sequential ocr text documents into one of several assigned categories and suggest that taking into account contextual-information provided by the whole page sequence can significantly improve classification-accuracy . the proposed architecture relies on hidden-markov-models whose emissions are bag-of-words according to a multinomial word event-model , as in the generative portion of the naive-bayes-classifier . our results on a collection of scanned journals from the making of america project confirm the importance of using whole page sequences . empirical-evaluation indicates that the error-rate (as obtained by running a plain naive-bayes-classifier on isolated page) can be roughly reduced by half if contextual-information is incorporated .