user model-based metrics for offline query-suggestion evaluation query-suggestion or auto-completion mechanisms are widely used by search-engines and are increasingly attracting interest from the research-community . however , the lack of commonly accepted evaluation-methodology and metrics means that it is not possible to compare results and approaches from the literature . moreover , often the metrics used to evaluate query-suggestions tend to be an adaptation from other domains without a proper justification . hence , it is not necessarily clear if the improvements reported in the literature would result in an actual improvement in the users ' experience . inspired by the cascade user-models and state-of-the-art evaluation-metrics in the web-search domain , we address the query-suggestion evaluation , by first studying the users behaviour from a search-engine 's query-log and thereby deriving a new family of user-models describing the users interaction with a query-suggestion mechanism . next , assuming a query log-based evaluation-approach , we propose two new metrics to evaluate query-suggestions , psaved and esaved . both metrics are parameterised by a user-model . psaved is defined as the probability of using the query-suggestions while submitting a query . esaved equates to the expected relative amount of effort (keypresses) a user can avoid due to the deployed query-suggestion mechanism . finally , we experiment with both metrics using four user-model instantiations as well as metrics previously used in the literature on a dataset of 6.1 m sessions . our results demonstrate that psaved and esaved show the best alignment with the users-satisfaction amongst the considered metrics .