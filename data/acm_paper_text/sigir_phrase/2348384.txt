top-k learning-to-rank : labeling , ranking and evaluation in this paper , we propose a novel top-k learning-to-rank framework , which involves labeling strategy , ranking-model and evaluation-measure . the motivation comes from the difficulty in obtaining reliable relevance-judgments from human assessors when applying learning-to-rank in real search systems . the traditional absolute-relevance-judgment method is difficult in both gradation specification and human assessing , resulting in high level of disagreement on judgments . while the pairwise-preference judgment , as a good alternative , is often criticized for increasing the complexity of judgment from o (n) to (n log n) . considering the fact that users mainly care about top ranked search-results , we propose a novel top-k labeling strategy which adopts the pairwise-preference judgment to generate the top k ordering items from n documents (i.e. top-k ground-truth) in a manner similar to that of heapsort . as a result , the complexity of judgment is reduced to o (n log k) . with the top-k ground-truth , traditional ranking-models (e.g. pairwise or listwise models) and evaluation-measures (e.g. ndcg) no longer fit the data-set . therefore , we introduce a new ranking-model , namely focusedrank , which fully captures the characteristics of the top-k ground-truth . we also extend the widely used evaluation-measures ndcg and err to be applicable to the top-k ground-truth , referred as &#954; - ndcg and &#954; - err , respectively . finally , we conduct extensive experiments on benchmark data collections to demonstrate the efficiency-and-effectiveness of our top-k labeling strategy and ranking-models .