ranking-oriented nearest-neighbor_based method for automatic-image-annotation automatic-image-annotation plays a critical role in keyword-based image-retrieval-systems . recently , the nearest-neighbor_based scheme has been proposed and achieved good performance for image-annotation . given a new image , the scheme is to first find its most similar neighbors from labeled images , and then propagate the keywords associated with the neighbors to it . many studies focused on designing a suitable distance-metric between images so that all labeled images can be ranked by their distance to the given image . however , higher accuracy in distance prediction does not necessarily lead to better ordering of labeled images . in this paper , we propose a ranking-oriented neighbor-search mechanism to rank labeled images directly without going through the intermediate step of distance prediction . in particular , a new learning-to-rank algorithm is developed , which exploits the implicit preference information of labeled images and underlines the accuracy of the top-ranked results . experiments on two benchmark datasets demonstrate the effectiveness of our approach for image-annotation .