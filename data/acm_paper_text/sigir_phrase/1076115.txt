a markov-random-field-model for term dependencies this paper develops a general , formal-framework for modeling term dependencies via markov-random-fields . the model allows for arbitrary text-features to be incorporated as evidence . in particular , we make use of features based on occurrences of single terms , ordered phrases , and unordered phrases . we explore full independence , sequential dependence , and full dependence variants of the model . a novel approach is developed to train the model that directly maximizes the mean-average-precision rather than maximizing the likelihood of the training-data . ad-hoc-retrieval experiments are presented on several newswire and web collections , including the gov2 collection used at the trec 2004 terabyte track . the results show significant improvements are possible by modeling dependencies , especially on the larger web collections .