positional-language-models for information-retrieval although many variants of language-models have been proposed for information-retrieval , there are two related retrieval-heuristics remaining `` external '' to the language-modeling-approach : (1) proximity heuristic which rewards a document where the matched query terms occur close to each other ; (2) passage-retrieval which scores a document mainly based on the best matching passage . existing studies have only attempted to use a standard language-model as a `` black-box '' to implement these heuristics , making it hard to optimize the combination parameters . in this paper , we propose a novel positional-language-model (plm) which implements both heuristics in a unified language-model . the key idea is to define a language-model for each position of a document , and score a document based on the scores of its plms . the plm is estimated based on propagated counts of words within a document through a proximity-based density-function , which both captures proximity heuristics and achieves an effect of `` soft '' passage-retrieval . we propose and study several representative density-functions and several different plm-based document-ranking strategies . experiment results on standard trec test-collections show that the plm is effective for passage-retrieval and performs better than a state-of-the-art proximity-based retrieval-model .