combining eye-movements and collaborative-filtering for proactive-information-retrieval we study a new task , proactive-information-retrieval by combining implicit-relevance-feedback and collaborative-filtering . we have constructed a controlled experimental-setting , a prototype application , in which the users try to find interesting scientific articles by browsing their titles . implicit-feedback is inferred from eye-movement signals , with discriminative hidden-markov-models estimated from existing data in which explicit-relevance-feedback is available . collaborative-filtering is carried out using the user rating profile model , a state-of-the-art probabilistic latent variable model , computed using markov-chain-monte-carlo techniques . for new document titles the prediction-accuracy with eye-movements , collaborative-filtering , and their combination was significantly better than by chance . the best prediction-accuracy still leaves room for improvement but shows that proactive-information-retrieval and combination of many sources of relevance-feedback is feasible .