ocfs : optimal orthogonal centroid-feature selection for text-categorization text-categorization is an important research area in many information-retrieval (ir) applications . to save the storage space and computation-time in text-categorization , efficient and effective algorithms for reducing the data before analysis are highly desired . traditional techniques for this purpose can generally be classified into feature-extraction and feature-selection . because of efficiency , the latter is more suitable for text-data such as web-documents . however , many popular feature-selection techniques such as information-gain (ig) and ? 2 - test (chi) are all greedy in nature and thus may not be optimal according to some criterion . moreover , the performance of these greedy methods may be deteriorated when the reserved data dimension is extremely low . in this paper , we propose an efficient optimal feature-selection-algorithm by optimizing the objective-function of orthogonal centroid (oc) subspace-learning algorithm in a discrete solution-space , called orthogonal centroid-feature selection (ocfs) . experiments on 20 newsgroups (20ng) , reuters-corpus volume 1 (rcv1) and open-directory-project (odp) data show that ocfs is consistently better than ig and chi with smaller computation-time especially when the reduced dimension is extremely small .