directly optimizing evaluation-measures in learning-to-rank one of the central issues in learning-to-rank-for-information-retrieval is to develop algorithms that construct ranking-models by directly optimizing evaluation-measures used in information-retrieval such as mean-average-precision (map) and normalized-discounted-cumulative-gain (ndcg) . several such algorithms including svm map and adarank have been proposed and their effectiveness has been verified . however , the relationships between the algorithms are not clear , and furthermore no comparisons have been conducted between them . in this paper , we conduct a study on the approach of directly optimizing evaluation-measures in learning-to-rank-for-information-retrieval (ir) . we focus on the methods that minimize loss-functions upper bounding the basic loss-function defined on the ir-measures . we first provide a general-framework for the study and analyze the existing algorithms of svm map and adarank within the framework . the framework is based on upper-bound analysis and two types of upper-bounds are discussed . moreover , we show that we can derive new algorithms on the basis of this analysis and create one example algorithm called permurank . we have also conducted comparisons between svm map , adarank , permurank , and conventional methods of ranking-svm and rankboost , using benchmark datasets . experimental-results show that the methods based on direct-optimization of evaluation-measures can always outperform conventional methods of ranking-svm and rankboost . however , no significant difference exists among the performances of the direct-optimization methods themselves .