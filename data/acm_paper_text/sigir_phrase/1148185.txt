music-structure_based vector-space-retrieval this paper proposes a novel framework for music content indexing-and-retrieval . the music-structure information , i.e. , timing , harmony and music region content , is represented by the layers of the music-structure pyramid . we begin by extracting this layered structure-information . we analyze the rhythm of the music and then segment the signal proportional to the inter-beat intervals . thus , the timing information is incorporated in the segmentation-process , which we call beat-space-segmentation . to describe harmony events , we propose a two-layer hierarchical-approach to model the music chords . we also model the progression of instrumental and vocal content as acoustic events . after information-extraction , we propose a vector-space-modeling approach which uses these events as the indexing terms . in query-by-example music-retrieval , a query is represented by a vector of the statistics of the n - gram events . we then propose two effective retrieval-models , a hard-indexing scheme and a soft-indexing scheme . experiments show that the vector-space-modeling is effective in representing the layered music-information , achieving 82.5 \ % top-5 retrieval-accuracy using 15-sec music clips as the queries . the soft-indexing outperforms hard-indexing in general .