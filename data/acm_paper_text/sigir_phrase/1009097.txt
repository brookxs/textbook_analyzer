aggregated feature-retrieval for mpeg-7 via clustering in this paper , we describe an approach to combining text and visual-features from mpeg-7 descriptions of video . a video-retrieval process is aligned to a text-retrieval process based on the tf * idf vector-space-model via clustering of low-level visual features . our assumption is that shots within the same cluster are not only similar visually but also semantically , to a certain extent . our experiments on the trecvid2002 and trecvid2003 collections show that adding extra meaning to a shot based on the shots from the same cluster is useful when each video in a collection contains a high proportion of similar shots , for example in documentaries .