evaluating evaluation-metrics based on the bootstrap this paper describes how the bootstrap approach to statistics can be applied to the evaluation of ir effectiveness metrics . first , we argue that bootstrap hypothesis-tests deserve more attention from the ir community , as they are based on fewer assumptions than traditional statistical significance-tests . we then describe straightforward methods for comparing the sensitivity of ir-metrics based on bootstrap hypothesis-tests . unlike the heuristics-based `` swap '' method proposed by voorhees and buckley , our method estimates the performance difference required to achieve a given significance-level directly from bootstrap hypothesis-test results . in addition , we describe a simple way of examining the accuracy of rank-correlation between two metrics based on the bootstrap estimate of standard-error . we demonstrate the usefulness of our methods using test-collections and runs from the ntcir clir track for comparing seven ir-metrics , including those that can handle graded-relevance and those based on the geometric-mean .