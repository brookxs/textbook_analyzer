the influence of basic tokenization on biomedical-document-retrieval tokenization is a fundamental preprocessing step in information-retrieval-systems in which text is turned into index-terms . this paper quantifies and compares the influence of various simple tokenization techniques on document-retrieval effectiveness in two domains : biomedicine and news . as expected , biomedical-retrieval is more sensitive to small changes in the tokenization method . the tokenization strategy can make the difference between a mediocre and well performing ir-system , especially in the biomedical-domain .