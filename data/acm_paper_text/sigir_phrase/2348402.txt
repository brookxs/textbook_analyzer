on per-topic variance in ir-evaluation we explore the notion , put forward by cormack &#38; lynam and robertson , that we should consider a document-collection used for cranfield-style experiments as a sample from some larger population of documents . in this view , any per-topic metric (such as average-precision) should be regarded as an estimate of that metric 's true value for that topic in the full population , and therefore as carrying its own per-topic variance or estimate precision or noise . as in the two mentioned papers , we explore this notion by simulating other samples from the same large population . we investigate different ways of performing this simulation . one use of this analysis is to refine the notion of statistical-significance of a difference between two systems (in most such analyses , each per-topic measurement is treated as equally precise) . we propose a mixed-effects model method to measure significance , and compare it experimentally with the traditional t-test .