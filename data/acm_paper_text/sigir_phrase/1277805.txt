test-theory for assessing ir test collections how good is an ir test collection ? a series of papers in recent years has addressed the question by empirically enumerating the consistency of performance comparisons using alternate subsets of the collection . in this paper we propose using test-theory , which is based on analysis-of-variance and is specifically designed to assess test-collections . using the method , we not only can measure test reliability after the fact , but we can estimate the test-collection 's reliability before it is even built or used . we can also determine an optimal-allocation of resources before the fact , e.g. whether to invest in more judges or queries . the method , which is in widespread use in the field of educational testing , complements data-driven-approaches to assessing test-collections . whereas the data-driven method focuses on test results , test-theory focuses on test designs . it offers unique practical results , as well as insights about the variety and implications of alternative test designs .