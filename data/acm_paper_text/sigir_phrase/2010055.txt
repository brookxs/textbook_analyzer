evaluating diversified search-results using per-intent graded-relevance search queries are often ambiguous and/or underspecified . to accomodate different user-needs , search-result-diversification has received attention in the past few years . accordingly , several new metrics for evaluating diversification have been proposed , but their properties are little understood . we compare the properties of existing metrics given the premises that (1) queries may have multiple-intents ; (2) the likelihood of each intent given a query is available ; and (3) graded-relevance assessments are available for each intent . we compare a wide range of traditional and diversified ir-metrics after adding graded-relevance assessments to the trec 2009 web track diversity task test-collection which originally had binary relevance-assessments . our primary criterion is discriminative power , which represents the reliability of a metric in an experiment . our results show that diversified ir experiments with a given number of topics can be as reliable as traditional ir experiments with the same number of topics , provided that the right metrics are used . moreover , we compare the intuitiveness of diversified ir-metrics by closely examining the actual ranked-lists from trec . we show that a family of metrics called d # - measures have several advantages over other metrics such as ? - ndcg and intent-aware metrics .