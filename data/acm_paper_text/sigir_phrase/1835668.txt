visual concept-based selection of query expansions for spoken-content-retrieval in this paper we present a novel approach to semantic-theme-based-video-retrieval that considers entire videos as retrieval units and exploits automatically detected visual-concepts to improve the results of retrieval based on spoken-content . we deploy a query-prediction method that makes use of a coherence indicator calculated on top returned documents and taking into account the information about visual-concepts presence in videos to make a choice between query-expansion methods . the main contribution of our approach is in its ability to exploit noisy shot-level concept-detection to improve semantic-theme-based-video-retrieval . strikingly , improvement is possible using an extremely limited set of concepts . in the experiments performed on trecvid-2007 and 2008 datasets our approach shows an interesting performance-improvement compared to the best performing baseline .