alternatives to bpref recently , a number of trec tracks have adopted a retrieval-effectiveness metric called bpref which has been designed for evaluation environments with incomplete relevance data . a graded-relevance version of this metric called rpref has also been proposed . however , we show that the application of q-measure , normalised-discounted-cumulative-gain (ndcg) or average-precision (avep) to condensed lists , obtained by ? ltering out all unjudged documents from the original ranked-lists , is actually a better solution to the incompleteness problem than bpref . furthermore , we show that the use of graded-relevance boosts the robustness of ir-evaluation to incompleteness and therefore that q-measure and ndcg based on condensed lists are the best choices . to this end , we use four graded-relevance test-collections from ntcir to compare ten different ir-metrics in terms of system ranking stability and pairwise discriminative power .