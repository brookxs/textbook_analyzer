effective music tagging through advanced statistical-modeling music-information-retrieval (mir) holds great promise as a technology for managing large music archives . one of the key components of mir that has been actively researched into is music tagging . while significant progress has been achieved , most of the existing systems still adopt a simple classification-approach , and apply machine-learning-classifiers directly on low level acoustic features . consequently , they suffer the shortcomings of (1) poor accuracy , (2) lack of comprehensive evaluation results and the associated analysis based on large-scale datasets , and (3) incomplete content-representation , arising from the lack of multimodal and temporal-information integration . in this paper , we introduce a novel system called mmtagger that effectively integrates both multimodal and temporal-information in the representation of music signal . the carefully designed multilayer architecture of the proposed classification framework seamlessly combines multiple gaussian-mixture-models (gmms) and support-vector-machine (svm) into a single framework . the structure preserves more discriminative information , leading to more accurate and robust tagging . experiment results obtained with two large music collections highlight the various advantages of our multilayer framework over state-of-the-art techniques .