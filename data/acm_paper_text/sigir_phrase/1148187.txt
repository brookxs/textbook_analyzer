aggregaterank : bringing order to web-sites since the website is one of the most important organizational-structures of the-web , how to effectively rank websites has been essential to many web-applications , such as web-search and crawling . in order to get the ranks of websites , researchers used to describe the inter-connectivity among websites with a so-called hostgraph in which the nodes denote websites and the edges denote linkages between websites (if-and-only-if there are hyperlinks from the pages in one website to the pages in the other , there will be an edge between these two websites) , and then adopted the random-walk-model in the hostgraph . however , as pointed in this paper , the random-walk over such a hostgraph is not reasonable because it is not in accordance with the browsing-behavior of web surfers . therefore , the derivate rank can not represent the true probability of visiting the corresponding website.in this work , we mathematically proved that the probability of visiting a website by the random web surfer should be equal to the sum of the pagerank values of the pages inside that website . nevertheless , since the number of web-pages is much larger than that of websites , it is not feasible to base the calculation of the ranks of websites on the calculation of pagerank . to tackle this problem , we proposed a novel method named aggregaterank rooted in the theory of stochastic complement , which can not only approximate the sum of pagerank accurately , but also have a lower computational-complexity than pagerank . both theoretical-analysis and experimental-evaluation show that aggregaterank is a better method for ranking websites than previous methods .