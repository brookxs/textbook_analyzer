multi-platform image-search using tag-enrichment the number of images available online is growing steadily and current web search-engines have indexed more than 10 billion images . approaches to image-retrieval are still often text-based and operate on image annotations and captions . image annotations (i.e. image-tags) are typically short , user-generated , and of varying quality , which increases the mismatch problem between query terms and image-tags . for example , a user might enter the query `` wedding dress '' while all images are annotated with `` bridal gown '' or `` wedding gown '' . this demonstration presents an image-search system using reduction and expansion of image annotations to overcome vocabulary mismatch problems by enriching the sparse set of image-tags . our image-search application accepts a written query as input and produces a ranked list of result images and annotations (i.e. image-tags) as output . the system integrates methods to reduce and expand the image tag set , thus decreasing the effect of sparse image tags . it builds on different image-collections such as the wikipedia image-collection (http://www.imageclef.org/wikidata) and the microsoft office.com clipart collection (http://office.microsoft.com/) , but can be applied to social collections such as flickr as well . our demonstration system runs on pcs , tablets , and smartphones , making use of advanced-user-interface capabilities on mobile-devices .