incorporating statistical topic information in relevance-feedback most of the relevance-feedback algorithms only use document terms as feedback (local-features) in order to update the query and re-rank the documents to show to the user . this approach is limited by the terms of those documents without any global context . we propose to use statistical topic modeling-techniques in relevance-feedback to incorporate a better estimate of context by including global information about the document . this is particularly helpful for difficult-queries where learning the context from the interactions with the user is crucial . we propose to use the topic mixture information obtained to characterize the documents and learn their topics . then , we rank documents incorporating positive and negative feedback by fitting a latent distribution for each class of documents online and combining all the features using bayesian-logistic-regression . we show results using the ohsumed-dataset for 3 different variants and obtain higher performance , up to 12.5 % in mean-average-precision (map) .