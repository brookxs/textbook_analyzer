cache-conscious performance-optimization for similarity-search all-pairs similarity-search can be implemented in two stages . the first stage is to partition the data and group potentially similar vectors . the second stage is to run a set of tasks where each task compares a partition of vectors with other candidate partitions . because of data-sparsity , accessing feature-vectors in memory for runtime comparison in the second stage , incurs significant overhead due to the presence of memory-hierarchy . this paper proposes a cache-conscious data layout and traversal optimization to reduce the execution-time through size-controlled data splitting and vector coalescing . it also provides an analysis to guide the optimal choice for the parameter-setting . our evaluation with several application datasets verifies the performance gains obtained by the optimization and shows that the proposed scheme is upto 2.74 x as fast as the cache-oblivious baseline .