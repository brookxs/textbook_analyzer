optimizing top-n collaborative-filtering via dynamic negative item sampling collaborative-filtering techniques rely on aggregated user-preference data to make personalized predictions . in many cases , users are reluctant to explicitly express their preferences and many recommender-systems have to infer them from implicit user behaviors , such as clicking a link in a webpage or playing a music track . the clicks and the plays are good for indicating the items a user liked (i.e. , positive training-examples) , but the items a user did not like (negative training-examples) are not directly observed . previous approaches either randomly pick negative training-samples from unseen items or incorporate some heuristics into the learning-model , leading to a biased solution and a prolonged training period . in this paper , we propose to dynamically choose negative training-samples from the ranked list produced by the current prediction-model and iteratively update our model . the experiments conducted on three large-scale-datasets show that our approach not only reduces the training-time , but also leads to significant performance gains .