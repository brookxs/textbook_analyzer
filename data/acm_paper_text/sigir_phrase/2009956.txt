efficiently collecting relevance information from clickthroughs for web-retrieval system-evaluation various click-models have been recently proposed as a principled approach to infer the relevance of documents from the clickthrough-data . the inferred document-relevance is potentially useful in evaluating the-web retrieval-systems . in practice , it generally requires to acquire the accurate evaluation results within minimal users ' query submissions . this problem is important for speeding up search-engine development and evaluation-cycle and acquiring reliable evaluation results on tail-queries . in this paper , we propose a reordering framework for efficient evaluation problem in the context of clickthrough based web-retrieval evaluation . the main idea is to move up the documents that contribute more for the evaluation-task . in this framework , we propose four intuitions and formulate them as an optimization-problem . both user-study and trec-data_based experiments validate that the reordering framework results in much fewer query submissions to get accurate evaluation results with only a little harm to the users ' utility .