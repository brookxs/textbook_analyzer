summaries , ranked-retrieval and sessions : a unified-framework for information-access evaluation we introduce a general information-access evaluation-framework that can potentially handle summaries , ranked document lists and even multi query sessions seamlessly . our framework first builds a trailtext which represents a concatenation of all the texts read by the user during a search-session , and then computes an evaluation-metric called u-measure over the trailtext . instead of discounting the value of a retrieved piece of information based on ranks , u-measure discounts it based on its position within the trailtext . u-measure takes the document length into account just like time-biased gain (tbg) , and has the diminishing return property . it is therefore more realistic than rank-based metrics . furthermore , it is arguably more flexible than tbg , as it is free from the linear traversal assumption (i.e. , that the user scans the ranked list from top to bottom) , and can handle information-access tasks other than ad-hoc-retrieval . this paper demonstrates the validity and versatility of the u-measure framework . our main conclusions are : (a) for ad-hoc-retrieval , u-measure is at least as reliable as tbg in terms of rank correlations with traditional metrics and discriminative power ; (b) for diversified search , our diversity versions of u-measure are highly correlated with state-of-the-art diversity-metrics ; (c) for multi-query sessions , u-measure is highly correlated with session ndcg ; and (d) unlike rank-based metrics such as dcg , u-measure can quantify the differences between linear and nonlinear traversals in sessions . we argue that our new framework is useful for understanding-the-user 's search-behaviour and for comparison across different information-access styles (e.g. examining a direct answer vs. examining a ranked list of web-pages) .