do summaries help ? we describe a task-based-evaluation to determine whether multi-document summaries measurably improve user-performance whe using online-news browsing systems for directed research . we evaluated the multi-document summaries generated by newsblaster , a robust news-browsing system that clusters online-news articles and summarizes multiple articles on each event . four groups of subjects were asked to perform the same time-restricted fact-gathering tasks , reading news under different conditions : no summaries at all , single sentence summaries drawn from one of the articles , newsblaster multi-document summaries , and human summaries . our results show that , in comparison to source-documents only , the quality of reports assembled using newsblaster summaries was significantly better and user-satisfaction was higher with both newsblaster and human summaries .