self reinforcement for important passage-retrieval in general , centrality-based retrieval-models treat all elements of the retrieval space equally , which may reduce their effectiveness . in the specific context of extractive-summarization (or important passage-retrieval) , this means that these models do not take into account that information-sources often contain lateral issues , which are hardly as important as the description of the main topic , or are composed by mixtures of topics . we present a new two-stage method that starts by extracting a collection of key-phrases that will be used to help centrality-as-relevance retrieval-model . we explore several approaches to the integration of the key-phrases in the centrality model . the proposed method is evaluated using different datasets that vary in noise (noisy vs clean) and language (portuguese vs english) . results show that the best variant achieves relative-performance improvements of about 31 % in clean data and 18 % in noisy-data .