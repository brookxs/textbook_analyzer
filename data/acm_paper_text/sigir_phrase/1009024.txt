dependence language-model for information-retrieval this paper presents a new dependence language-modeling-approach to information-retrieval . the approach extends the basic language-modeling-approach based on unigram by relaxing the independence-assumption . we integrate the linkage of a query as a hidden-variable , which expresses the term dependencies within the query as an acyclic , planar , undirected-graph . we then assume that a query is generated from a document in two stages : the linkage is generated first , and then each term is generated in turn depending on other related terms according to the linkage . we also present a smoothing-method for model-parameter-estimation and an approach to learning the linkage of a sentence in an unsupervised manner . the new approach is compared to the classical probabilistic-retrieval-model and the previously proposed language-models with and without taking into account term dependencies . results show that our model achieves substantial and significant improvements on trec collections .