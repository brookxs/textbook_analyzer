reorganizing compressed text recent research has demonstrated beyond doubts the benefits of compressing natural-language-texts using word-based statistical semistatic compression . not only it achieves extremely competitive compression rates , but also direct-search on the compressed text can be carried out faster than on the original text ; indexing based on inverted-lists benefits from compression as well . such compression methods assign a variable-length codeword to each different text word . some coding methods (plain huffman and restricted prefix byte codes) do not clearly mark codeword boundaries , and hence can not be accessed at random positions nor searched with the fastest text-search algorithms . other coding methods (tagged huffman , end-tagged dense code , or (s , c) - dense code) do mark codeword boundaries , achieving a self-synchronization property that enables fast-search and random-access , in exchange for some loss in compression effectiveness . in this paper , we show that by just performing a simple reordering of the target symbols in the compressed text (more precisely , reorganizing the bytes into a wavelet-treelike shape) and using little additional space , searching capabilities are greatly improved without a drastic impact in compression and decompression times . with this approach , all the codes achieve synchronism and can be searched fast and accessed at arbitrary points . moreover , the reordered compressed text becomes an implicitly indexed representation of the text , which can be searched for words in time independent of the text-length . that is , we achieve not only fast sequential search-time , but indexed search-time , for almost no extra space cost . we experiment with three well-known word-based-compression techniques with different characteristics (plain huffman , end-tagged dense code and restricted prefix byte codes) , and show the searching capabilities achieved by reordering the compressed representation on several corpora . we show that the reordered versions are not only much more efficient than their classical counterparts , but also more efficient than explicit inverted-indexes built on the collection , when using the same amount of space .