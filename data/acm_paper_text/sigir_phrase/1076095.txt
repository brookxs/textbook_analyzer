using term informativeness for named-entity-detection informal-communication (e-mail , bulletin-boards) poses a difficult learning-environment because traditional grammatical and lexical-information are noisy . other information is necessary for tasks such as named-entity-detection . how topic-centric , or informative , a word is can be valuable information . it is well known that informative words are best modeled by `` heavy-tailed '' distributions , such as mixture-models . however , informativeness scores do not take full advantage of this fact . we introduce a new informativeness score that directly utilizes mixture-model likelihood to identify informative words . we use the task of extracting restaurant names from bulletin-board posts as a way to determine effectiveness . we find that our `` mixture score '' is weakly effective alone and highly effective when combined with inverse-document-frequency . we compare against other informativeness criteria and find that only residual idf is competitive against our combined idf/mixture score .