estimating probabilities for effective data fusion data-fusion is the combination of a number of independent search-results , relating to the same document-collection , into a single result to be presented to the user . a number of probabilistic-data-fusion models have been shown to be effective in empirical-studies . these typically attempt to estimate the probability that particular documents will be relevant , based on training-data . however , little attempt has been made to gauge how the accuracy of these estimations affect fusion performance . the focus of this paper is twofold : firstly , that accurate estimation of the probability of relevance results in effective data fusion ; and secondly , that an effective approximation of this probability can be made based on less training-data that has previously been employed . this is based on the observation that the distribution-of-relevant-documents follows a similar pattern in most high-quality result sets . curve-fitting suggests that this can be modelled by a simple function that is less complex than other models that have been proposed . the use of existing ir-evaluation metrics is proposed as a substitution for probability calculations . mean-average-precision is used to demonstrate the effectiveness of this approach , with evaluation results demonstrating competitive performance when compared with related algorithms with more onerous requirements for training-data .