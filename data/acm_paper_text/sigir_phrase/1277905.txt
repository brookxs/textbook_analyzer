resource-monitoring in information-extraction it is often argued that in information-extraction (ie) , certain machine-learning (ml) approaches save development time over others , or that certain ml methods (e.g. active-learning) require less training-data than others , thus saving development cost . however , such development cost claims are not normally backed up by controlled studies which show that such development cost-savings actually occur . this situation in language-engineering is contrasted with software-engineering in general , where a lot of studies investigating system-development cost have been carried out . we argue for the need of controlled studies that measure actual system-development time in language-engineering . to this end , we carry out an experiment in resource-monitoring for an ie-task : three named-entity taggers for the same `` surprise '' domain are developed in parallel , using competing methods . their human development time is accounted forusing a logging facility.we report development cost results for parallel-implementations of a named-entity-tagger and present a breakdown of the development time for the three alternative methods . we are not aware of detailed previous parallel studies that detail how system-development time is spent when creating a named-entity-tagger .