web derived pronunciations for spoken-term-detection indexing-and-retrieval of speech content in various forms such as broadcast-news , customer-care data and on-line media has gained a lot of interest for a wide range of applications , from customer analytics to on-line media-search . for most retrieval applications , the speech content is typically first converted to a lexical or phonetic-representation using automatic-speech-recognition (asr) . the first step in searching through indexes built on these representations is the generation of pronunciations for named-entities and foreign-language query terms . this paper summarizes the results of the work conducted during the 2008 jhu summer workshop by the multilingual spoken-term-detection team , on mining the-web for pronunciations and analyzing their impact on spoken-term-detection . we will first present methods to use the vast amount of pronunciation information available on the web , in the form of ipa and ad-hoc transcriptions . we describe techniques for extracting candidate pronunciations from web-pages and associating them with orthographic words , filtering out poorly extracted pronunciations , normalizing ipa pronunciations to better conform to a common transcription-standard , and generating phonemic representations from ad-hoc transcriptions . we then present an analysis of the effectiveness of using these pronunciations to represent out-of-vocabulary (oov) query terms on the performance of a spoken-term-detection (std) system . we will provide comparisons of web pronunciations against automated techniques for pronunciation generation as well as pronunciations generated by human experts . our results cover a range of speech indexes based on lattices , confusion-networks and one-best transcriptions at both word and word-fragments levels .