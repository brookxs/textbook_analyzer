multimedia-information-retrieval this tutorial is concerned with creating the best possible multimedia-search experience . the intriguing bit here is that the query itself can be a multimedia excerpt : for example , when you walk around in an unknown place and stumble across an interesting landmark , would it not be great if you could just take a picture with your mobile-phone and send it to a service that finds a similar picture in a database and tells you more about the building - and about its significance for that matter ? the ideas for this type of search have been around for a decade , but this tutorial will look at recent successes and take stock of the state-of-the-art . it examines the full matrix of a variety of query-modes versus document types . how do you retrieve a music piece by humming ? what if you want to find news-video clips on forest-fires using a still-image ? the tutorial discusses underlying techniques and common approaches to facilitate multimedia-search engines : metadata-driven-search ; piggy-back-text-search where automated processes create text surrogates for multimedia ; automated-image-annotation ; content-based-search . the latter is studied in more depth looking at features and distances , and how to effectively combine them for efficient retrieval , to a point where the participants have the ingredients and recipe in their hands for building their own visual-search engines . supporting users in their resource-discovery mission when hunting for multimedia material is not a technological indexing problem alone . we will briefly look at interactive ways of engaging with repositories through browsing-and-relevance-feedback , roping in geographical context , and providing visual summaries for videos . the tutorial emphasises state-of-the-art research in the area of multimedia-information-retrieval , which gives an indication of the research-and-development trends and , thereby , a glimpse of the-future world .