text-classification with kernels on the multinomial manifold support-vector-machines (svms) have been very successful in text-classification . however , the intrinsic geometric-structure of text-data has been ignored by standard kernels commonly used in svms . it is natural to assume that the documents are on the multinomial manifold , which is the simplex of multinomial models furnished with the riemannian-structure induced by the fisher-information metric . we prove that the negative geodesic-distance (ngd) on the multinomial manifold is conditionally positive definite (cpd) , thus can be used as a kernel in svms . experiments show the ngd kernel on the multinomial manifold to be effective for text-classification , significantly outperforming standard kernels on the ambient euclidean-space .