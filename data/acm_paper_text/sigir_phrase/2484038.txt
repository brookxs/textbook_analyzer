on the measurement of test-collection reliability the reliability of a test-collection is proportional to the number of queries it contains . but building a collection with many queries is expensive , so researchers have to find a balance between reliability and cost . previous work on the measurement of test-collection reliability relied on data-based approaches that contemplated random what if scenarios , and provided indicators such as swap rates and kendall tau correlations . generalizability-theory was proposed as an alternative founded on analysis-of-variance that provides reliability-indicators based on statistical-theory . however , these reliability-indicators are hard to interpret in practice , because they do not correspond to well known indicators like kendall tau correlation . we empirically established these relationships based on data from over 40 trec collections , thus filling the gap in the practical interpretation of generalizability-theory . we also review the computation of these indicators , and show that they are extremely dependent on the sample of systems and queries used , so much that the required number of queries to achieve a certain level of reliability can vary in orders of magnitude . we discuss the computation of confidence-intervals for these statistics , providing a much more reliable tool to measure test-collection reliability . reflecting upon all these results , we review a wealth of trec test-collections , arguing that they are possibly not as reliable as generally accepted and that the common choice of 50 queries is insufficient even for stable rankings .