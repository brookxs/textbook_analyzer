exploring the limits of single-iteration clarification dialogs single-iteration clarification dialogs , as implemented in the trec-hard track , represent an attempt to introduce interaction into ad-hoc-retrieval , while preserving the many benefits of large-scale evaluations . although previous experiments have not conclusively demonstrated performance gains resulting from such interactions , it is unclear whether these findings speak to the nature of clarification dialogs , or simply the limitations of current systems . to probe the limits of such interactions , we employed a human intermediary to formulate clarification questions and exploit user responses . in addition to establishing a plausible upper-bound on performance , we were also able to induce an `` ontology of clarifications '' to characterize human-behavior . this ontology , in turn , serves as the input to a regression-model that attempts to determine which types of clarification questions are most helpful . our work can serve to inform the design of interactive-systems that initiate user dialogs .