effective sentiment stream analysis with self-augmenting training and demand-driven projection how do we analyze sentiments over a set of opinionated twitter-messages ? this issue has been widely studied in recent years , with a prominent approach being based on the application of classification-techniques . basically , messages are classified according to the implicit attitude of the writer with respect to a query-term . a major concern , however , is that twitter (and other media-channels) follows the data-stream model , and thus the classifier must operate with limited-resources , including labeled-data for training classification-models . this imposes serious challenges for current classification-techniques , since they need to be constantly fed with fresh training messages , in order to track sentiment-drift and to provide up-to-date sentiment-analysis . we propose solutions to this problem . the heart of our approach is a training augmentation procedure which takes as input a small training seed , and then it automatically incorporates new relevant messages to the training-data . classification-models are produced on-the-fly using association-rules , which are kept up-to-date in an incremental fashion , so that at any given time the model properly reflects the sentiments in the event being analyzed . in order to track sentiment-drift , training messages are projected on a demand driven basis , according to the content of the message being classified . projecting the training-data offers a series of advantages , including the ability to quickly detect trending information emerging in the stream . we performed the analysis of major events in 2010 , and we show that the prediction-performance remains about the same , or even increases , as the stream passes and new training messages are acquired . this result holds for different languages , even in cases where sentiment distribution changes over time , or in cases where the initial training seed is rather small . we derive lower-bounds for prediction-performance , and we show that our approach is extremely effective under diverse learning-scenarios , providing gains that range from 7 \ % to 58 \ % .