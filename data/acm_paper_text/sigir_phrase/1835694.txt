reverse annotation_based retrieval from large document image-collections a number of projects are dedicated to creating digital-libraries from scanned-books , such as google-books , udl , digital-library of india (dli) , etc. . the ability to search in the content of document-images is essential for the usability and popularity of these dls . in this work , we aim toward building a retrieval-system over 120k document-images coming from 1000 scanned-books of telugu literature . this is a challenge because : i) ocrs are not robust enough for indian-languages , especially the telugu script , ii) the document images contain large number of degradations and artifacts , iii) scalability to large-collections is hard . moreover , users expect that the search-system accept text queries and retrieve relevant results in interactive times . we propose a reverse annotation-framework [1] , that labels word-images by their equivalent text label in the offline phase . reverse annotation applies a retrieval_based approach to recognition . unlike traditional annotation/recognition that identifies keywords for data , reverse annotation identifies data that corresponds to a given keyword . it first selects a set of keywords which are considered useful for labeling and retrieval , such as those that repeat often , and ignoring stopwords and rare-words . exemplars are obtained for each word from a crude ocr or human annotations . the labels are then propagated across the rest of the collection by matching words in the image-feature space . since such a matching is computationally expensive , scalability is achieved using a fast approximate nearest-neighbor technique based on hierarchical k-means . once text labels are assigned , each document-image is considered a bag-of-words over the labeled keywords . a standard search-engine is used to build a search-index for quick online retrieval . an example query and the retrieved results are shown in figure 1 . we are unaware of any conventional ocrs which can retrieve such images for the given query . there are three major contributions of our work : i) recognizing the entire document-collection together , instead of one-at-a-time ; this means that the repetition of words in the test-set is effectively used for improving accuracy , ii) speeding up recognition by clustering multiple instances of a given word , iii) recognising at the word-level , avoiding the pitfalls of character-segmentation and recognition . other ocr techniques that use word-level context still rely on inaccurate component-level classification . using the techniques developed from this work , we were able to successfully build a retrieval-system over our challenging dataset . to the best of our knowledge , this is the largest collection of document-images that has been made searchable for any indian-language . our algorithm is easily scalable to larger collections , and directly applicable to documents from other language scripts . the first issue to discuss , is the fraction of word-images that remain unrecognized at the end of the reverse annotation phase . rare-words , nouns etc. are not labeled in the test-set . it is important to estimate the cost of not being able to answer such queries . if this cost is indeed high , we need to explore methods to label such infrequently occurring words in the collection . needless to say , such methods should be computationally efficient without compromising on accuracy . the other major issue to discuss is the evaluation of retrieval results . the true recall of the retrieval-system can not be computed , since it is impossible to identify every occurrence of the given query in such large-data . questions to be considered include : whether precision alone is a sufficient indicator of retrieval-performance ; whether there is some better document-level effectiveness assessment possible ; and how best to estimate the relative satisfaction of the user 's information-need .