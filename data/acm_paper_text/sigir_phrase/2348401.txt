an ir-based evaluation-framework for web-search query-segmentation this paper presents the first evaluation-framework for web-search query-segmentation based directly on ir performance . in the past , segmentation strategies were mainly validated against manual annotations . our work shows that the goodness of a segmentation-algorithm as judged through evaluation against a handful of human annotated segmentations hardly reflects its effectiveness in an ir-based setup . in fact , state-of the-art algorithms are shown to perform as good as , and sometimes even better than human annotations a fact masked by previous validations . the proposed framework also provides us an objective understanding of the gap between the present best and the best possible segmentation-algorithm . we draw these conclusions based on an extensive evaluation of six segmentation strategies , including three most recent algorithms , vis-a-vis segmentations from three human-annotators . the evaluation-framework also gives insights about which segments should be necessarily detected by an algorithm for achieving the best retrieval results . the meticulously constructed dataset used in our experiments has been made public for use by the research-community .