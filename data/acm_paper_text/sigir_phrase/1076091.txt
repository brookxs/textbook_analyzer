learning to extract information from semi-structured text using a discriminative context-free-grammar in recent work , conditional markov chain models (cmm) have been used to extract information from semi-structured text (one example is the conditional-random-field [10]) . applications range from finding the author and title in research papers to finding the phone-number and street address in a web-page . the cmm framework combines a priori knowledge encoded as features with a set of labeled-training-data to learn an efficient extraction-process . we will show that similar problems can be solved more effectively by learning a discriminative context-free-grammar from training-data . the grammar has several distinct advantages : long range , even global , constraints can be used to disambiguate entity labels ; training-data is used more efficiently ; and a set of new more powerful features can be introduced . the grammar_based approach also results in semantic-information (encoded in the form of a parse-tree) which could be used for ir applications like question-answering . the specific problem we consider is of extracting personal contact , or address , information from unstructured sources such as documents and emails . while linear-chain cmms perform reasonably well on this task , we show that a statistical parsing-approach results in a 50 \ % reduction in error-rate . this system also has the advantage of being interactive , similar to the system described in [9] . in cases where there are multiple errors , a single user correction can be propagated to correct multiple errors automatically . using a discriminatively trained grammar , 93.71 \ % of all tokens are labeled correctly (compared to 88.43 \ % for a cmm) and 72.87 \ % of records have all tokens labeled correctly (compared to 45.29 \ % for the cmm) .