a study of methods for negative-relevance-feedback negative-relevance-feedback is a special case of relevance-feedback where we do not have any positive example ; this often happens when the topic is difficult and the search-results are poor . although in principle any standard relevance-feedback technique can be applied to negative-relevance-feedback , it may not perform well due to the lack of positive examples . in this paper , we conduct a systematic study of methods for negative-relevance-feedback . we compare a set of representative negative-feedback methods , covering vector-space models and language-models , as well as several special heuristics for negative-feedback . evaluating negative-feedback methods requires a test-set with sufficient difficult-topics , but there are not many naturally difficult-topics in the existing test-collections . we use two sampling strategies to adapt a test-collection with easy topics to evaluate negative-feedback . experiment results on several trec collections show that language-model_based negative-feedback methods are generally more effective than those based on vector-space models , and using multiple negative models is an effective heuristic for negative-feedback . our results also show that it is feasible to adapt test-collections with easy topics for evaluating negative-feedback methods through sampling .