click model-based information-retrieval metrics in recent years many models have been proposed that are aimed at predicting clicks of web-search users . in addition , some information-retrieval-evaluation metrics have been built on top of a user-model . in this paper we bring these two directions together and propose a common approach to converting any click-model into an evaluation-metric . we then put the resulting model-based metrics as well as traditional metrics (like dcg or precision) into a common evaluation-framework and compare them along a number of dimensions . one of the dimensions we are particularly interested in is the agreement between offline and online experimental outcomes . it is widely believed , especially in an industrial setting , that online a/b-testing and interleaving experiments are generally better at capturing system-quality than offline measurements . we show that offline metrics that are based on click-models are more strongly correlated with online experimental outcomes than traditional offline metrics , especially in situations when we have incomplete relevance-judgements .