the impact of crawl policy on web-search-effectiveness crawl selection policy has a direct influence on web-search-effectiveness , because a useful page that is not selected for crawling will also be absent from search-results . yet there has been little or no work on measuring this effect . we introduce an evaluation-framework , based on relevance-judgments pooled from multiple search-engines , measuring the maximum potential ndcg that is achievable using a particular crawl . this allows us to evaluate different crawl policies and investigate important scenarios like selection stability over multiple iterations . we conduct two sets of crawling experiments at the scale of 1 ~ billion and 100 ~ million pages respectively . these show that crawl selection based on pagerank , indegree and trans-domain indegree all allow better retrieval-effectiveness than a simple breadth-first crawl of the same size . pagerank is the most reliable and effective method . trans-domain indegree can outperform pagerank , but over multiple crawl iterations it is less effective and more unstable . finally we experiment with combinations of crawl selection-methods and per-domain page limits , which yield crawls with greater potential ndcg than pagerank .