automated performance assessment in interactive qa in interactive-question-answering (qa) , users and systems take turns to ask questions and provide answers . in such an interactive setting , user questions largely depend on the answers provided by the system . one question is whether user follow-up questions can provide feedback for the system to automatically assess its performance (e.g. , assess whether a correct answer is delivered) . this self-awareness can make qa-systems more intelligent for information-seeking , for example , by adapting better strategies to cope with problematic situations . therefore , this paper describes our initial investigation in addressing this problem . our results indicate that interaction-context can provide useful cues for automated performance assessment in interactive qa .