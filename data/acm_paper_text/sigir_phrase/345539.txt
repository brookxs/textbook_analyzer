do batch and user-evaluations give the same results ? do improvements in system-performance demonstrated by batch evaluations confer the same benefit for real-users ? we carried out experiments designed to investigate this question . after identifying a weighting-scheme that gave maximum improvement over the baseline in a non-interactive evaluation , we used it with real-users searching on an instance recall task . our results showed the weighting-scheme giving beneficial results in batch studies did not do so with real-users . further analysis did identify other factors predictive of instance recall , including number of documents saved by the user , document recall , and number of documents seen by the user .