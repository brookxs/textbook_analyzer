robustness of regularized linear-classification methods in text-categorization real-world-applications often require the classification of documents under situations of small number of features , mis-labeled documents and rare positive examples . this paper investigates the robustness of three regularized linear-classification methods (svm , ridge-regression-and-logistic-regression) under above situations . we compare these methods in terms of their loss-functions and score distributions , and establish the connection between their optimization-problems and generalization-error bounds . several sets of controlled-experiments on the reuters-21578 corpus are conducted to investigate the robustness of these methods . our results show that ridge-regression seems to be the most promising candidate for rare class problems .