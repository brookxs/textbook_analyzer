translating topics to words for image-annotation one of the classic techniques for image-annotation is the language-translation model . it views an image as a document , i.e. , a set of visual-words which are obtained by vector quatitizing the image regions generated by unsupervised-image-segmentation . annotating images are achieved by translating visual-words to textual words , just like translating a document in english to a document in french . in this paper , we also view an image as a document , but we view the annotation processes as two consecutive processes , i.e. , document-summarization and translation . in the document-summarization process , an image document is firstly summarized into its own visual-language , which we called visual-topics . the translation-process translates these visual-topics to textual words . compared to the original translation-model , our visual-topics learned by the probabilistic-latent-semantic-analysis (plsa) approach provide an intermediate abstract level of visual description . we show improved annotation performance on the corel image dataset .