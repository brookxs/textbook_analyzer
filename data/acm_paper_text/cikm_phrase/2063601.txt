query-sampling for learning data-fusion data-fusion is to merge the results of multiple independent retrieval-models into a single ranked list . several earlier studies have shown that the combination of different models can improve the retrieval-performance better than using any of the individual models . although many promising results have been given by supervised-fusion methods , training-data sampling has attracted little attention in previous work of data-fusion . by observing some evaluations on trec and ntcir datasets , we found that the performance of one model varied largely from one training-example to another , so that not all training-examples were equivalently effective . in this paper , we propose two novel approaches : greedy and boosting approaches , which select effective-training data by query-sampling to improve the performance of supervised data-fusion algorithms such as bayesfuse , probfuse and mapfuse . extensive experiments were conducted on five data-sets including trec-3 ,4,5 and ntcir-3 ,4 . the results show that our sampling approaches can significantly improve the retrieval-performance of those data-fusion methods .