more influence means less work : fast latent-dirichlet-allocation by influence scheduling there have recently been considerable advances in fast inference for (online) latent-dirichlet-allocation (lda) . while it is widely recognized that the scheduling of documents in stochastic-optimization and in turn in lda may have significant consequences , this issue remains largely unexplored . instead , practitioners schedule documents essentially uniformly at random , due perhaps to ease of implementation , and to the lack of clear guidelines on scheduling the documents . in this work , we address this issue and propose to schedule documents for an update that exert a disproportionately large influence on the topics of the corpus before less influential ones . more precisely , we justify to sample documents randomly biased towards those ones with higher norms to form mini-batches . on several real-world datasets , including 3m articles from wikipedia and 8m from pubmed , we demonstrate that the resulting influence scheduled lda can handily analyze massive document-collections and find topic-models as good or better than those found with online lda , often at a fraction of time .