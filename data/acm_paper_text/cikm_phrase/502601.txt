mining confident rules without support requirement an open problem is to find all rules that satisfy a minimum confidence but not necessarily a minimum support . without the support requirement , the classic support-based pruning-strategy is inapplicable . the problem demands a confidence-based pruning-strategy . in particular , the following monotonicity of confidence , called the universal-existential upward closure , holds : if a rule of size k is confident (for the given minimum confidence) , for every other attribute not in the rule , some specialization of size k +1 using the attribute must be confident . like the support-based pruning , the bottleneck is at the memory that often is too small to store the candidates required for search . we implement this strategy on disk and study its performance .