integrating heterogeneous reatures for efficient content-based music-retrieval in this paper , we present a novel feature-extraction method facilitating efficient content-based-music-retrieval and classification , called <i> inmaf </i> . the goal of our approach is to allow straightforward incorporation of multiple musical features , such as timbral texture , pitch and rhythm structure , into a single low dimensional vector that is effective for retrieval and classification . unlike earlier approaches that used only acoustic properties as the basis for retrieval , our approach can easily incoporate human music-perception to improve accuracy of retrieval and classification-process . the superiority of our method is demonstrated by comparing it with state-of-the-art approaches in the areas of music-classification (using a variety of machine-learning-algorithms) , query-effectiveness and robustness against audio distortion .