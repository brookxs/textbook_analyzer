improving search-engines using human-computation-games work on evaluating and improving the relevance of web-search-engines typically use human-relevance-judgments or clickthrough-data . both these methods look at the problem of learning the mapping from queries to web-pages . in this paper , we identify some issues with this approach , and suggest an alternative approach , namely , learning a mapping from web-pages to queries . in particular , we use human-computation-games to elicit data about web-pages from players that can be used to improve search . we describe three human-computation-games that we developed , with a focus on page hunt , a single-player game . we describe experiments we conducted with several hundred game players , highlight some interesting-aspects of the data obtained and define the ` findability ' metric . we also show how we automatically extract query-alterations for use in query-refinement using techniques from bitext matching . the data that we elicit from players has several other applications including providing metadata for pages and identifying ranking issues .