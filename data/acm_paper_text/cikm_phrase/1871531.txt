a framework for evaluating database keyword-search strategies with regard to keyword-search systems for structured-data , research during the past decade has largely focused on performance . researchers have validated their work using ad-hoc experiments that may not reflect real-world workloads . we illustrate the wide deviation in existing evaluations and present an evaluation-framework designed to validate the next decade of research in this field . our comparison of 9 state-of-the-art keyword-search systems contradicts the retrieval-effectiveness purported by existing evaluations and reinforces the need for standardized evaluation . our results also suggest that there remains considerable room for improvement in this field . we found that many techniques can not scale to even moderately-sized datasets that contain roughly a million tuples . given that existing databases are considerably larger than this threshold , our results motivate the creation of new algorithms and indexing-techniques that scale to meet both current and future workloads .