dictionary_based sparse-representation for domain-adaptation machine-learning-algorithms are often as good as the data they can learn from . enormous amount of unlabeled-data is readily available and the ability to efficiently use such amount of unlabeled-data holds a significant promise in terms of increasing the performance of various learning tasks . we consider the task of supervised domain-adaptation and present a self-taught-learning_based framework which makes use of the k-svd algorithm for learning sparse-representation of data in an unsupervised manner . to the best of our knowledge this is the first work that integrates k-svd algorithm into the self-taught-learning framework . the k-svd algorithm iteratively alternates between sparse-coding of the instances based on the current dictionary and a process of updating/adapting the dictionary to better fit the data so as to achieve a sparse-representation under strict sparsity constraints . using the learnt dictionary , a rich feature-representation of the few labeled-instances is obtained which is fed to a classifier along with class labels to build the model . we evaluate our framework on the task of domain-adaptation for sentiment-classification . both self-domain (requiring very few domain-specific training instances) and cross-domain classification (requiring 0 labeled-instances of target-domain and very few labeled-instances of source-domain) are performed . empirical comparisons of self-domain and cross-domain results establish the efficacy of the proposed framework .