a unified optimization framework for robust pseudo-relevance-feedback algorithms we present a flexible new optimization framework for finding effective , reliable pseudo-relevance-feedback models that unifies existing complementary approaches in a principled way . the result is an algorithmic approach that not only brings together different benefits of previous methods , such as parameter self-tuning and risk-reduction from term-dependency modeling , but also allows a rich new space of model-search strategies to be investigated . we compare the effectiveness of a unified algorithm to existing methods by examining iterative performance and risk-reward tradeoffs . we also discuss extensions for generating new algorithms within our framework .