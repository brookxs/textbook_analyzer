stochastic-gradient boosted distributed decision trees stochastic-gradient boosted decision trees (gbdt) is one of the most widely used learning-algorithms in machine-learning today . it is adaptable , easy to interpret , and produces highly accurate models . however , most implementations today are computationally expensive and require all training-data to be in main-memory . as training-data becomes ever larger , there is motivation for us to parallelize the gbdt algorithm . parallelizing decision-tree-training is intuitive and various approaches have been explored in existing literature . stochastic boosting on the other hand is inherently a sequential process and have not been applied to distributed decision trees . in this work , we present two different distributed methods that generates exact stochastic gbdt models , the first is a mapreduce implementation and the second utilizes mpi on the hadoop grid-environment .