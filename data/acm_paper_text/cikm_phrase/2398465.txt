extraction of topic evolutions from references in scientific articles and its gpu-acceleration this paper provides a topic-model for extracting topic evolutions as a corpus-wide transition-matrix among latent topics . recent trends in text-mining point to a high demand for exploiting metadata . especially , exploitation of reference relationships among documents induced by hyperlinking web-pages , citing scientific articles , tumblring blog posts , retweeting tweets , etc. , is put in the foreground of the effort for an effective mining . we focus on scholarly activities and propose a topic-model for obtaining a corpus-wide view on how research topics evolve along citation relationships . our model , called teresa , extends latent-dirichlet-allocation (lda) by introducing a corpus-wide topic-transition probability-matrix , which models reference relationships as transitions among topics . our approximated variational-inference updates lda posteriors and topic-transition posteriors alternately . the main issue is execution-time amounting to o (mk2) , where k is the number of topics and m is that of links in citation-network . therefore , we accelerate the inference with nvidia-cuda compatible gpus . we compare the effectiveness of teresa with that of lda by introducing a new measure called diversity plus focusedness (d+f) . we also present topic-evolution examples our method gives .