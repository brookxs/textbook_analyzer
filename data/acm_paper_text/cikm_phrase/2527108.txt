usability in machine-learning at scale with graphlab today , machine-learning (ml) methods play a central role in industry and science . the growth of the-web and improvements in sensor-data-collection technology have been rapidly increasing the magnitude and complexity of the ml tasks we must solve . this growth is driving the need for scalable , parallel ml algorithms that can handle `` big-data . '' in this talk , we will focus on : examining common algorithmic-patterns in distributed ml methods . qualifying the challenges of implementing these algorithms in real distributed-systems . describing computational frameworks for implementing these algorithms at scale . addressing a significant-core challenge to large-scale ml -- enabling the widespread adoption of machine-learning beyond experts . in the latter part , we will focus mainly on the graphlab framework , which naturally expresses asynchronous , dynamic-graph computations that are key for state-of-the-art ml algorithms . when these algorithms are expressed in our higher-level abstraction , graphlab will effectively address many of the underlying parallelism challenges , including data-distribution , optimized communication , and guaranteeing sequential-consistency , a property that is surprisingly important for many ml algorithms . on a variety of large-scale tasks , graphlab provides 20-100x performance-improvements over hadoop . in recent months , graphlab has received many tens of thousands of downloads , and is being actively used by a number of startups , companies , research labs and universities .