towards a universal wordnet by learning from combined evidence lexical databases are invaluable sources of knowledge about words and their meanings , with numerous applications in areas like nlp , ir , and ai . we propose a methodology for the automatic-construction of a large-scale multilingual lexical database where words of many languages are hierarchically organized in terms of their meanings and their semantic-relations to other words . this resource is bootstrapped from wordnet , a well-known english-language resource . our approach extends wordnet with around 1.5 million meaning links for 800,000 words in over 200 languages , drawing on evidence extracted from a variety of resources including existing (monolingual) wordnets , (mostly bilingual) translation dictionaries , and parallel-corpora . graph-based-scoring functions and statistical-learning techniques are used to iteratively integrate this information and build an output graph . experiments show that this wordnet has a high level of precision and coverage , and that it can be useful in applied tasks such as cross-lingual text classification .