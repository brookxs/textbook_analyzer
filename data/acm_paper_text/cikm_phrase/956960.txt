summarization-evaluation using relative-utility we present a series of experiments to demonstrate the validity of relative-utility (ru) as a measure for evaluating extractive summarizers . ru is applicable in both single-document and multi-document-summarization , is extendable to arbitrary compression rates with no extra annotation-effort , and takes into account both random system-performance and interjudge agreement . our results using the jhu summary corpus indicate that ru is a reasonable and often superior alternative to several common evaluation-metrics .