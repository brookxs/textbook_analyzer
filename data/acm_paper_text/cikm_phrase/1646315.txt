spider : a system for scalable , parallel / distributed-evaluation of large-scale rdf-data rdf is a data-model for representing labeled directed-graphs , and it is used as an important building-block of semantic-web . due to its flexibility and applicability , rdf has been used in applications , such as semantic-web , bioinformatics , and social-networks . in these applications , large-scale-graph datasets are very common . however , existing techniques are not effectively managing them . in this paper , we present a scalable , efficient-query-processing system for rdf-data , named spider , based on the well-known parallel/distributed computing framework , hadoop . spider consists of two major modules (1) the graph-data loader , (2) the graph-query processor . the loader analyzes and dissects the rdf-data and places parts of data over multiple-servers . the query-processor parses the user-query and distributes sub queries to cluster nodes . also , the results of sub queries from multiple-servers are gathered (and refined if necessary) and delivered to the user . both modules utilize the mapreduce framework of hadoop . in addition , our system supports some features of sparql-query language . this prototype will be foundation to develop real applications with large-scale rdf graph data .