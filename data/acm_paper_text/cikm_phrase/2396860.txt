the generalized dirichlet-distribution in enhanced topic-detection we present a new , robust and computationally efficient hierarchical-bayesian-model for effective topic correlation modeling . we model the prior-distribution of topics by a generalized dirichlet-distribution (gd) rather than a dirichlet-distribution as in latent-dirichlet-allocation (lda) . we define this model as gd-lda . this framework captures correlations between topics , as in the correlated topic-model (ctm) and pachinko allocation model (pam) , and is faster to infer than ctm and pam . gd-lda is effective to avoid over-fitting as the number of topics is increased . as a tree-model , it accommodates the most important set of topics in the upper part of the tree based on their probability mass . thus , gd-lda provides the ability to choose significant topics effectively . to discover topic relationships , we perform hyper-parameter-estimation based on monte-carlo em estimation . we provide results using empirical likelihood (el) in 4 public datasets from trec and nips . then , we present the performance of gd-lda in ad-hoc-information-retrieval (ir) based on map , p@10, and discounted gain . we discuss an empirical-comparison of the fitting time . we demonstrate significant improvement over ctm , lda , and pam for el estimation . for all the ir-measures , gd-lda shows higher performance than lda , the dominant topic-model in ir . all these improvements with a small increase in fitting time than lda , as opposed to ctm and pam .