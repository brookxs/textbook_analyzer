improving retrieval-accuracy of difficult-queries through generalizing negative document language models when a query topic is difficult and the search-results are very poor , negative-feedback is a very useful method to improve the retrieval-accuracy and user-experience . one challenge in negative-feedback is that negative documents tend to be distracting in different ways , thus as training-examples , negative-examples are sparse . in this paper , we solve the problem of data-sparseness in the language-modeling framework . we propose an optimization framework , in which we learn from a few top-ranked non-relevant examples , and search in a large space of all language-models to build a more general negative language-model . this general negative language-model has more power in pruning the non-relevant documents , thus potentially improving the performance for difficult-queries . experiment results on representative trec collections show that the proposed optimization framework can improve negative-feedback performance over the state-of-the-art negative-feedback method through generalizing negative language-models .