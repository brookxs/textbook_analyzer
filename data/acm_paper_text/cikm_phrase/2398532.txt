semantic-context learning with large-scale weakly-labeled image-set there are a large number of images available on the web ; meanwhile , only a subset of web-images can be labeled by professionals because manual-annotation is time-consuming and labor-intensive . although we can now use the collaborative image-tagging system , e.g. , flickr , to get a lot of tagged images provided by internet-users , these labels may be incorrect or incomplete . furthermore , semantics richness requires more than one label to describe one image in real applications , and multiple labels usually interact with each other in semantic-space . it is of significance to learn semantic-context with large-scale weakly-labeled image-set in the task of multi-label-annotation . in this paper , we develop a novel method to learn semantic-context and predict the labels of web-images in a semi-supervised framework . to address the scalability issue , a small number of exemplar images are first obtained to cover the whole data cloud ; then the label vector of each image is estimated as a local combination of the exemplar label vectors . visual-context , semantic-context , and neighborhood consistency in both visual and semantic-spaces are sufficiently leveraged in the proposed framework . finally , the semantic context and the label confidence vectors for exemplar images are both learned in an iterative way . experimental-results on the real-world image dataset demonstrate the effectiveness of our method .