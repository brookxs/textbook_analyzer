identifying interesting assertions from the-web how can we cull the facts we need from the overwhelming mass of information and misinformation that is the-web ? the textrunner extraction engine represents one approach , in which people pose keyword-queries or simple questions and textrunner returns concise answers based on tuples extracted from web-text . unfortunately , the results returned by engines such as textrunner include both informative facts (e.g. , the fda banned ephedra) and less useful statements (e.g. , the fda banned products) . this paper therefore investigates filtering textrunner results to enable people to better focus on interesting assertions . we first develop three distinct models of what assertions are likely to be interesting in response to a query . we then fully operationalize each of these models as a filter over textrunner results . finally , we develop a more sophisticated filter that combines the different models using relevance-feedback . in a study of human ratings of the interestingness of textrunner assertions , we show that our approach substantially enhances the quality of textrunner results . our best filter raises the fraction of interesting results in the top thirty from 41.6 \ % to 64.1 \ % .