text-classification improved through multigram models classification algorithms and document-representation approaches are two key elements for a successful document-classification system . in the past , much work has been conducted to find better ways to represent documents . however , most of the attempts rely on certain extra resources such as wordnet , or they face the problem of extremely high-dimension . in this paper , we propose a new document-representation approach based on n-multigram language-models . this approach can automatically discover the hidden semantic sequences in the documents under each category . based on n-multigram language-models and n-gram language models , we put forward two text-classification algorithms . the experiments on rcv1 show that our proposed algorithm based on n-multigram-models alone can achieve the similar or even better classification-performance compared with the classifier based on n-gram-models but the model-size of our algorithm is much smaller than that of the latter . another proposed algorithm based on the combination of n-multigram-models and n-gram-models improves the micro-f1 and macro-f1 values from 89.5 \ % to 92.6 \ % and 87.2 \ % to 91.1 \ % respectively . all these observations support the validity of our proposed document-representation approach .