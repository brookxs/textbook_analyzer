one is enough : distributed filtering for duplicate-elimination the growth of online-services has created the need for duplicate-elimination in high-volume streams of events . the sheer volume of data in applications such as pay-per-click clickstream processing , rss-feed syndication and notification-services in social-sites such twitter and facebook makes traditional centralized solutions hard to scale . in this paper , we propose an approach based on distributed filtering . to this end , we introduce a suite of distributed-bloom-filters that exploit different ways of partitioning the event-space . to address the continuous nature of event-delivery , the filters are extended to support sliding-window semantics . moreover , we examine locality-related tradeoffs and propose a tree-based architecture to allow for duplicate-elimination across geographic locations . we cast the design space and present experimental-results that demonstrate the pros-and-cons of our various solutions in different settings .