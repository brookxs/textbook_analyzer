learning on the border : active-learning in imbalanced-data-classification this paper is concerned with the class-imbalance-problem which has been known to hinder the learning-performance of classification algorithms . the problem occurs when there are significantly less number of observations of the target concept . various real-world classification-tasks , such as medical-diagnosis , text-categorization and fraud-detection suffer from this phenomenon . the standard machine-learning-algorithms yield better prediction-performance with balanced datasets . in this paper , we demonstrate that active-learning is capable of solving the class-imbalance-problem by providing the-learner more balanced classes . we also propose an efficient way of selecting informative instances from a smaller pool of samples for active-learning which does not necessitate a search through the entire dataset . the proposed method yields an efficient querying system and allows active-learning to be applied to very-large datasets . our experimental-results show that with an early stopping-criteria , active-learning achieves a fast solution with competitive prediction-performance in imbalanced-data-classification .