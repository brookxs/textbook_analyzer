goal-oriented methods and meta methods for document-classification and their parameter-tuning automatic-text-classification methods come with various calibration parameters such as thresholds for probabilities in bayesian-classifiers or for hyperplane distances in svm classifiers . in a given application context these parameters should be set so as to meet the relative-importance of various result quality metrics such as precision versus recall . in this paper we consider classifiers that can accept a document for a topic , reject it , or abstain . we aim to meet the application 's goals in terms of accuracy (i.e. , avoid false acceptances or rejections) and loss (i.e. , limit the fraction of documents for which no decision is made) . to this end we investigate restrictive forms of support-vector-machine classifiers and we develop meta methods that split the training-data into subsets for independently trained classifiers and then combine the results of these classifiers . these techniques tend to improve accuracy at the expense of document loss . we develop estimators that help to predict the accuracy and loss for a given setting of the methods ' tuning parameters , and a methodology for efficiently deriving a setting that meets the application 's goals . our experiments confirm the practical viability of the approach .