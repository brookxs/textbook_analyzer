a robust semi-supervised-classification method for transfer-learning the transfer-learning problem of designing good classifiers with a high generalization ability by using labeled samples whose distribution is different from that of test samples is an important and challenging research issue in the fields of machine-learning and data-mining . this paper focuses on designing a semi-supervised-classifier trained by using unlabeled-samples drawn by the same distribution as test samples , and presents a semi-supervised-classification method to deal with the transfer-learning problem , based on a hybrid discriminative and generative-model . although jess-cm is one of the most successful semi-supervised-classifier design frameworks and has achieved the best published results in nlp-tasks , it has an overfitting problem in transfer-learning settings that we consider in this paper . we expect the overfitting problem to be mitigated with the proposed method , which utilizes both labeled and unlabeled-samples for the discriminative-training of classifiers . we also present a refined objective that formalizes the training-algorithm and classifier form . our experimental-results for text-classification using three typical benchmark-test collections confirmed that the proposed method outperformed the jess-cm framework with most transfer-learning settings .