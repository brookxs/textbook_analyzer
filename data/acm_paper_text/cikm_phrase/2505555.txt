on handling textual-errors in latent document-modeling as large-scale text data become available on the web , textual-errors in a corpus are often inevitable (e.g. , digitizing historic-documents) . due to the calculation of frequencies of words , however , such textual-errors can significantly impact the accuracy of statistical-models such as the popular latent-dirichlet-allocation (lda) model . to address such an issue , in this paper , we propose two novel extensions to lda (i.e. , te-lda and tde-lda) : (1) the te-lda model incorporates textual-errors into term generation-process ; and (2) the tde-lda model extends te-lda further by taking into account topic dependency to leverage on semantic connections among consecutive words even if parts are typos . using both real and synthetic-data sets with varying degrees of `` errors '' , our tde-lda model outperforms : (1) the traditional lda model by 16 % -39 % (real) and 20 % -63 % (synthetic) ; and (2) the state-of-the-art n-grams model by 11 % -27 % (real) and 16 % -54 % (synthetic) .