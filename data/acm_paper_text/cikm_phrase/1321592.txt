dynamic-index-pruning for effective caching ram and dynamic-pruning schemes to reduce query-evaluation times . while only a small portion of lists are processed with dynamic-pruning , current systems still store the entire inverted list in cache . in this paper we investigate caching only the pieces of the inverted-lists that are actually used to answer a query during dynamic-pruning . we examine an lru cache-model , and two recently proposed models . we also introduce a new dynamic-pruning scheme for impact-ordered inverted-lists . using two large web collections and corresponding query-logs we show that , using an lru cache , our new pruning scheme reduces the number of disk accesses during query-processing time by 7 \ % -15 \ % over the state-of-the-art impact-ordered baseline , without reducing answer-quality . surprisingly , however , we discover that using our new pruning scheme makes little difference to disk traffic when the more sophisticated caching schemes are employed .