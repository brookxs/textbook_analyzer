learning-to-rank for robust question-answering this paper aims to solve the problem of improving the ranking of answer candidates for factoid_based questions in a state-of-the-art question-answering-system . we first provide an extensive comparison of 5 ranking-algorithms on two datasets -- from the jeopardy quiz show and a medical-domain . we then show the effectiveness of a cascading approach , where the ranking produced by one ranker is used as input to the next stage . the cascading approach shows sizeable gains on both datasets . we finally evaluate several rank-aggregation techniques to combine these algorithms , and find that supervised kemeny aggregation is a robust technique that always beats the baseline ranking approach used by watson for the jeopardy competition . we further corroborate our results on trec question-answering datasets .