citedata : a new multi-faceted dataset for evaluating personalized-search performance personalized-search systems have evolved to utilize heterogeneous features including document hyperlinks , category labels in various taxonomies and social-tags in addition to free-text of the documents . consequently , classifiers , pagerank algorithms and collaborative-filtering methods are often used as intermediate steps in such personalized-retrieval systems . thorough comparative-evaluation of such complex-systems has been difficult due to the lack of appropriate publicly available datasets that provide such diverse feature-sets . to remedy the situation , we have created citedata , a new dataset for benchmark evaluations of personalized-search performance , that will be made publicly accessible . citedata is a collection of academic articles extracted from citeulike and citeseer repositories , with rich feature-sets such as authors , author-affiliations , topic labels , social-tags and citation-information . we further supplement it with personalized queries and relevance-judgments which were obtained from volunteer users . this paper starts with a discussion of the design criteria and characteristics of the citedata dataset in comparison with current benchmark datasets , followed by a set of task-oriented empirical evaluations of popular algorithms in statistical-classification , collaborative-filtering and link-analysis as intermediate steps for personalized-search . our results show significant performance-improvement of personalized approaches , over that of unpersonalized approaches . we also observe that a meta personalized-search engine that leverages information from multiple sources of features performs better than algorithms that use only one of the constituent source of features .