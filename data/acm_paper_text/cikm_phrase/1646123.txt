a risk-minimization framework for domain-adaptation supervised-learning algorithms usually require high quality labeled training set of large volume . it is often expensive to obtain such labeled examples in every domain of an application . domain-adaptation aims to help in such cases by utilizing data available in related domains . however transferring knowledge from one domain to another is often non trivial due to different data distributions among the domains . moreover , it is usually very hard to measure and formulate these distribution differences . hence we introduce a new concept of label-relation function to transfer knowledge among different domains without explicitly formulating the data-distribution differences . a novel learning-framework , domain-transfer risk-minimization (dtrm) , is proposed based on this concept . dtrm simultaneously minimizes the empirical risk for the target and the regularized empirical risk for source-domain . under this framework , we further derive a generic-algorithm called domain-adaptation by label relation (dalr) that is applicable to various applications in both classification and regression settings . dalr iteratively updates the target hypothesis function and outputs for the source-domain until it converges . we provide an in-depth theoretical-analysis of dtrm and establish fundamental error-bounds . we also experimentally evaluate dalr on the task of ranking search-results using real-world-data . our experimental-results show that the proposed algorithm effectively and robustly utilizes data from source domains under various conditions : different sizes for source-domain data ; different noise levels for source-domain data , and different difficulty levels for target-domain data .