modeling semantic-relations between visual attributes and object categories via dirichlet forest prior in this paper , we deal with two research-issues : the automation of visual attribute-identification and semantic-relation learning between visual attributes and object categories . the contribution is two-fold , firstly , we provide uniform framework to reliably extract both categorical attributes and depictive attributes . secondly , we incorporate the obtained semantic-associations between visual attributes and object categories into a text-based topic-model and extract descriptive latent topics from external textual knowledge sources . specifically , we show that in mining natural-language descriptions from external-knowledge sources , the relation between semantic visual attributes and object categories can be encoded as must-links and cannot-links , which can be represented by dirichlet-forest prior . to alleviate the workload of manual supervision and labeling in image-categorization process , we introduce a semi-supervised-training framework using soft-margin semi-supervised svm-classifier . we also show that the large-scale image categorization results can be significantly improved by combining automatically acquired visual attributes . experimental-results show that the proposed model achieves better ability in describing object-related attributes and makes the inferred latent topics more descriptive .