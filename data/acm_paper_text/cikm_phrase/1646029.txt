l2 norm regularized feature kernel regression for graph-data features in many real-world-applications such as cheminformatics , bioinformatics and information retrieval have complex internal-structure . for example , frequent-patterns mined from graph-data are graphs . such graph features have different number of nodes and edges and usually overlap with each other . in conventional data-mining and machine-learning-applications , the internal-structure of features are usually ignored . in this paper we consider a supervised-learning-problem where the features of the data-set have intrinsic complexity , and we further assume that the feature intrinsic complexity may be measured by a kernel-function . we hypothesize that by regularizing model-parameters using the information of feature complexity , we can construct simple yet high quality model that captures the intrinsic structure of the data . towards the end of testing this hypothesis , we focus on a regression-task and have designed an algorithm that incorporate the feature complexity in the learning-process , using a kernel matrix weighted l2 norm for regularization , to obtain improved regression performance over conventional learning-methods that does not consider the additional-information of the feature . we have tested our algorithm using 5 different real-world-data sets and have demonstrate the effectiveness of our method .