transfer incremental-learning for pattern-classification traditional machine-learning-methods , such as support-vector-machines (svms) , usually assume that training-and-test-data share the same distributions . due to the inherent dynamic-data nature , it is often observed that (1) the volumes of the training-data may gradually grow ; and (2) the existing and the newly arrived samples may be subject to different distributions or learning tasks . in this paper , we propose a transfer incremental support-vector-machine (trisvm) , with the objective of tackling changes in data volumes and learning tasks at the same time . by using new updating rules to calculate the inverse matrix , trisvm solves the existing incremental-learning problem more efficiently , especially for high-dimensional-data . furthermore , when using new samples to update the existing models , trisvm employs sample-based weight adjustment procedures to ensure that the concept transferring between auxiliary and target samples can be leveraged to fulfill the transfer-learning goal . experimental-results on real-world-data sets demonstrate that trisvm achieves better efficiency and prediction-accuracy than both incremental-learning and transfer-learning_based methods . in addition , the results also show that trisvm is able to achieve bidirectional knowledge-transfer between two similar tasks .