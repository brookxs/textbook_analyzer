feature-based models for improving the quality of noisy training data for relation-extraction supervised-relation-extraction from text relies on annotated data . distant supervision is a scheme to obtain noisy training data by using a knowledge-base of relational tuples as the ground-truth and finding entity pair matches in a text-corpus . we propose and evaluate two feature-based models for increasing the quality of distant supervision extraction-patterns . the first model is an extension of a hierarchical topic model that induces background , relation specific and argument-pair specific feature distributions . the second model is a perceptron , trained to match an objective-function that enforces two constraints : 1) an at-least-one-semantics , i.e. at least one training-example per relational tuple is assumed to be correct ; 2) high scores for a dedicated nil label that accounts for the noise in the training-data . for both algorithms , neither explicit negative data nor the ratio of negatives has to be provided . both algorithms give improvements over a maximum-likelihood baseline as well as over a previous topic-model without features , evaluated on tac kbp data .