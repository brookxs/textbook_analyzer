feature-selection based on term-frequency and t-test for text-categorization much work has been done on feature-selection . existing methods are based on document-frequency , such as chi-square-statistic , information-gain etc. . however , these methods have two shortcomings : one is that they are not reliable for low-frequency terms , and the other is that they only count whether one term occurs in a document and ignore the term-frequency . actually , high-frequency terms within a specific category are often regards as discriminators . this paper focuses on how to construct the feature-selection function based on term-frequency , and proposes a new approach based on t-test , which is used to measure the diversity of the distributions of a term between the specific category and the entire corpus . extensive comparative experiments on two text-corpora using three classifiers show that our new approach is comparable to or or slightly better than the state-of-the-art feature-selection methods (i.e. , chi2 , and ig) in terms of macro-f1 and micro-f1