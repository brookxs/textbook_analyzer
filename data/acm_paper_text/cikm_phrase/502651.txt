learning probabilistic-datalog rules for information classification and transformation probabilistic-datalog is a combination of classical datalog (i.e. , function-free horn-clause predicate-logic) with probability-theory . therefore , probabilistic weights may be attached to both facts and rules . but it is often impossible to assign exact rule weights or even to construct the rules themselves . instead of specifying them manually , learning-algorithms can be used to learn both rules and weights . in practice , these algorithms are very slow because they need a large example set and have to test a high number of rules . we apply a number of extensions to these algorithms in order to improve efficiency . several applications demonstrate the power of learning probabilistic-datalog rules , showing that learning-rules is suitable for low dimensional problems (e.g. , schema-mapping) but inappropriate for higher dimensions like e.g. in text-classification .