mr.knn : soft-relevance for multi-label-classification multi-label-classification refers to learning tasks with each instance belonging to one or more classes simultaneously . it arose from real-world-applications such as information-retrieval , text-categorization and functional-genomics . currently , most of the multi-label-learning methods use the strategy called binary relevance , which constructs a classifier for each unique label by grouping data into positives (examples with this label) and negatives (examples without this label) . with binary relevance , an example with multiple labels is considered as a positive data for each label it belongs to . for some classes , this data point may behave like an outlier confusing classifiers , especially in the cases of well-separated classes . in this paper , we first introduce a new strategy called soft-relevance , where each multi-label example is assigned a relevance score to the labels it belongs to . this soft-relevance is then employed in a voting function used in a k-nearest-neighbor classifier . furthermore , a voting-margin ratio is introduced to the k-nearest-neighbor classifier for better performance . we compare the proposed method to other multi-label-learning methods over three multi-label datasets and demonstrate that the proposed method provides an effective way to multi-label-learning .