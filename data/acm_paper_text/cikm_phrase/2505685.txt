is top-k sufficient for ranking ? recently , ` top-k learning-to-rank ' has attracted much attention in the community of information-retrieval . the motivation comes from the difficulty in obtaining a full-order ranking list for training , when employing reliable pairwise-preference judgment . inspired by the observation that users mainly care about top ranked search result , top-k learning-to-rank proposes to utilize top-k ground-truth for training , where only the total-order of top k items are provided , instead of a full-order ranking list . however , it is not clear whether the underlying assumption holds , i.e. top-k ground-truth is sufficient for training . in this paper , we propose to study this problem from both empirical and theoretical aspects . empirically , our experimental-results on benchmark datasets letor4 .0 show that the test performances of both pairwise and listwise ranking-algorithms will quickly increase to a stable value , with the growth of k in the top-k ground-truth . theoretically , we prove that the losses of these typical ranking-algorithms in top-k setting are tighter upper-bounds of (1--ndcg@k) , compared with that in full-order setting . therefore , our studies reveal that learning on top-k ground-truth is surely sufficient for ranking , which lay a foundation for the new learning-to-rank framework .