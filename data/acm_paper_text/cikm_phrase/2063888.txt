smoothing ndcg metrics using tied scores one of promising directions in research on learning-to-rank concerns the problem of appropriate choice of the objective-function to maximize by means of machine-learning-algorithms . we describe a novel technique of smoothing an arbitrary ranking-metric and demonstrate how to utilize it to maximize the retrieval quality in terms of the $ ndcg$ metric . the idea behind our listwise ranking-model called tierank is artificial probabilistic tying of predicted relevance-scores at each iteration of learning-process , which defines a distribution on the set of all permutations of retrieved documents . such distribution provides a desired smoothed version of the target retrieval quality-metric . this smooth function is possible to maximize using a gradient-descent-method . experiments on letor collections show that tierank outperforms most of the existing learning-to-rank algorithms .