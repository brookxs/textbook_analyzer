evaluation-of-methods for relative comparison of retrieval-systems based on clickthroughs the cranfield evaluation method has some disadvantages , including its high cost in labor and inadequacy for evaluating interactive-retrieval techniques . as a very promising alternative , automatic comparison of retrieval-systems based on observed clicking behavior of users has recently been studied . several methods have been proposed , but there has so far been no systematic way to assess which strategy is better , making it difficult to choose a good method for real applications . in this paper , we propose a general way to evaluate these relative comparison methods with two measures : utility to users (utu) and effectiveness of differentiation (eod) . we evaluate two state-of-the-art methods by systematically simulating different retrieval scenarios . inspired by the weakness of these methods revealed through our evaluation , we further propose a novel method by considering the positions of clicked documents . experiment results show that our new method performs better than the existing methods .