parallel proximal support-vector-machine for high-dimensional pattern classification proximal support-vector-machine (psvm) is a simple but effective classifier , especially for solving large-scale-data classification problems . an inherent deficiency of psvm lies on its inefficiency for dealing with high-dimensional-data . in this paper , we propose a parallel version of psvm (ppsvm) . based on random dimensionality partitioning , ppsvm can obtain partitioned local model parameters in parallel , with combined parameters to form the final global solution . in fact , ppsvm enjoys two properties : 1) it can calculate model-parameters in parallel and is therefore a fast learning-method with theoretically proved convergence ; and 2) it can avoid the inversion of large matrix , which makes it suitable for high-dimensional-data . in the paper , we also propose a random ppsvm with randomly partitioned data in each iteration to improve the performance of psvm . experimental-results on real-world-data demonstrate that the proposed methods can obtain similar or even better prediction-accuracy than psvm with much better runtime efficiency .