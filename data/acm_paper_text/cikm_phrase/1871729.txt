yes we can : simplex volume maximization for descriptive web-scale matrix-factorization matrix-factorization methods are among the most common techniques for detecting latent components in data . popular examples include the singular-value-decomposition or non-negative-matrix-factorization . unfortunately , most methods suffer from high computational-complexity and therefore do not scale to massive-data . in this paper , we present a linear time algorithm for the factorization of gigantic matrices that iteratively yields latent components . we consider a constrained matrix-factorization s.t. ~ the latent components form a simplex that encloses most of the remaining data . the algorithm maximizes the volume of that simplex and thereby reduces the displacement of data from the space spanned by the latent components . hence , it also lowers the frobenius norm , a common criterion for matrix-factorization quality . our algorithm is efficient , well-grounded in distance-geometry , and easily applicable to matrices with billions of entries . in addition , the resulting factors allow for an intuitive interpretation of data : every data point can now be expressed as a convex-combination of the most extreme and thereby often most descriptive instances in a collection of data . extensive experimental validations on web-scale-data , including 80 million images and 1.5 million twitter tweets , demonstrate superior performance compared to related factorization or clustering-techniques .