term necessity prediction the probability that a term appears in relevant documents (p (t | r)) is a fundamental quantity in several probabilistic-retrieval-models , however it is difficult to estimate without relevance-judgments or a relevance-model . we call this value term necessity because it measures the percentage of relevant documents retrieved by the term - how necessary a term 's occurrence is to document-relevance . prior research typically either set this probability to a constant , or estimated it based on the term 's inverse-document-frequency , neither of which was very effective . this paper identifies several factors that affect term necessity , for example , a term 's topic centrality , synonymy and abstractness . it develops term - and query-dependent features for each factor that enable supervised-learning of a predictive-model of term necessity from training-data . experiments with two popular retrieval-models and 6 standard-datasets demonstrate that using predicted term necessity estimates as user term weights of the original query terms leads to significant improvements in retrieval-accuracy .