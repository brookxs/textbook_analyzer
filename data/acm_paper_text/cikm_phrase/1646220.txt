vetting the links of the-web many web-links mislead human surfers and automated crawlers because they point to changed content , out-of-date information , or invalid urls . it is a particular problem for large , well-known directories such as the dmoz open-directory-project , which maintains links to representative and authoritative external web-pages within their various topics . therefore , such sites involve many editors to manually revisit and revise links that have become out-of-date . to remedy this situation , we propose the novel web-mining task of identifying outdated links on the web . we build a general classification-model , primarily using local and global temporal-features extracted from historical content , topic , link and time-focused changes over time . we evaluate our system via five-fold cross-validation on more than fifteen thousand odp external-links selected from thirteen top-level categories . our system can predict the actions of odp editors more than 75 \ % of the time . our models and predictions could be useful for various applications that depend on analysis of web-links , including ranking and crawling .