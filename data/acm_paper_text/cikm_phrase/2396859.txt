tcsst : transfer classification of short &#38; sparse-text using external data short &#38; sparse-text is becoming more prevalent on the web , such as search snippets , micro-blogs and product-reviews . accurately classifying short &#38; sparse-text has emerged as an important while challenging task . existing work has considered utilizing external data (e.g. wikipedia) to alleviate data-sparseness , by appending topics detected from external data as new features . however , training a classifier on features concatenated from different spaces is not easy considering the features have different physical meanings and different significance to the classification-task . moreover , it exacerbates the `` curse-of-dimensionality '' problem . in this study , we propose a transfer classification-method , tcsst , to exploit the external data to tackle the data-sparsity issue . the transfer classifier will be learned in the original feature-space . considering that the labels of the external data may not be readily available or sufficiently enough , tcsst further exploits the unlabeled external data to aid the transfer classification . we develop novel strategies to allow tcsst to iteratively select high quality unlabeled external data to help with the classification . we evaluate the performance of tcsst on both benchmark as well as real-world-data sets . our experimental-results demonstrate that the proposed method is effective in classifying very short &#38; sparse-text , consistently outperforming existing and baseline methods .