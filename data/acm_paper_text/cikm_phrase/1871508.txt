assessor-error in stratified evaluation several important information-retrieval-tasks , including those in medicine , law , and patent review , have an authoritative standard of relevance , and are concerned about retrieval completeness . during the evaluation of retrieval-effectiveness in these domains , assessors make errors in applying the standard of relevance , and the impact of these errors , particularly on estimates of recall , is of crucial concern . using data from the interactive task of the trec legal track , this paper investigates how reliably the yield of relevant documents can be estimated from sampled assessments in the presence of assessor-error , particularly where sampling is stratified based upon the results of participating retrieval-systems . we show that assessor-error is in general a greater source of inaccuracy than sampling-error . a process of appeal and adjudication , such as used in the interactive task , is found to be effective at locating many assessment errors ; but the process is expensive if complete , and biased if incomplete . an unbiased double-sampling method for resolving assessment error is proposed , and shown on representative data to be more efficient and accurate than appeal-based adjudication .