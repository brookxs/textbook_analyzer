feature-selection using hierarchical feature clustering one of the challenges in data-mining is the dimensionality of data , which is often very high and prevalent in many domains , such as text-categorization and bio-informatics . the high-dimensionality of data may bring many adverse situations to traditional-learning algorithms . to cope with this issue , feature-selection has been put forward . currently , many efforts have been attempted in this field and lots of feature-selection algorithms have been developed . in this paper we propose a new selection-method to pick discriminative-features by using information measurement . the main characteristic of our selection-method is that the selection procedure works like feature-clustering in a hierarchically agglomerative way , where each feature is considered as a cluster and the between-cluster and within-cluster distances are measured by mutual-information and the coefficient of relevancy respectively . consequently , the final aggregated cluster is the selection result , which has the minimal redundancy among its members and the maximal relevancy with the class labels . the simulation-experiments on seven datasets show that the proposed method outperforms other popular feature-selection algorithms in classification-performance .