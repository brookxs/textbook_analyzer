 7.1 Background  Most of the techniques described in the last chapter built on representational and inference methods originally developed within AI in the 1970s and '80s. Today, these methods are sometimes called Good OldFashioned AI (GOFAI), to distinguish them from more recent advances. There are many ways to characterize this change (see Russell and Norvig's text for an alternative account [Russell and Norvig, 1995, p. 827] and cf. Sections 6.9 and 7.8), but the most important is: AI is now centrally concerned with learning the representations it uses rather than assuming that some smart knowledge engineer has entered it manually.  To be concrete, imagine that you are to act as a librarian with respect to your own email. We have assumed at several points that you are collecting vast amounts of email, but perhaps are only now starting to think how it should be classified for subsequent retrieval. If we hire a librarian, we can reasonably expect him or her to bring certain useful skills to this new job and to continue to learn ways of doing it better. As their boss we must provide regular feedback that points out both good and bad aspects of their work If this person was having their first annual review and they were no better at finding useful information than the day they were hired, we would have reason for concern.  252 ADAPTIVE INFORMATION RETRIEVAL       253  Ancillary structure  M;  Ency. Britannica WESTLAW MED LINE  index  Manual encoding effort  FIGURE 7.1 Learning Conceptual Structures  The preceding chapters have surveyed a number of techniques for supporting the FOA task, but their utility is immediately apparent and we do not expect it to improve. This chapter is concerned with adaptive techniques: those that improve their performance over time, in response to feedback they receive on prior performance. We can idealize our goal for the learning system in terms of a person - a clever, resourceful, adaptive librarian.  Figure 7.1 gives an overview of how machine learning fits into the space of existing IR techniques. The horizontal axis is meant to indicate the amount of manual effort expended to improve the corpus. These activities may include constructing a controlled vocabulary, forming good lexical index terms, including phrases, building thesauri relating the keywords to one another, etc. The vertical axis attempts to capture something like ease of use for FOA. Such ease-of-use metrics are notoriously difficult to quantify, but some indicators may include search time to find a known item.  Prior to the widespread application of search engine technologies, brought on by efforts like B. Kahle's Wide Area Information System (WAIS) and G. Salton's SMART system, to search text meant to grep across textual fields. Because grep and related search methods rely on regular expressions for queries, and because regular expressions can't 254      FINDING OUT ABOUT  be conveniently composed with Boolean operators, early search systems provided only these search techniques.  But with the introduction of search engine technologies, the goal became to build an index, much like a librarian might construct for a collection of books or documents. These indices have been at the core of our FOA discussion.  Figure 7.1 extends this progression further. While it is rare to have any textual corpus receive manual attention from a librarian or editor, and so there are very few manual indices, a very few corpora have received even more extensive editorial enhancement. The Encyclopedia Britannicagt; Westlaw, and Medline are examples of just how much the FOA activity can be supported by rich representations.  This becomes the goal for our machine learning techniques. They will turn out to form a natural extension of the statistical techniques underlying automatic index construction. Peter Turney maintains a useful bibliography of Machine Learning Applied to Information Retrieval1 references generally, and of Text Classification Resources2 in particular.  Finally, it is always a mistake to view the relationship between algorithmic (artificially intelligent) methods and the natural, human intelligent behaviors they mimic as an opposition. The most constructive systems we can build are ones that leverage editorial capabilities with new computational tools. The editor's workbench is a good metaphor for such designs.   