 INFERENCE BEYOND THE INDEX      213  6.3.2 Corpus-Based Linguistics and WordNet  Linguistics has traditionally focused on the phenomena of spoken language, and since Chomsky [Chomsky, 1965; Chomsky, 1972] it has further focused on syntactic rules describing the generation and understanding of individual sentences. But as more large samples of written text have become available, corpus-based linguistics has become an increasingly active area of research. D. D. Lewis and E. D. Liddy have collected a useful bibliography and resource list on NLPfor IR,11 and R. Futrelle and X. Zhang have collected large-scale persistent object systems for Corpus Linguistics and Information Retrieval12 Stuart Shieber maintains the The Computation and Language Archive13 as part of the LANL reprint server.  The sophistication of syntactic analysis of computational linguistics provides a striking contrast to IR's typical bag-of-words approach, which aggressively ignores any ordering effects. Conversely, IR's central concerns with semantic issues of meaning and the ultimate pragmatics of using language to find relevant documents go beyond the myopic concern with isolated sentences that is typical of linguistics. The range of potential interactions between these perspectives is only beginning to be explored, but it includes the introduction of parsing techniques with IR retrieval systems [Smeaton, 1992; Strzalkowski, 1994], as^well as using statistical methods to identify phrases that are a first step from a simple bag-of-words to syntactically well-formed sentences [Lewis, 1992; Krovetz, 1993; Church and Hanks, 1989; Steier, 1994; Steier and Belew, 1994a]. Another important direction of interaction is the use of IR methods across multilingual corpora, for example, arising from the integration of the European Community [Hull and Grefenstette, 1996; Sheridan and Ballerini, 1996].  From a syntactic perspective, the only way to get issues of real meaning into language is via the lexicon: a dictionary of all words and their meanings. Our present concern, interkeyword structures, becomes an issue of lexical semantics [Cruse, 1986], and it is no surprise that linguists have also developed representational systems for interword relationships. An influential and widely used example of a keyword  11 ftp: //ciir-ffcp.cs.ijinass.eciu/pub/papers/lewis/nlir"bib93.ps.Z  12 atgl .wxistl.edu/digital library94/paper/futa^Ue.htanl  n zxxianl.gov/cmp-lg/ 214      FINDING OUT ABOUT  TABLE 6.4 WordNet VocabularyDistribution by Lexical Category  Category      Forms       Meanings (SynSets)  Nouns             57,000               48,800  Adjectives        19,500                10,000  Verbs              21,000                 8,400  Total               95,600                70,100  A wide-ranging     thesaurus is the WordNet14 system developed by George Miller^ and  psychologist         colleagues [Fellbaum, 1998].  One obvious distinction of WordNet is simply the size of its vocabulary: It contains almost 100,000 distinct word forms, divided into lexical categories as shown in Table 6.4. Central to the lexical approach to semantics is distinguishing between lexical items and the "concepts" they are meant to invoke:  "Word form" will be used here to refer to the physical utterance or inscription and "word meaning" to refer to the lexicalized concept that a form can be used to express. Then the starting point for lexical semantics can be said to be the mapping between forms and meanings. [Fellbaum, 1998, p. 4]  The relations connecting words in WordNet are similar - but not identical - to those used within thesauri. The first and most important relation is synonymy. This has a special role in WordNet, pulling multiple word forms together into a synonym set, which, by definition, all have the same meaning:  According to one definition (usually attributed to Leibniz) two expressions are synonymous if the substitution of one for the other never changes the truth value of a sentence in which the substitution is made___A weakened version of this definition  would make synonymy relative to a context: two expressions are synonymous in a linguistic context C if the substitution of one for the other in C does not alter the truth value. [Fellbaum, 1998,  p. 6]  14 www.cogBcl.priiiceton.edu/wn/ INFERENCE BEYOND THE INDEX      215  TABLE 6.5 WordNet's Top-Level Noun Categories  act, action, activity            natural object  animal, fauna                   natural phenomenon  artifact                             person, human being  attribute, property            plant, flora  body, corpus                     possession  cognition, knowledge        process  communication                quantity, amount  event, happening              relation  feeling, emotion               shape  food                                state, condition  group, collection               substance  location, place                  time motive  The BT/NT relation in standard thesauri is refined in WordNet into two types of relations, hypernymy and meronymy. The former relation plays a dominant role, allowing inheritance of various properties of parent words by their children:  Much attention has been devoted to hyponymy/hypernymy (variously called subordination/superordination, subset/superset, or the ISA relation).... A hyponym inherits all the features of the more generic concept and adds at least one feature that distinguishes it from its superordinate and from any other hyponyms of that superordinate. This convention provides the central organizing principle for the nouns in WordNet. [Fellbaum, 1998, p. 8]  This hypernymy relation connects virtually all the words into a forest of  trees rooted on a very restricted set of "unique beginners." In the case of nouns, the top-level categories are those shown in Table 6.5; those for verbs are Table 6.6.  The final category of stative verbs is used to capture the distinction  between the majority of active verbs and those (e.g., SUFFICE, BELONG, RESEMBLE) reflecting state characteristics.  WordNet also represents roughly the opposite of the synonym relation with the antonymy relation. Defining this logically proves more 216       FINDING OUT ABOUT  TABLE 6.6 WordNet's Top-Level Verb Categories  bodily care and functions creation  change emotion  cognition motion  communication perception  competition possession  consumption social interaction  contact weather  stative   difficult, and Miller is forced to simply equate it with human subjects' typical responses:  Antonymy is a lexical relation between word forms, not a semantic relation between word meanings___The strongest psy cholinguistic indication that two words are antonyms is that each is given on a word association test as the most common response to the other. For example, if people are asked for the first word they think of (other than the probe word itself) when they hear VICTORY, most will respond DEFEAT; when they hear DEFEAT most will respond VICTORY. [Fellbaum, 1998, pp. 7, 24]  The use of the antonymy relation in WordNet is particularly interesting when applied to adjectives:  The semantic organization of descriptive adjectives is entirely different from that of nouns. Nothing like the hyponymic relation that generates nominal hierarchies is available for adjectives___The semantic organization of adjectives is more naturally thought of as an abstract hyperspace of N dimensions rather than as a hierarchical tree. [Fellbaum, 1998, p. 27]  First, WordNet distinguishes the bulk of adjectives, which are called descriptive adjectives (such as BIG, INTERESTING, POSSIBLE), from relational adjectives (PRESIDENTIAL, NUCLEAR) and INFERENCE BEYOND THE INDEX      217  Similarity Antonymy  FIGURE 6.15 Bipolar Organization of Adjectives in WordNet From [Fellbaum, 1998]. Reproduced with permission of MIT Press  reference-modifying adjectives (FORMER,  ALLEGED). They then find:  All descriptive adjectives have antonyms; those lacking direct antonyms have indirect antonyms, i.e., are synonyms of adjectives that have direct antonyms. [Fellbaum, 1998, p. 28]  An example of the resulting dumbbell-shaped bipolar organization is shown in Figure 6.15.  Voorhees was one of the first to explore how WordNet data can be harnessed as part of a search engine [Voorhees, 1993].   