 5.2.2.2 Inverse Document Frequency  The basic algorithm is improved by taking into consideration the frequency of occurrence of the processing token in the database. One of the objectives of indexing an item is to discriminate the semantics of that item from other items in the database. If the token "computer" occurs in every item in the database, its value representing the semantics of an item may be less useful compared to a processing token that occurs in only a subset of the items in the database. The term "computer" represents a concept used in an item, but it does not help a user find the specific information being sought since it returns the complete database. This leads to the general statement enhancing weighting algorithms that the weight assigned to an item should be inversely proportional to the frequency of occurrence of an item in the database. This algorithm is called inverse document frequency (IDF). The un-normalized weighting formula is:  WEIGHT, = TFy * [Log2(n) - Log2(IFj) + 1]  where WEIGHTtj is the vector weight that is assigned to term "j" in item "i," TFy (term frequency) is the frequency of term "j" in item "i" , "n" is the number of items in the database and IFj (item frequency or document frequency) is the number of items in the database that have term "j" in them. A negative log is the same as dividing by the log value, thus the basis for the name of the algorithm. Figure 5.4 demonstrates the impact of using this weighting algorithm. The term "refinery'1 has the highest frequency in the new item (10 occurrences). But it has a normalized weight of 20 which is less than the normalized weight of "Mexico." This change in relative importance between "Mexico" and "refinery" from the unnormalized to normalized vectors is due to an adjustment caused by "refinery" already existing in 50 per cent of the database versus "Mexico" which is found in 6.25 per cent of the items.  The major factor of the formula for a particular term is (Log2(n) Log2(IFj)). The value for IF can vary from UP to wn." At X" the term is found in every item in the database and the factor becomes (Log2(n) - Loga(n)) = I. As the number of items a term is found in decreases, the value of the denominator decreases eventually approaching the value Log2(l) which is close to I. The weight assigned to the term in the item varies from Tf^ * (! + I) to Tf^ * (~ Log2(n)). The effect of this factor can be too great as the number of items that a term is found in becomes small. To compensate for this, the INQUERY system at the University of Massachusetts normalizes this factor by taking an additional log value. Automatic Indexing                                                                                    117  Assume that the term "oil" is found in 128 items, "Mexico" is found in 16 items and "refinery" is found in 1024 items. If a new item arrives with all three terms in it, "oil" found 4 times, "Mexico" found 8 times, and "refinery found 10 times and there are 2048 items in the total database, Figure 5.4 shows the weight calculations using inverse document frequency.  Using a simple unnormalized term frequency, the item vector is (4, 8, 10) Using inverse document frequency the following calculations apply:  Weighty = 4 * (Log2(2048) - Log2(128) +l) = 4*(ll-7+l) = 20 WeightMex.cc = 8 * (Log2(2048) - Log2(16) +l)=8*(ll-4+l)= 64  ight*^ = 10 * (Log2(2048) - Log2(1024) + 1) = 10*(ll - 10+ 1 ) = 20  with the resultant inverse document frequency item vector = (20, 64, 20) Figure 5.4 Example of Inverse Document Frequency  The value of "n" and IF, vary as items are added and deleted from the database. To implement this algorithm in a dynamically changing system, the physical index only stores the frequency of occurrence of the terms in an item (usually with their word location) and the IDF factor is calculated dynamically at retrieval time. The required information can easily be determined from an inversion list for a search term that is retrieved and a global variable on the number of items in the database.   