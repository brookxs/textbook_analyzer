<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Clustering in information retrieval</title> 
  <meta name="description" content="Clustering in information retrieval" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="next" href="problem-statement-1.html" /> 
  <link rel="previous" href="flat-clustering-1.html" /> 
  <link rel="up" href="flat-clustering-1.html" /> 
  <link rel="next" href="problem-statement-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html4157" href="problem-statement-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html4151" href="flat-clustering-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html4145" href="flat-clustering-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html4153" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html4155" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html4158" href="problem-statement-1.html">Problem statement</a> 
  <b> Up:</b> 
  <a name="tex2html4152" href="flat-clustering-1.html">Flat clustering</a> 
  <b> Previous:</b> 
  <a name="tex2html4146" href="flat-clustering-1.html">Flat clustering</a> &nbsp; 
  <b> <a name="tex2html4154" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html4156" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h1><a name="SECTION002110000000000000000"> Clustering in information retrieval</a> </h1> The 
  <a name="24124"></a> 
  <i>cluster hypothesis</i> states the fundamental assumption we make when using clustering in information retrieval. 
  <blockquote> 
   <b>Cluster hypothesis.</b> Documents in the same cluster behave similarly with respect to relevance to information needs. 
  </blockquote> The hypothesis states that if there is a document from a cluster that is relevant to a search request, then it is likely that other documents from the same cluster are also relevant. This is because clustering puts together documents that share many terms. The cluster hypothesis essentially is the contiguity hypothesis in Chapter 
  <a href="vector-space-classification-1.html#ch:vectorclass">14</a> (page 
  <a href="vector-space-classification-1.html#p:contiguity">14</a> ). In both cases, we posit that similar documents behave similarly with respect to relevance. 
  <p> <a name="sec:clusteringinir"></a> <a name="p:clusteringinir"></a> <br /></p> 
  <p></p> 
  <div align="CENTER"> 
   <a name="24145"></a> 
   <table> 
    <caption> 
     <strong>Table 16.1:</strong> Some applications of clustering in information retrieval. 
    </caption> 
    <tbody> 
     <tr> 
      <td> 
       <table cellpadding="3" border="1"> 
        <tbody> 
         <tr> 
          <td align="LEFT">Application</td> 
          <td align="LEFT" valign="TOP" width="57">What is</td> 
          <td align="LEFT" valign="TOP" width="119">Benefit</td> 
          <td align="LEFT" valign="TOP" width="111">Example</td> 
         </tr> 
         <tr> 
          <td align="LEFT">&nbsp;</td> 
          <td align="LEFT" valign="TOP" width="57">clustered?</td> 
          <td align="LEFT" valign="TOP" width="119">&nbsp;</td> 
          <td align="LEFT" valign="TOP" width="111">&nbsp;</td> 
         </tr> 
         <tr> 
          <td align="LEFT">Search result clustering</td> 
          <td align="LEFT" valign="TOP" width="57">search results</td> 
          <td align="LEFT" valign="TOP" width="119">more effective information presentation to user</td> 
          <td align="LEFT" valign="TOP" width="111">Figure <a href="#fig:clustfg1">16.2</a></td> 
         </tr> 
         <tr> 
          <td align="LEFT">Scatter-Gather</td> 
          <td align="LEFT" valign="TOP" width="57">(subsets of) collection</td> 
          <td align="LEFT" valign="TOP" width="119">alternative user interface: ``search without typing''</td> 
          <td align="LEFT" valign="TOP" width="111">Figure <a href="#fig:scatter">16.3</a></td> 
         </tr> 
         <tr> 
          <td align="LEFT">Collection clustering</td> 
          <td align="LEFT" valign="TOP" width="57">collection</td> 
          <td align="LEFT" valign="TOP" width="119">effective information presentation for exploratory browsing</td> 
          <td align="LEFT" valign="TOP" width="111"><a href="bibliography-1.html#mckeown02news">McKeown et&nbsp;al. (2002)</a>, <tt><a name="tex2html176" href="http://news.google.com">http://news.google.com</a></tt></td> 
         </tr> 
         <tr> 
          <td align="LEFT">Language modeling</td> 
          <td align="LEFT" valign="TOP" width="57">collection</td> 
          <td align="LEFT" valign="TOP" width="119">increased precision and/or recall</td> 
          <td align="LEFT" valign="TOP" width="111"><a href="bibliography-1.html#liu04cluster">Liu and Croft (2004)</a></td> 
         </tr> 
         <tr> 
          <td align="LEFT">Cluster-based retrieval</td> 
          <td align="LEFT" valign="TOP" width="57">collection</td> 
          <td align="LEFT" valign="TOP" width="119">higher efficiency: faster search</td> 
          <td align="LEFT" valign="TOP" width="111"><a href="bibliography-1.html#salton71cluster">Salton (1971a)</a></td> 
         </tr> 
        </tbody> 
       </table> <a name="tab:clusttb1"></a> <a name="p:clusttb1"></a> </td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <p></p> 
  <br /> 
  <p> Table <a href="#tab:clusttb1">16.1</a> shows some of the main applications of clustering in information retrieval. They differ in the set of documents that they cluster - search results, collection or subsets of the collection - and the aspect of an information retrieval system they try to improve - user experience, user interface, effectiveness or efficiency of the search system. But they are all based on the basic assumption stated by the cluster hypothesis. </p> 
  <p> </p> 
  <div align="CENTER"> 
   <p><a name="fig:clustfg1"></a><a name="p:clustfg1"></a></p> 
   <img width="678" height="368" align="BOTTOM" border="0" src="img1388.png" alt="\includegraphics[width=15cm]{clust01.eps}" /> Clustering of search results to improve recall. None of the top hits cover the animal sense of jaguar, but users can easily access it by clicking on the cat cluster in the Clustered Results panel on the left (third arrow from the top). 
  </div> 
  <p> The first application mentioned in Table <a href="#tab:clusttb1">16.1</a> is <a name="24160"></a> <i>search result clustering</i> where by <a name="24162"></a> <i>search results</i> we mean the documents that were returned in response to a query. The default presentation of search results in information retrieval is a simple list. Users scan the list from top to bottom until they have found the information they are looking for. Instead, search result clustering clusters the search results, so that similar documents appear together. It is often easier to scan a few coherent groups than many individual documents. This is particularly useful if a search term has different word senses. The example in Figure <a href="#fig:clustfg1">16.2</a> is jaguar. Three frequent senses on the web refer to the car, the animal and an Apple operating system. The Clustered Results panel returned by the Viv&iacute;simo search engine (<tt><a name="tex2html178" href="http://vivisimo.com">http://vivisimo.com</a></tt>) can be a more effective user interface for understanding what is in the search results than a simple list of documents. </p> 
  <p> </p> 
  <div align="CENTER"> 
   <p><a name="fig:scatter"></a><a name="p:scatter"></a></p> 
   <img width="588" height="427" align="BOTTOM" border="0" src="img1389.png" alt="\includegraphics[width=13cm]{clust02.eps}" />An example of a user session in Scatter-Gather. A collection of New York Times news stories is clustered (``scattered'') into eight clusters (top row). The user manually 
   <i>gathers</i> three of these into a smaller collection International Stories and performs another scattering operation. This process repeats until a small cluster with relevant documents is found (e.g., Trinidad). 
  </div> 
  <p> A better user interface is also the goal of <a name="24178"></a> <i>Scatter-Gather</i> , the second application in Table <a href="#tab:clusttb1">16.1</a> . Scatter-Gather clusters the whole collection to get groups of documents that the user can select or <i>gather</i>. The selected groups are merged and the resulting set is again clustered. This process is repeated until a cluster of interest is found. An example is shown in Figure <a href="#fig:scatter">16.3</a> . </p> 
  <p> Automatically generated clusters like those in Figure <a href="#fig:scatter">16.3</a> are not as neatly organized as a manually constructed hierarchical tree like the Open Directory at <tt><a name="tex2html179" href="http://dmoz.org">http://dmoz.org</a></tt>. Also, finding descriptive labels for clusters automatically is a difficult problem (Section <a href="cluster-labeling-1.html#sec:clusterlabeling">17.7</a> , page <a href="cluster-labeling-1.html#p:clusterlabeling">17.7</a> ). But cluster-based navigation is an interesting alternative to keyword searching, the standard information retrieval paradigm. This is especially true in scenarios where users prefer browsing over searching because they are unsure about which search terms to use. </p> 
  <p> As an alternative to the user-mediated iterative clustering in Scatter-Gather, we can also compute a static hierarchical clustering of a collection that is not influenced by user interactions (``Collection clustering'' in Table <a href="#tab:clusttb1">16.1</a> ). Google News and its precursor, the Columbia NewsBlaster system, are examples of this approach. In the case of news, we need to frequently recompute the clustering to make sure that users can access the latest breaking stories. Clustering is well suited for access to a collection of news stories since news reading is not really search, but rather a process of selecting a subset of stories about recent events. </p> 
  <p> The fourth application of clustering exploits the cluster hypothesis directly for improving search results, based on a clustering of the entire collection. We use a standard inverted index to identify an initial set of documents that match the query, but we then add other documents from the same clusters even if they have low similarity to the query. For example, if the query is car and several car documents are taken from a cluster of automobile documents, then we can add documents from this cluster that use terms other than car (automobile, vehicle etc). This can increase recall since a group of documents with high mutual similarity is often relevant as a whole. </p> 
  <p> More recently this idea has been used for language modeling. Equation <a href="estimating-the-query-generation-probability-1.html#eqn:lgmodelmix">102</a> , <a name="p:clusterlgmodel"></a> page <a href="estimating-the-query-generation-probability-1.html#p:lgmodelmix">102</a> , showed that to avoid sparse data problems in the language modeling approach to IR, the model of document <img width="12" height="31" align="MIDDLE" border="0" src="img354.png" alt="$d$" /> can be interpolated with a collection model. But the collection contains many documents with terms untypical of <img width="12" height="31" align="MIDDLE" border="0" src="img354.png" alt="$d$" />. By replacing the collection model with a model derived from <img width="12" height="31" align="MIDDLE" border="0" src="img354.png" alt="$d$" />'s cluster, we get more accurate estimates of the occurrence probabilities of terms in <img width="12" height="31" align="MIDDLE" border="0" src="img354.png" alt="$d$" />. </p> 
  <p> Clustering can also speed up search. As we saw in Section <a href="queries-as-vectors-1.html#sec:queryvector">6.3.2</a> (<a name="p:cluster4fastsearch"></a> page <a href="queries-as-vectors-1.html#p:queryvector">6.3.2</a> ) search in the vector space model amounts to finding the nearest neighbors to the query. The inverted index supports fast nearest-neighbor search for the standard IR setting. However, sometimes we may not be able to use an inverted index efficiently, e.g., in latent semantic indexing (Chapter <a href="matrix-decompositions-and-latent-semantic-indexing-1.html#ch:lsi">18</a> ). In such cases, we could compute the similarity of the query to every document, but this is slow. The cluster hypothesis offers an alternative: Find the clusters that are closest to the query and only consider documents from these clusters. Within this much smaller set, we can compute similarities exhaustively and rank documents in the usual way. Since there are many fewer clusters than documents, finding the closest cluster is fast; and since the documents matching a query are all similar to each other, they tend to be in the same clusters. While this algorithm is inexact, the expected decrease in search quality is small. This is essentially the application of clustering that was covered in Section <a href="cluster-pruning-1.html#sec:clusterpruning">7.1.6</a> (page <a href="cluster-pruning-1.html#p:clusterpruning">7.1.6</a> ). </p> 
  <p> <b>Exercises.</b> </p> 
  <ul> 
   <li>Define two documents as similar if they have at least two proper names like Clinton or Sarkozy in common. Give an example of an information need and two documents, for which the cluster hypothesis does <i>not</i> hold for this notion of similarity. <p> </p></li> 
   <li>Make up a simple one-dimensional example (i.e. points on a line) with two clusters where the inexactness of cluster-based retrieval shows up. In your example, retrieving clusters close to the query should do worse than direct nearest neighbor search. <p> </p></li> 
  </ul> 
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html4157" href="problem-statement-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html4151" href="flat-clustering-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html4145" href="flat-clustering-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html4153" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html4155" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html4158" href="problem-statement-1.html">Problem statement</a> 
  <b> Up:</b> 
  <a name="tex2html4152" href="flat-clustering-1.html">Flat clustering</a> 
  <b> Previous:</b> 
  <a name="tex2html4146" href="flat-clustering-1.html">Flat clustering</a> &nbsp; 
  <b> <a name="tex2html4154" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html4156" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>  
 </body>
</html>