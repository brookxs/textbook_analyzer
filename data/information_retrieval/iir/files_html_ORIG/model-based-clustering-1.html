<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Model-based clustering</title> 
  <meta name="description" content="Model-based clustering" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="next" href="references-and-further-reading-16.html" /> 
  <link rel="previous" href="k-means-1.html" /> 
  <link rel="up" href="flat-clustering-1.html" /> 
  <link rel="next" href="references-and-further-reading-16.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html4252" href="references-and-further-reading-16.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html4246" href="flat-clustering-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html4240" href="cluster-cardinality-in-k-means-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html4248" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html4250" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html4253" href="references-and-further-reading-16.html">References and further reading</a> 
  <b> Up:</b> 
  <a name="tex2html4247" href="flat-clustering-1.html">Flat clustering</a> 
  <b> Previous:</b> 
  <a name="tex2html4241" href="cluster-cardinality-in-k-means-1.html">Cluster cardinality in K-means</a> &nbsp; 
  <b> <a name="tex2html4249" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html4251" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h1><a name="SECTION002150000000000000000"></a> <a name="sec:modelclustering"></a> <a name="p:modelclustering"></a> <br /> Model-based clustering </h1> 
  <p> In this section, we describe a generalization of <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means, the EM algorithm. It can be applied to a larger variety of document representations and distributions than <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means. </p>
  <p> In <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means, we attempt to find centroids that are good representatives. We can view the set of <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" /> centroids as a model that generates the data. Generating a document in this model consists of first picking a centroid at random and then adding some noise. If the noise is normally distributed, this procedure will result in clusters of spherical shape. <a name="24900"></a> <i>Model-based clustering</i> assumes that the data were generated by a model and tries to recover the original model from the data. The model that we recover from the data then defines clusters and an assignment of documents to clusters. </p>
  <p> A commonly used criterion for estimating the model parameters is maximum likelihood. In <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means, the quantity 
   <!-- MATH
 $\exp(-\mbox{RSS})$
 --> <img width="83" height="33" align="MIDDLE" border="0" src="img1482.png" alt="$\exp(-\mbox{RSS})$" /> is proportional to the likelihood that a particular model (i.e., a set of centroids) generated the data. For <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means, maximum likelihood and minimal RSS are equivalent criteria. We denote the model parameters by <img width="17" height="32" align="MIDDLE" border="0" src="img65.png" alt="$\Theta$" />. In <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means, 
   <!-- MATH
 $\Theta = \{ \vec{\mu}_1, \ldots ,\vec{\mu}_K \}$
 --> <img width="126" height="33" align="MIDDLE" border="0" src="img1483.png" alt="$\Theta = \{ \vec{\mu}_1, \ldots ,\vec{\mu}_K \}$" />. </p>
  <p> More generally, the maximum likelihood criterion is to select the parameters <img width="17" height="32" align="MIDDLE" border="0" src="img65.png" alt="$\Theta$" /> that maximize the log-likelihood of generating the data <img width="17" height="32" align="MIDDLE" border="0" src="img1484.png" alt="$D$" />: <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
\Theta  = \argmax_{\Theta}  L(D|\Theta)
= 
\argmax_{\Theta} \log \prod_{n=1}^N P(d_n | \Theta) 
=
\argmax_{\Theta} \sum_{n=1}^N \log P(d_n| \Theta)
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="525" height="52" border="0" src="img1485.png" alt="\begin{displaymath}
\Theta = \argmax_{\Theta} L(D\vert\Theta)
=
\argmax_{\Theta...
...heta)
=
\argmax_{\Theta} \sum_{n=1}^N \log P(d_n\vert \Theta)
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (198)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> 
  <img width="58" height="33" align="MIDDLE" border="0" src="img1486.png" alt="$L(D\vert\Theta)$" /> is the objective function that measures the goodness of the clustering. Given two clusterings with the same number of clusters, we prefer the one with higher 
  <img width="58" height="33" align="MIDDLE" border="0" src="img1486.png" alt="$L(D\vert\Theta)$" />. 
  <p> This is the same approach we took in Chapter <a href="language-models-for-information-retrieval-1.html#ch:lmodels">12</a> (page <a href="finite-automata-and-language-models-1.html#p:generativemodel">12.1.1</a> ) for language modeling and in Section <a href="the-text-classification-problem-1.html#sec:classificationproblem">13.1</a> (page <a href="properties-of-naive-bayes-1.html#p:generativemodel2">13.4</a> ) for text classification. In text classification, we chose the class that maximizes the likelihood of generating a particular document. Here, we choose the clustering <img width="17" height="32" align="MIDDLE" border="0" src="img65.png" alt="$\Theta$" /> that maximizes the likelihood of generating a given set of documents. Once we have <img width="17" height="32" align="MIDDLE" border="0" src="img65.png" alt="$\Theta$" />, we can compute an assignment probability 
   <!-- MATH
 $P(d|\omega_k;\Theta)$
 --> <img width="80" height="33" align="MIDDLE" border="0" src="img1487.png" alt="$P(d\vert\omega_k;\Theta)$" /> for each document-cluster pair. This set of assignment probabilities defines a soft clustering. </p>
  <p> An example of a soft assignment is that a document about Chinese cars may have a fractional membership of 0.5 in each of the two clusters China and automobiles, reflecting the fact that both topics are pertinent. A hard clustering like <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means cannot model this simultaneous relevance to two topics. </p>
  <p> Model-based clustering provides a framework for incorporating our knowledge about a domain. <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means and the hierarchical algorithms in Chapter <a href="hierarchical-clustering-1.html#ch:hierclust">17</a> make fairly rigid assumptions about the data. For example, clusters in <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means are assumed to be spheres. Model-based clustering offers more flexibility. The clustering model can be adapted to what we know about the underlying distribution of the data, be it Bernoulli (as in the example in Table <a href="#tab:clusttb4">16.3</a> ), Gaussian with non-spherical variance (another model that is important in document clustering) or a member of a different family. </p>
  <p> A commonly used algorithm for model-based clustering is the <a name="24926"></a> <i>Expectation-Maximization algorithm</i> or <a name="24928"></a> <i>EM algorithm</i> . EM clustering is an iterative algorithm that maximizes <img width="58" height="33" align="MIDDLE" border="0" src="img1486.png" alt="$L(D\vert\Theta)$" />. EM can be applied to many different types of probabilistic modeling. We will work with a mixture of multivariate Bernoulli distributions here, the distribution we know from Section <a href="the-binary-independence-model-1.html#sec:bim">11.3</a> (page <a href="the-binary-independence-model-1.html#p:bim">11.3</a> ) and Section <a href="the-bernoulli-model-1.html#sec:twomodels">13.3</a> (page <a href="the-bernoulli-model-1.html#p:twomodels">13.3</a> ): <br /> </p>
  <div align="CENTER">
   <a name="emdocprob"></a> 
   <!-- MATH
 \begin{eqnarray}
P(d| \omega_k ; \Theta) = 
\left( \prod_{\tcword_m \in d} q_{mk} \right)
\left( \prod_{\tcword_m \notin d} (1-q_{mk}) \right)
\end{eqnarray}
 --> 
   <table align="CENTER" cellpadding="0" width="100%"> 
    <tbody>
     <tr valign="MIDDLE">
      <td nowrap="" align="RIGHT"><img width="303" height="64" align="MIDDLE" border="0" src="img1488.png" alt="$\displaystyle P(d\vert \omega_k ; \Theta) =
\left( \prod_{\tcword_m \in d} q_{mk} \right)
\left( \prod_{\tcword_m \notin d} (1-q_{mk}) \right)$" /></td> 
      <td>&nbsp;</td> 
      <td>&nbsp;</td> 
      <td width="10" align="RIGHT"> (199)</td>
     </tr> 
    </tbody>
   </table>
  </div> 
  <br clear="ALL" />
  <p></p> where 
  <!-- MATH
 $\Theta = \{ \Theta_1,\ldots,\Theta_K \}$
 --> 
  <img width="133" height="33" align="MIDDLE" border="0" src="img1489.png" alt="$\Theta = \{ \Theta_1,\ldots,\Theta_K \} $" />, 
  <!-- MATH
 $\Theta_k = (\alpha_k , q_{1k}, \ldots, q_{Mk})$
 --> 
  <img width="162" height="33" align="MIDDLE" border="0" src="img1490.png" alt="$\Theta_k = (\alpha_k , q_{1k}, \ldots, q_{Mk})$" />, and 
  <!-- MATH
 $q_{mk} = P(\wvar_m=1 | \omega_k)$
 --> 
  <img width="151" height="33" align="MIDDLE" border="0" src="img1491.png" alt="$q_{mk} = P(\wvar_m=1 \vert \omega_k)$" /> are the parameters of the model.
  <a name="tex2html184" href="footnode.html#foot25265"><sup><img align="BOTTOM" border="1" alt="[*]" src="http://nlp.stanford.edu/IR-book/html/icons/footnote.png" /></sup></a>
  <!-- MATH
 $P(\wvar_m=1|\omega_k)$
 --> 
  <img width="104" height="33" align="MIDDLE" border="0" src="img1494.png" alt="$P(\wvar_m=1\vert\omega_k)$" /> is the probability that a document from cluster 
  <img width="22" height="32" align="MIDDLE" border="0" src="img1396.png" alt="$\omega_k$" /> contains term 
  <img width="20" height="32" align="MIDDLE" border="0" src="img1493.png" alt="$\tcword_m$" />. The probability 
  <img width="19" height="32" align="MIDDLE" border="0" src="img1495.png" alt="$\alpha_k$" /> is the prior of cluster 
  <img width="22" height="32" align="MIDDLE" border="0" src="img1396.png" alt="$\omega_k$" />: the probability that a document 
  <img width="12" height="31" align="MIDDLE" border="0" src="img354.png" alt="$d$" /> is in 
  <img width="22" height="32" align="MIDDLE" border="0" src="img1396.png" alt="$\omega_k$" /> if we have no information about 
  <img width="12" height="31" align="MIDDLE" border="0" src="img354.png" alt="$d$" />. 
  <p> The mixture model then is: <br /> </p>
  <div align="CENTER">
   <a name="emdocprob2"></a> 
   <!-- MATH
 \begin{eqnarray}
P(d| \Theta) = 
\sum_{k=1}^{K} \alpha_k 
\left( \prod_{\tcword_m \in d} q_{mk} \right)
\left( \prod_{\tcword_m \notin d} (1-q_{mk}) \right)
\end{eqnarray}
 --> 
   <table align="CENTER" cellpadding="0" width="100%"> 
    <tbody>
     <tr valign="MIDDLE">
      <td nowrap="" align="RIGHT"><img width="321" height="64" align="MIDDLE" border="0" src="img1496.png" alt="$\displaystyle P(d\vert \Theta) =
\sum_{k=1}^{K} \alpha_k
\left( \prod_{\tcword_m \in d} q_{mk} \right)
\left( \prod_{\tcword_m \notin d} (1-q_{mk}) \right)$" /></td> 
      <td>&nbsp;</td> 
      <td>&nbsp;</td> 
      <td width="10" align="RIGHT"> (200)</td>
     </tr> 
    </tbody>
   </table>
  </div> 
  <br clear="ALL" />
  <p></p> In this model, we generate a document by first picking a cluster 
  <img width="11" height="31" align="MIDDLE" border="0" src="img20.png" alt="$k$" /> with probability 
  <img width="19" height="32" align="MIDDLE" border="0" src="img1495.png" alt="$\alpha_k$" /> and then generating the terms of the document according to the parameters 
  <img width="28" height="32" align="MIDDLE" border="0" src="img1497.png" alt="$q_{mk}$" />. Recall that the document representation of the multivariate Bernoulli is a vector of 
  <img width="20" height="32" align="MIDDLE" border="0" src="img186.png" alt="$M$" /> Boolean values (and not a real-valued vector). 
  <p> How do we use EM to infer the parameters of the clustering from the data? That is, how do we choose parameters <img width="17" height="32" align="MIDDLE" border="0" src="img65.png" alt="$\Theta$" /> that maximize <img width="58" height="33" align="MIDDLE" border="0" src="img1486.png" alt="$L(D\vert\Theta)$" />? EM is similar to <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means in that it alternates between an <a name="24957"></a> <i>expectation step</i> , corresponding to reassignment, and a <a name="24959"></a> <i>maximization step</i> , corresponding to recomputation of the parameters of the model. The parameters of <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means are the centroids, the parameters of the instance of EM in this section are the <img width="19" height="32" align="MIDDLE" border="0" src="img1495.png" alt="$\alpha_k$" /> and <img width="28" height="32" align="MIDDLE" border="0" src="img1497.png" alt="$q_{mk}$" />. </p>
  <p> The maximization step recomputes the conditional parameters <img width="28" height="32" align="MIDDLE" border="0" src="img1497.png" alt="$q_{mk}$" /> and the priors <img width="19" height="32" align="MIDDLE" border="0" src="img1495.png" alt="$\alpha_k$" /> as follows: </p>
  <p> <br /> </p>
  <div align="CENTER">
   <a name="eqn:wgc"></a> 
   <!-- MATH
 \begin{eqnarray}
\mbox{\bf Maximization step:} \quad
q_{mk} = \frac{\sum_{n=1}^N r_{nk} I( \tcword_m \in d_n )}
{\sum_{n=1}^N  r_{nk}} \quad \alpha_k = \frac{\sum_{n=1}^N r_{nk}}{N}
\end{eqnarray}
 --> 
   <table align="CENTER" cellpadding="0" width="100%"> 
    <tbody>
     <tr valign="MIDDLE">
      <td nowrap="" align="RIGHT"><img width="458" height="61" align="MIDDLE" border="0" src="img1498.png" alt="$\displaystyle \mbox{\bf Maximization step:} \quad
q_{mk} = \frac{\sum_{n=1}^N r...
...\in d_n )}
{\sum_{n=1}^N r_{nk}} \quad \alpha_k = \frac{\sum_{n=1}^N r_{nk}}{N}$" /></td> 
      <td>&nbsp;</td> 
      <td>&nbsp;</td> 
      <td width="10" align="RIGHT"> (201)</td>
     </tr> 
    </tbody>
   </table>
  </div> 
  <br clear="ALL" />
  <p></p> where 
  <!-- MATH
 $I( \tcword_m \in d_n )=1$
 --> 
  <img width="108" height="33" align="MIDDLE" border="0" src="img1499.png" alt="$I( \tcword_m \in d_n )=1$" /> if 
  <!-- MATH
 $\tcword_m \in d_n$
 --> 
  <img width="56" height="31" align="MIDDLE" border="0" src="img1500.png" alt="$\tcword_m \in d_n$" /> and 0 otherwise and 
  <img width="24" height="32" align="MIDDLE" border="0" src="img1501.png" alt="$r_{nk}$" /> is the soft assignment of document 
  <img width="20" height="31" align="MIDDLE" border="0" src="img1502.png" alt="$d_n$" /> to cluster 
  <img width="11" height="31" align="MIDDLE" border="0" src="img20.png" alt="$k$" /> as computed in the preceding iteration. (We'll address the issue of initialization in a moment.) These are the maximum likelihood estimates for the parameters of the multivariate Bernoulli from Table 
  <a href="#tab:nbmodelcomparison">13.3</a> (page 
  <a href="#p:nbmodelcomparison">13.3</a> ) except that documents are assigned fractionally to clusters here. These maximum likelihood estimates maximize the likelihood of the data given the model. 
  <p> The expectation step computes the soft assignment of documents to clusters given the current parameters <img width="28" height="32" align="MIDDLE" border="0" src="img1497.png" alt="$q_{mk}$" /> and <img width="19" height="32" align="MIDDLE" border="0" src="img1495.png" alt="$\alpha_k$" />: </p>
  <p> <br /> </p>
  <div align="CENTER">
   <a name="eqn:emexpectation"></a> 
   <!-- MATH
 \begin{eqnarray}
{\bf Expectation \ step:} \quad
r_{nk} = \frac{ \alpha_k (\prod_{\tcword_m \in d_n} q_{mk})
(\prod_{\tcword_m \notin d_n} (1-q_{mk}))
}{\sum_{k=1}^{K} \alpha_k (\prod_{\tcword_m \in d_n} q_{mk})
(\prod_{\tcword_m \notin d_n} (1-q_{mk}))
}
\end{eqnarray}
 --> 
   <table align="CENTER" cellpadding="0" width="100%"> 
    <tbody>
     <tr valign="MIDDLE">
      <td nowrap="" align="RIGHT"><img width="471" height="57" align="MIDDLE" border="0" src="img1503.png" alt="$\displaystyle {\bf Expectation \ step:} \quad
r_{nk} = \frac{ \alpha_k (\prod_{...
... (\prod_{\tcword_m \in d_n} q_{mk})
(\prod_{\tcword_m \notin d_n} (1-q_{mk}))
}$" /></td> 
      <td>&nbsp;</td> 
      <td>&nbsp;</td> 
      <td width="10" align="RIGHT"> (202)</td>
     </tr> 
    </tbody>
   </table>
  </div> 
  <br clear="ALL" />
  <p></p> This expectation step applies and 
  <a href="#emdocprob2">200</a> to computing the likelihood that 
  <img width="22" height="32" align="MIDDLE" border="0" src="img1396.png" alt="$\omega_k$" /> generated document 
  <img width="20" height="31" align="MIDDLE" border="0" src="img1502.png" alt="$d_n$" />. It is the classification procedure for the multivariate Bernoulli in Table 
  <a href="#tab:nbmodelcomparison">13.3</a> . Thus, the expectation step is nothing else but Bernoulli Naive Bayes classification (including normalization, i.e. dividing by the denominator, to get a probability distribution over clusters). 
  <p> <br /></p>
  <p></p> 
  <div align="CENTER"> 
   <p> </p>
   <table cellpadding="3" border="1"> 
    <tbody>
     <tr>
      <td align="LEFT">(a)</td> 
      <td align="LEFT">docID</td> 
      <td align="LEFT">document text</td> 
      <td align="LEFT">docID</td> 
      <td align="LEFT">document text</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">1</td> 
      <td align="LEFT">hot chocolate cocoa beans</td> 
      <td align="LEFT">7</td> 
      <td align="LEFT">sweet sugar</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">2</td> 
      <td align="LEFT">cocoa ghana africa</td> 
      <td align="LEFT">8</td> 
      <td align="LEFT">sugar cane brazil</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">3</td> 
      <td align="LEFT">beans harvest ghana</td> 
      <td align="LEFT">9</td> 
      <td align="LEFT">sweet sugar beet</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">4</td> 
      <td align="LEFT">cocoa butter</td> 
      <td align="LEFT">10</td> 
      <td align="LEFT">sweet cake icing</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">5</td> 
      <td align="LEFT">butter truffles</td> 
      <td align="LEFT">11</td> 
      <td align="LEFT">cake black forest</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">6</td> 
      <td align="LEFT">sweet chocolate</td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">&nbsp;</td> 
     </tr> 
    </tbody>
   </table> 
   <p> <br /> <br /> </p>
   <p> </p>
   <table cellpadding="3" border="1"> 
    <tbody>
     <tr>
      <td align="LEFT">(b)</td> 
      <td align="LEFT">Parameter</td> 
      <td align="CENTER" colspan="8">Iteration of clustering</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0</td> 
      <td align="LEFT">1</td> 
      <td align="LEFT">2</td> 
      <td align="LEFT">3</td> 
      <td align="LEFT">4</td> 
      <td align="LEFT">5</td> 
      <td align="LEFT">15</td> 
      <td align="LEFT">25</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="19" height="32" align="MIDDLE" border="0" src="img1504.png" alt="$\alpha_1$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.50</td> 
      <td align="LEFT">0.45</td> 
      <td align="LEFT">0.53</td> 
      <td align="LEFT">0.57</td> 
      <td align="LEFT">0.58</td> 
      <td align="LEFT">0.54</td> 
      <td align="LEFT">0.45</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="26" height="32" align="MIDDLE" border="0" src="img1505.png" alt="$r_{1,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="26" height="32" align="MIDDLE" border="0" src="img1506.png" alt="$r_{2,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.50</td> 
      <td align="LEFT">0.79</td> 
      <td align="LEFT">0.99</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="26" height="32" align="MIDDLE" border="0" src="img1507.png" alt="$r_{3,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.50</td> 
      <td align="LEFT">0.84</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="26" height="32" align="MIDDLE" border="0" src="img1508.png" alt="$r_{4,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.50</td> 
      <td align="LEFT">0.75</td> 
      <td align="LEFT">0.94</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="26" height="32" align="MIDDLE" border="0" src="img1509.png" alt="$r_{5,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.50</td> 
      <td align="LEFT">0.52</td> 
      <td align="LEFT">0.66</td> 
      <td align="LEFT">0.91</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="26" height="32" align="MIDDLE" border="0" src="img1510.png" alt="$r_{6,1}$" /></td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">1.00</td> 
      <td align="LEFT">0.83</td> 
      <td align="LEFT">0.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="26" height="32" align="MIDDLE" border="0" src="img1511.png" alt="$r_{7,1}$" /></td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="26" height="32" align="MIDDLE" border="0" src="img1512.png" alt="$r_{8,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="26" height="32" align="MIDDLE" border="0" src="img1513.png" alt="$r_{9,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="32" height="32" align="MIDDLE" border="0" src="img1514.png" alt="$r_{10,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.50</td> 
      <td align="LEFT">0.40</td> 
      <td align="LEFT">0.14</td> 
      <td align="LEFT">0.01</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="32" height="32" align="MIDDLE" border="0" src="img1515.png" alt="$r_{11,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.50</td> 
      <td align="LEFT">0.57</td> 
      <td align="LEFT">0.58</td> 
      <td align="LEFT">0.41</td> 
      <td align="LEFT">0.07</td> 
      <td align="LEFT">0.00</td> 
      <td align="LEFT">0.00</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="54" height="32" align="MIDDLE" border="0" src="img1516.png" alt="$q_{africa,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.100</td> 
      <td align="LEFT">0.134</td> 
      <td align="LEFT">0.158</td> 
      <td align="LEFT">0.158</td> 
      <td align="LEFT">0.169</td> 
      <td align="LEFT">0.200</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="54" height="32" align="MIDDLE" border="0" src="img1517.png" alt="$q_{africa,2}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.083</td> 
      <td align="LEFT">0.042</td> 
      <td align="LEFT">0.001</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="51" height="32" align="MIDDLE" border="0" src="img1518.png" alt="$q_{brazil,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="52" height="32" align="MIDDLE" border="0" src="img1519.png" alt="$q_{brazil,2}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.167</td> 
      <td align="LEFT">0.195</td> 
      <td align="LEFT">0.213</td> 
      <td align="LEFT">0.214</td> 
      <td align="LEFT">0.196</td> 
      <td align="LEFT">0.167</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="49" height="32" align="MIDDLE" border="0" src="img1520.png" alt="$q_{cocoa,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.400</td> 
      <td align="LEFT">0.432</td> 
      <td align="LEFT">0.465</td> 
      <td align="LEFT">0.474</td> 
      <td align="LEFT">0.508</td> 
      <td align="LEFT">0.600</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="50" height="32" align="MIDDLE" border="0" src="img1521.png" alt="$q_{cocoa,2}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.167</td> 
      <td align="LEFT">0.090</td> 
      <td align="LEFT">0.014</td> 
      <td align="LEFT">0.001</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="51" height="32" align="MIDDLE" border="0" src="img1522.png" alt="$q_{sugar,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
      <td align="LEFT">0.000</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="51" height="32" align="MIDDLE" border="0" src="img1523.png" alt="$q_{sugar,2}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">1.000</td> 
      <td align="LEFT">0.500</td> 
      <td align="LEFT">0.585</td> 
      <td align="LEFT">0.640</td> 
      <td align="LEFT">0.642</td> 
      <td align="LEFT">0.589</td> 
      <td align="LEFT">0.500</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="50" height="32" align="MIDDLE" border="0" src="img1524.png" alt="$q_{sweet,1}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">1.000</td> 
      <td align="LEFT">0.300</td> 
      <td align="LEFT">0.238</td> 
      <td align="LEFT">0.180</td> 
      <td align="LEFT">0.159</td> 
      <td align="LEFT">0.153</td> 
      <td align="LEFT">0.000</td> 
     </tr> 
     <tr>
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT"><img width="50" height="32" align="MIDDLE" border="0" src="img1525.png" alt="$q_{sweet,2}$" /></td> 
      <td align="LEFT">&nbsp;</td> 
      <td align="LEFT">1.000</td> 
      <td align="LEFT">0.417</td> 
      <td align="LEFT">0.507</td> 
      <td align="LEFT">0.610</td> 
      <td align="LEFT">0.640</td> 
      <td align="LEFT">0.608</td> 
      <td align="LEFT">0.667</td> 
     </tr> 
    </tbody>
   </table> The EM clustering algorithm.The table shows a set of documents (a) and parameter values for selected iterations during EM clustering (b). Parameters shown are prior 
   <img width="19" height="32" align="MIDDLE" border="0" src="img1504.png" alt="$\alpha_1$" />, soft assignment scores 
   <img width="27" height="32" align="MIDDLE" border="0" src="img1526.png" alt="$r_{n,1}$" /> (both omitted for cluster&nbsp;2), and lexical parameters 
   <img width="31" height="32" align="MIDDLE" border="0" src="img1527.png" alt="$q_{m,k}$" /> for a few terms. The authors initially assigned document&nbsp;6 to cluster&nbsp;1 and document&nbsp;7 to cluster&nbsp;2 (iteration 0). EM converges after 25 iterations. For smoothing, the 
   <img width="24" height="32" align="MIDDLE" border="0" src="img1501.png" alt="$r_{nk}$" /> in Equation&nbsp;
   <a href="#eqn:wgc">201</a> were replaced with 
   <!-- MATH
 $r_{nk}+\epsilon$
 --> 
   <img width="51" height="32" align="MIDDLE" border="0" src="img1528.png" alt="$r_{nk}+\epsilon$" /> where 
   <!-- MATH
 $\epsilon = 0.0001$
 --> 
   <img width="78" height="32" align="MIDDLE" border="0" src="img1529.png" alt="$\epsilon = 0.0001$" />. 
   <a name="tab:clusttb4"></a> 
   <a name="p:clusttb4"></a> 
  </div> 
  <br /> 
  <p> We clustered a set of 11 documents into two clusters using EM in Table <a href="#tab:clusttb4">16.3</a> . After convergence in iteration&nbsp;25, the first 5 documents are assigned to cluster&nbsp;1 (
   <!-- MATH
 $r_{i,1} = 1.00$
 --> <img width="74" height="32" align="MIDDLE" border="0" src="img1530.png" alt="$r_{i,1} = 1.00$" />) and the last 6 to cluster&nbsp;2 (<img width="74" height="32" align="MIDDLE" border="0" src="img1531.png" alt="$r_{i,1}=0.00$" />). Somewhat atypically, the final assignment is a hard assignment here. EM usually converges to a soft assignment. In iteration&nbsp;25, the prior <img width="19" height="32" align="MIDDLE" border="0" src="img1504.png" alt="$\alpha_1$" /> for cluster&nbsp;1 is 
   <!-- MATH
 $5/11 \approx 0.45$
 --> <img width="88" height="31" align="MIDDLE" border="0" src="img1532.png" alt="$5/11 \approx 0.45$" /> because 5 of the 11 documents are in cluster&nbsp;1. Some terms are quickly associated with one cluster because the initial assignment can ``spread'' to them unambiguously. For example, membership in cluster&nbsp;2 spreads from document 7 to document 8 in the first iteration because they share sugar (<img width="56" height="32" align="MIDDLE" border="0" src="img1533.png" alt="$r_{8,1}=0$" /> in iteration 1). </p>
  <p> For parameters of terms occurring in ambiguous contexts, convergence takes longer. Seed documents 6 and 7 both contain sweet. As a result, it takes 25 iterations for the term to be unambiguously associated with cluster 2. (<img width="80" height="32" align="MIDDLE" border="0" src="img1534.png" alt="$q_{sweet,1}=0$" /> in iteration 25.) </p>
  <p> Finding good seeds is even more critical for EM than for <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means. EM is prone to get stuck in local optima if the seeds are not chosen well. This is a general problem that also occurs in other applications of EM.<a name="tex2html185" href="footnode.html#foot25272"><sup><img align="BOTTOM" border="1" alt="[*]" src="http://nlp.stanford.edu/IR-book/html/icons/footnote.png" /></sup></a>Therefore, as with <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means, the initial assignment of documents to clusters is often computed by a different algorithm. For example, a hard <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means clustering may provide the initial assignment, which EM can then ``soften up.'' </p>
  <p> <b>Exercises.</b> </p>
  <ul> 
   <li>We saw above that the time complexity of <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means is <img width="79" height="33" align="MIDDLE" border="0" src="img1460.png" alt="$\Theta(IKNM)$" />. What is the time complexity of EM? <p> </p></li> 
  </ul>
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html4252" href="references-and-further-reading-16.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html4246" href="flat-clustering-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html4240" href="cluster-cardinality-in-k-means-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html4248" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html4250" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html4253" href="references-and-further-reading-16.html">References and further reading</a> 
  <b> Up:</b> 
  <a name="tex2html4247" href="flat-clustering-1.html">Flat clustering</a> 
  <b> Previous:</b> 
  <a name="tex2html4241" href="cluster-cardinality-in-k-means-1.html">Cluster cardinality in K-means</a> &nbsp; 
  <b> <a name="tex2html4249" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html4251" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>   
 </body>
</html>