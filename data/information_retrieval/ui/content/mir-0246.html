 12.8    Bibliographic Discussion Spatial Access Methods Structures and Algorithms For a recent, very thorough survey of spatial access methods, see [290]. For the introduction of R-trees, see the seminal paper by Guttman [330]. Among the numerous follow-up variations, the jR*-tree [69] seems to be one of the best performing methods, using the idea of deferred splitting with 'forced-reinsert,' thus achieving higher space utilization, and therefore more compact, shorter, and faster trees. Another strong contender is the Hilbert R-tree [427], which achieves even higher space utilization and often outperforms the JT-tree. A generalized framework and implementation for all these methods is the GiST tree [362] which is available, at the time of writing, at http://gist.cs.berkeley.edu:8000 /gist. With respect to algorithms, the range search is trivial in R-trees. Nearest neighbors queries require more careful record keeping, with a branch-and-bound algorithm (e.g., [686]). Spatial joins (e.g., 'find all pairs of points within distance £') have also attracted a lot of interest: see the filtering algorithms in [119] and the methods in [521] and [458]. Indexing high-dimensional address spaces has attracted a lot of recent interest: the TV-trees [519] adaptively use only a few of the available dimensions. The SR-trees [431] use spheres in conjunction to rectangles, as bounding regions. The more recent X-trees [83] gracefully switch to sequential scanning for extremely high dimensionalities. For the analysis of spatial access methods and selectivity estimation, the concept of "fractal dimension' has given very accurate results in every case it was tried: range queries [247], nearest neighbor queries [628], spatial joins [79]. quadtrees [245]. The idea behind the fractal dimension is to consider the intrinsic dimensionality of the given set of points. For example, consider the points on the diagonal of a 3D cube: their "embedding' dimensionality is E = 3: however, their intrinsic dimensionality is D = 1. Using the appropriate definition for the dimensionality, like the Hausdorff fractal dimension, or the correlation fractal 364        MULTIMEDIA IR: INDEXING AND SEARCHING dimension [712], it turns out that real data sets have a fractional dimensionality: the value is 1.1-1.2 for coastlines, ~2.7 for the brain surface of mammals, ´1.3 for the periphery of rain patches, ´1.7 for the end-points of road segments, to name but a few [247]. Metric Trees Finally, a class of access methods that operate on the distance function directly seems promising. These methods require only a distance function, and they typically build a cluster hierarchy, that is, a tree structure of 'spheres', which include the children spheres, and so on, recursively. This class includes the Burkhard-Keller methods [131], the Fixed-query trees [47], the GNAT trees [116], the MVP trees [112], and the M-trees [172]. The technology is still young: most of the above methods are designed for static data sets. On the positive side, they don't need feature extraction; on the negative side, they don't provide for visualization and data mining, like GEMINI and FastMap do (see Figure 12.10). Multimedia Indexing, DSP and Feature Extraction GEMINI ó Feature Extraction Probably the earliest paper that suggested feature extraction for fast indexing is [400], for approximate matching in shapes. The proof of the lower bounding lemma is in [249]. Algorithms for automatic feature extraction include the traditional, Multidimensional Scaling (MDS), see, e.g., [462]. MDS has attracted tremendous interest, but it is O(iV2), quadratic on the number of database objects N. Thus, it is impractical for large data sets. An O(N) alternative is the so-called FastMap [248], which was used to produce Figure 12.10. Time Sequences For additional, more elaborate distance functions, that include time-warping, see Chapter 8 or [706]. An indexing method with the time-warping distance function has recently been developed [840], using FastMap. For linear time sequence forecasting, see the classic book on the Box-Jenkins methodology [109]. For more recent, non-linear forecasting methods, see the intriguing volumes from the Santa-Fe Institute [149, 808]. Digital Signal Processing (DSP) Powerful tools for the analysis of time sequences and n-D signals in general include the traditional Fourier transform (see, e.g., [622]), the popular    discrete cosine transform, which is the basis for the JPEG image compression standard [802], and the more recent, and even more effective, wavelet transform (DWT) [689]. An excellent introduction to all these methods, as well as source code, is available in [051]. BIBLIOGRAPHIC DISCUSSION        365 Image Features and Similarity Functions There is a lot of work in machine vision on feature extraction and similarity measures. Classic references are e.g., [53, 224, 285]. A recent survey on image registration and image comparison methods is in [125]. The proof for quadratic distance bounding theorem of section 12.5 is in [244]. Other Applications of Multimedia Indexing There are numerous papers on indexing in multimedia databases. A small sample of them include the following: for time sequences allowing scaling or subpattern matching, see [305], [7], [246]. For voice and video see, e.g., [800]. For shapes see, e.g., [244]. For medical image databases see, e.g., [381], [454], [635]. For multimedia searching on the Web, see, e.g., [4, 733, 80, 714]. Data Mining Finally, there is a lot of work on traditional machine learning [565] and statistics (e.g., [408]).  