 5.5.7 Bayesian Networks  As will be discussed in great detail in Chapter 6, there are many types of information on which we might wish to base our retrieval. Most of this 176       FINDING OUT ABOUT  FIGURE 5.7 Interaction between Parental Influences  section has concerned probabilistic models for the crucial Index relation between keywords and documents, but we may wish to model other information probabilistically as well.  Bayesian networks (also known as inference or belief networks) are a modeling language within which many probabilistic relationships can be expressed as part of a common representation and used as part of a unified inference procedure [Pearl, 1988]. A Bayesian network is a graph in which nodes correspond to propositions and links correspond to conditional probabilistic dependencies between these propositions. A directed link from node p to node q is used to model the fact that p causes qgt; although other semantics (e.g., logical implication) are sometimes also used.  When representing interactions among n propositions, we must generally consider the possible dependency of each proposition on every other. To do this completely requires an exponential number of statistics, which is impractical for most situations and certainly if we attempt to model interactions between all the documents in our corpora and their keywords. Within Bayesian networks, this full set of statistics - the joint probability distribution - is replaced by a sparse representation only among those variables directly influencing one another. Interactions among indirectly related variables are then computed by propagating inference through a graph of these direct connections.  The key integration of probabilistic information across interacting variables is accomplished by specifying how each child node depends on the set of its parents' values. A table of conditional dependency probabilities specifies, for each possible value of each parent node, the probability of each of the child variable's value; see Figure 5.7. With these condiditional relationships specified for each node* querying a Bayesian network corresponds to placing prior probabilities on some elements of the network and then asking for the probability at other nodes.  One of the most comprehensive applications of Bayesian network representations to the propositions associated with FOA is due to Croft MATHEMATICAL FOUNDATIONS       177  FIGURE 5.8 Bayesian Network Representation for FOA  with Turtle and other students [Turtle, 1990; Turtle and Croft, 1990; Turtle and Croft, 1991; Turtle and Croft, 1992; Callan et al., 1995] and is shown in Figure 5.8. This graph shows four types of nodes: documents, keywords, queries, and a single information need node.^  This graph is rooted on the document nodes. To use this representation, a single document is "instantiated," meaning that we posit that only this one document is retrieved and we ask for the probability that the information need is satisfied. Given these estimates for each document, the hitlist is formed according to the Probability Ranking Principle. Estimates for the keywords' dependencies on documents rely on the same weighting techniques discussed in Section 3.3.  Fuhr and Buckley have extended this formalism to include an additional level, which they call relevance description /(Ã¯) [Fuhr and Buckley, 1991]. This is an arbitrary function over terms and documents X(k, d). Using this descriptive layer, rather than computing  Pr{Rel\ky d)  the probability of relevance given a particular keyword and a particular document, they propose to evaluate  Pr{Rel\Xihd))  where this is the "probability that a document will be judged relevant to an arbitrary query, given that one of the document's index terms* which  Multiple representations of the same document 178      FINDING OUT ABOUT  FIGURE 5.9 Concept-Matching Version of Bayesian Network  also occurs in the query, has the relevance description x" Fuhr argues that by separating the description function from the keyword and the document, a wider range of descriptions can be considered, and there is no longer a need to associate a probability of relevance with individual keywords or documents.  An alternative formulation proposed by Ribeiro and Muntz, following work by Wong and Yao, imagines the keyword vocabulary describing a universe of discourse [Ribeiro, 1995; Ribeiro and Muntz, 1996; Wong and Yao, 1995], as shown in Figure 5.9. Treating each keyword as a binary variable, any of the 2V possible subsets corresponds to a concept; any query and every document can be described as a concept within this space. The goal of retrieval becomes one of conceptual matching of a query against that of the documents. Either Pr (d|q) or Pr(q|d) can be used to reflect the strength of the concept matching relationship. In fact, these two quantities can generally be made equivalent with proper normalization [Wong and Yao, 1995].  Note that the Bayesian network generated from this perspective inverts the causal links from those proposed by Turtle and Croft! Riberiro and Muntz argue that their formulation is superior, because it treats queries and documents symmetrically (as we would expect for a concept matching retrieval). Further, the fact that conventional cosine-similarity matching requires normalization of the document vector over all index terms creates a dependence on terms not contained in the query. Any such dependence violates a fundamental condition for Bayesian network graphs [Pearl, 1988].  A good example of modeling within the Bayesian network formalism is to show how multiple query formulations, for example, Boolean and MATHEMATICAL FOUNDATIONS       179  CD  (information AND retrieval) OR (-satellite)  information retrieval  B  information retrieval  FIGURE 5.10 Two Examples of Query Modeling  weighted vector space query strategies, can be modeled interchangeably. Figure 5.10 shows in detail two possible ways in which query nodes might be connected to particular keywords. The jfirst shows a Boolean combination of keywords, and the second shows a network capturing dependencies between a phrase keyword and its constituent elements. Interaction among multiple queries all designed to satisfy the same information need, as discussed in terms of a query session in Section 4.2, can also be modeled.   