 244  Chapter 10  10.2 Non-Speech Audio Retrieval  In addition to content-based access to speech audio, noise/sound retrieval is also important in such fields as music and movie/video production. Thorn Blum et al (1997) describe a user-extensible sound classification and retrieval system, called SoundFisher (www.musclefish.com), that draws from several disciplines, including signal processing, psychoacoustics, speech recognition, computer music, and multimedia databases. Just as image indexing algorithms use visual feature vectors to index and match images, Blum et al. use a vector of directly measurable acoustic features (e.g., duration, loudness, pitch, brightness) to index sounds. This enables users to search for sounds within specified feature ranges. For example, Figure 10.2a illustrates the analysis of male laughter on several dimensions including amplitude, brightness, bandwidth, and pitch. Figure 10.2b shows an enduser content-based retrieval application that enables a user to browse and/or query a sound database by acoustic (e.g., pitch, duration) and/or perceptual properties (e.g., "scratchy") and/or query by example. For example, SoundFisher supports such complex content queries as "Find all AIFF encoded files with animal or human vocal sounds that are similar to barking sounds without regard to duration or amplitude." The user can also perform a weighted query-by-value (e.g., foreground and transition with gt;.8 metallic and gt;.7 plucked aural properties and 2000 hz lt; average pitch lt; 300 hz and duration ...). The system can also be trained by example, so that perceptual properties (e.g., "scratchiness" or "buzziness") that are more indirectly related to acoustic features can be specified and retrieved.  ï l. \\  ¶\.-'.'l  OSO     0.30      I.CO     COO      130  Liufl iteiYuu-h MmI feb kd A \      MVMlid  Figure 10.2a. Analysis of Male Laugher. Figure 10.2b. Content based access to  audio. Multimedia Information Retrieval  245  Figure 10.2. Content-based Retrieval of Non-speech Audio  Performance of the SoundFisher system was evaluated using a database of 400 widely ranging sound files (e.g., captured from nature, animals, instruments, speech). Additional requirements identified by this research include the need for sound displays, sound synthesis (a kind of query formulation/refinement tool), sound separation, and matching of trajectories of features over time.   