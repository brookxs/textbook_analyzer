 4.4 RAVE: A Relevance Assessment VEhicle  Section 4.3.2 argued that the opinions of many users concerning the relevance of a document to a query provides a more robust characterization than any single expert. It seems, however, that our move from omniscient to consensual relevance has only made the problem of evaluation that much more difficult: Test corpora must be large enough to provide robust tests for retrieval methods, and multiple queries are necessary to evaluate the overall performance of an IR system. Getting even a single person's opinion about the relevance of a document to a particular query is hard, and we are now interested in getting many!  This section describes RAVE, a relevance assessment vehicle that demonstrates that it is possible to operationally define relevance in the manner we suggest. RAVE is a suite of software routines that allow an IR experimenter to effectively collect large numbers of relevance assessments for an arbitrary document corpus. It has been used with a number of different classes of students to collect the relevance assessments used for evaluation with respect to the AIT corpus; your teacher may have you participate in a similar experiment. It can also be used to collect assessments for other document corpora and query sets.   