 5.3.2 Information in RelFhk  Section 5.2.7 raised several important cognitive questions arising from  attempts to study "semantic" interpretation of LSI/SVD dimensions. The connection to the psychologically important analysis of MDS adds even  more. If we interpret relevance feedback information as constraints about which documents a user likes, how much can we reduce dimensionality without 164       FINDING OUT ABOUT  violating the relevance feedback constraints they are giving us? That is, how much can we reduce the representational space before we're changing somebody's order? Second, how many relevance feedback statements do we need to accurately determine a good compression? How many people have to tell us things before we have enough information to form this reduced representation? These questions also connect to ones related to learning these representations (cf. Chapter 7) and to our mechanisms, as part of the interface or as part of a special experimental system like RAVE, for efficiently collecting large volumes ofrelevance feedback (cf. Section 4.4). Most of these questions remain unanswered, but a beginning is simply counting the number of preference constraints provided by each relevance feedback labeling of a hitlist by a user.  First note that the total number of preference statements required to completely determine n elements grows very rapidly as ( 2 )gt; corresponding to the fact that preference order information is defined over pairs of pairs of evaluated documents. Against this backdrop, each relevance feedback labeling produces:  NPlus = |0|                                                  (5.27)  NDCare = |#|                                                    (5.28)  NMinus- |e|                                                  (5.29)  NRetr = NPlus + NDCare + NMinus            (5.30)  NPref = NPlus ï (NDCare + NMinus)  + (NDCare ï NMinus)                       (5.31)  When this information is used as part of error correction learning, another useful quantity is the number of documents over which the relevance feedback preference relation and the ranked list disagree:  Disagree = {(diy d/)|(df- ~lt; dj) A (Rank(di) lt; Rank(dj))}    (532)  Because this relatively small number of data points will always be dwarfed by the number of total preferences across the entire corpus, the goal becomes to constrain the application of relevance feedback data to those subsets  of the corpus possibly appropriate to a particular query. And because we intend to learn from the browsing users, we can afford to be patient:  The documents are only written once but browsing users will continue to read them and provide relevance feedback for some time.  