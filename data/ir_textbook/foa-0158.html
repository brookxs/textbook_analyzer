 7.5.4 Combining Classifiers  The preceding chapters have described a wide range of potentially useful retrieval techniques. A very reasonable response is to ask if perhaps the  best possible retrieval system isn't some sort of mixture of these various techniques. For example, Bartell [Bartell et al, 1994a] has considered  simple linear combinations of experts like those shown in Figure 7.8. His experiments considered two experts, one that used a set of simple words as features and a second that did more elaborate phrase extraction. 276      FINDING OUT ABOUT  1  O  Optimal term weight (weights normalized to unit circle)  FIGURE 7.9 Optimal Weightings Distribution From [Bartell et al., 1994b]  Holding the sum of the two experts' contributions constant, their relative contribution describes a circle of fixed radius. Figure 7.9 shows a set of 228 test queries and the optimal weighting of phrase and term experts for each. That is, for a particular query, the optimal contribution of ranking information from the phrase and term expert is determined. Also shown is a line corresponding to the optimal balance between phrase and term expert across all queries. In general, the phrase expert was not very useful. On some queries, however, it was able to improve performance significantly. The way in which individual queries make special demands of the retrieval system is perhaps the most striking feature of these results.  As search engine technologies have developed, the composition of hybrid systems involving multiple systems has required a more "black box" composition. That is, rather than manipulating a single feature of the retrieval system (e.g., term versus phrase features), the combination has been of a system's net ranking [Thompson, 1990a; Thompson, 1990b].  Collection fusion refers to the problem of combining results coming from disjoint corpora [Towell et al., 1995; Yager and Rybalov, 1998]. (In the emerging environment of combined corpora and primarily ADAPTIVE INFORMATION RETRIEVAL       277  publisher-driven search engines, corpora have become confounded with the search engines allowed to search them.) Diamond (personal communication) has hypothesized several effects we might imagine from fusing multiple search engines:  Skimming effect... [when] retrieval approaches that represent [documents] differently may retrieve different relevant items, so that a combination method that takes the top-ranked items from each of the retrieval approaches will "push" non-relevant items down in the ranking.  Chorus effect... when several retrieval approaches (each representing the query differently) suggest that an item is relevant to a query, this tends to be stronger evidence for relevance than a single approach doing so. Thus, allowing several independent retrieval approaches to "vote" on the relevance of an item should enable a sharper distinction between relevant and non-relevant items. [Diamond, personal communication]  Note how the first of these focuses on differences in the systemsbased treatment of documents and the second on queries (cf. Section 3.3.3).*                                                                                                 Dark Horse  In some ways, this combination of classifiers is reminiscent of earlier effect too work using multiple query representations [BeUcin et al., 1993]. Vogt has recently performed an exhaustive analysis of linear combinations for all 61 search engines submitted to the TREC5 competition [Vogt and Cottrell, 1998]. His primary conclusion, following Lee [Lee, 1997], is that two systems are best combined linearly when there is a great deal of overlap in the set of relevant documents they identify, while their retrieval of nonrelevant documents is nearly disjoint. In terms of Diamond's qualitative expectations, linear combinations are best able to support the "chorus" effect. Schutze et al. and Larkey have considered combining various types of special-function classifiers [Schutze et al., 1995b; Larkey and Croft, 1996].   