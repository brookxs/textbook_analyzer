 4.8 Hidden Markov Models  Hidden Markov Models (HMM) have been applied for the last 20 years to solving problems in speech recognition and to a lesser extent in the areas locating named entities (Bikel-97), optical character recognition (Bazzi-98) and topic identification (KubaIa-97). More recently HMMs have been applied more generally to information retrieval search with good results. One of the first comprehensive and practical descriptions of Hidden Markov Models was written by Dr. Lawrence Rabiner (Rabiner-89)  A HMM can best be understood by first defining a discrete Markov process. The easiest way to understand it is by an example. Lets take the example of a three state Markov Model of the Stock Market. The states will be one of the following that is observed at the closing of the market:  State 1 (SI): market decreased State 2 (S2): market did not change State 3 (S3): market increased in value  The movement between states can be defined by a state transition matrix with state transitions (this assumes you can go from any state to any other state):  .5           .3           .4  A={*u} =    .1           .6          .3  .6          .7          .5  Given that the market fell on one day (State 1), the matrix suggests that the  probability of the market not changing the next day is .1. This then allows questions such as the probability that the market will increase for the next 4 days then fall. This would be equivalent to the sequence of SEQ = {S3, S3, S3, S3, SI}. In order to simplify our model, lets assume that instead of the current state being dependent upon all the previous states, lets assume it is only dependent upon the 100                                                                                              Chapter 4  last state (discrete, first order, Markov chain.) This would then be calculated by the formula:  P(SEQ) =P[S3, S3, S3, S3.S1]  = P[S3] * P[S3/S3] * P[S3/S3} * P[S3/S3] * P[S1/S3] = S3(init)*a3,3* a3,3* a3,3* a1gt;3 = (1.0)* (.5)* (.5)* (.5)* (.4) = .05  In the equation we also assume the probability of the initial state of S3 is S3(init)=l. The following graph depicts the model. The directed lines indicate the state transition probabilities a,j. There is also an implicit loop from every state back to itself  In the example every state corresponded to an observable event (change in the market).  When trying to apply this model to less precise world problems such as in speech  recognition, this model was too restrictive to be applicable. To add more flexibility a probability function was allowed to be associated with the state. The result is called the Hidden Markov Model. It gets its name from the fact that there are two  stochastic processes with the underlying stochastic process not being observable (hidden), but can only be analyzed by observations which originate from another  stochastic process. Thus the system will have as input a series of results, but it will not know the Markov model and the number of states that were associated with generating the results. So part of the HMM process is in determining which model of states best explains the results that are being observed.  Amore formal definition of a discrete Hidden Markov Model is summarized by Mittendorf and Schauble (Mittendorf-94): as consisting of the following: Data Structure                                                                                            101  1.   S = { So, ,..., sn.i} as a finite set of states where s0 always denotes the initial state. Typically the states are interconnected such that any state can be reached from any other state.  2.     V = { v0,..., vm_j} is a finite set of output symbols.    This will correspond to the physical output from the system being modeled.  3.    A = S x S a transition probability matrix where ay   represents the  n-\  probability of transitioning from state i to state] such that   /\#i,j = 1 for  all i = 0, ... ,n - 1. Every value in the matrix is a positive value between 0 and 1. For the case where every state can be reached from every other state every value in the matrix will be non-zero.  4.    B = S X V is an output probability matrix where element bjtk is a  m-\  function determining the probability and J^b jtk = 1 for all  Â£=0  j = 0, ...,n-l.  5.   The initial state distribution.  The HMM will generate an output symbol at every state transition. The transition probability is the probability of the next state given the current state. The output probability is the probability that a given output is generated upon arriving at the next state.  Given the HMM definition, it can be used as both a generator of possible sequences of outputs and their probabilities (as shown in example above), or given a particular out sequence it can model its generation by an appropriate HMM model. The complete specification of a HMM requires specification of the states, the output symbols and three probability measures for the state transitions, output probability functions and the initial states. The distributions are frequently called A, B, and 7t, and the following notation is used to define the model:  I = (A, B, 7i).  One of the primary problems associated with HMM is how to efficiently calculate the probability of a sequence of observed outputs given the HMM model. This can best be looked at as how to score a particular model given a series of outputs. Or another way to approach it is how to determine which of a number of competing models should be selected given an observed set of outputs. This is in effect 102                                                                                              Chapter 4  uncovering the hidden part of the model. They typical approach is to apply an "optimality criterion" to select the states. But there are many such algorithms to choose from. Once you have selected the model that you expect corresponds to the output, then there is the issue of determining which set of state sequences best explains the output. The final issue is how best to tune the X model to maximize the probability of the output sequence given X. This is called the training sequence and is crucial to allow the models to adapt to the particular problem being solved. More details can be found in Rabiner's paper (Rabiner-89).   