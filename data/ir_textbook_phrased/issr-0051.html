74 chapter 4 4.2.1 introduction to the stemming process stemming algorithms are used to improve the efficiency of the information-system and to improve recall . conflation is the term frequently used to refer to mapping multiple morphological variants to a single representation (stem) . the premise is that the stem carries the meaning of the concept associated with the word and the affixes (endings) introduce subtle modifications to the concept or are used for syntactical purposes . languages have precise grammars that define their usage , but also evolve based upon human usage . thus exceptions and non-consistent variants are always present in languages that typically require exception look-up tables in addition to the normal reduction rules . at first glance , the idea of equating multiple-representations of a word as a single stem term would appear to provide significant compression , with associated savings in storage and processing . for example , the stem `` comput '' could associate `` computable , computability , computation , computational , computed , computing , computer , computerese , computerize '' to one compressed word . but upon closer examination , looking at an inverted-file system-implementation , the savings is only in the dictionary since weighted positional-information is typically needed in the inversion lists . in an architecture with stemming , the information is in the one inversion list for the stem term versus distributed across multiple inversion lists for each unstemmed term . since the size of the inversion lists are the major storage factor , the compression of stemming does not significantly reduce storage requirements . for small test-databases such as the cranfield collection , lennon reported savings of 32 per cent (lennon-81) . but when applied to larger databases of 1.6 megabytes and 50 megabytes , the compression reduced respectively to 20 percent and 13.5 percent (harman-91) . harman also points out that misspellings and proper-names reduce the compression even more . in a large text corpus , such as the trec database , over 15 per cent of the unique-words are proper nouns or acronyms that should not be stemmed . another major use of stemming is to improve recall . as long as a semantically consistent stem can be identified for a set of words , the generalization process of stemming does help in not missing potentially relevant items . stemming of the words `` calculate , calculates , calculation , calculations , calculating '' to a single stem (`` calculat '') insures whichever of those terms is entered by the user , it is translated to the stem and finds all the variants in any items they exist . in contrast , stemming can not improve , but has the potential for decreasing precision . the precision value is not based on finding all relevant items but just minimizing the retrieval of non-relevant items . any function that generalizes a user 's search statement can only increase the likelihood of retrieving non-relevant items unless the expansion guarantees every item retrieved by the expansion is relevant . data-structure 75 it is important for a system to be able to categorize a word prior to making the decision to stem it . certain categories such as proper-names and acronyms should not have stemming applied because their morphological basis is not related to a common core concept . stemming can also cause problems for natural-language-processing (nlp) systems by causing the loss of information needed for aggregate levels of natural-language-processing (discourse-analysis) . the tenses of verbs may be lost in creating a stem , but they are needed to determine if a particular concept (e.g. , economic support) being indexed occurred in the past or will be occurring in the future . time is one example of the type of relationships that are defined in natural-language-processing-systems (see chapter 5) . the most common stemming algorithm removes suffixes and prefixes , sometimes recursively , to derive the final stem . other techniques such as table-lookup and successor stemming provide alternatives that require additional overheads . successor stemmers determine prefix overlap as the length of a stem is increased . this information can be used to determine the optimal length for each stem from a statistical versus a linguistic perspective . table-lookup requires a large-data structure . a system such as retrievalware that is based upon a very-large thesaurus/concept network has the data-structure as part of its basic product and thus uses table-look-up . the kstem algorithm used in the inquery-system combines a set of simple stemming rules with a dictionary to determine processing tokens . the affix removal technique removes prefixes-and-suffixes from terms leaving the stem . most stemmers are iterative and attempt to remove the longest prefixes-and-suffixes (lovins-68 , salton-68 , dawson-74 , porter-80 and paice-90) . the porter algorithm is the most commonly accepted algorithm , but it leads to loss of precision and introduces some anomalies that cause the user to question the integrity of the system . stemming is applied to the user 's query as well as to the incoming text . if the transformation moves the query-term to a different semantic-meaning , the user will not understand why a particular item is returned and may begin questioning the integrity of the system in general .