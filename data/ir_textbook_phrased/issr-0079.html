5.2.3 bayesian-model one way of overcoming the restrictions inherent in a vector-model is to use a bayesian-approach to maintaining information on processing tokens . the bayesian-model provides a conceptually simple yet complete model for information-systems . in its most general definition , the bayesian-approach is based upon conditional-probabilities (e.g. , probability of event 1 given event 2 occurred) . this general concept can be applied to the search function as well as to creating the index to the database . the objective of information-systems is to return relevant items . thus the general case , using the bayesian formula , is p (rel/doq , query ,) which is interpreted as the probability of relevance (rel) to a search statement given a particular document and query . interpretation of this process is discussed in detail in chapter 7 . in addition to search , bayesian formulas can be used in determining the weights associated with a particular processing token in an item . the objective of creating the index to an item is to represent the semantic information in the item . a bayesian-network can be used to determine the final set of processing tokens (called topics) and their weights . figure 5.6 shows a simple view of the process where tj represents the relevance of topic `` i '' in a particular item and pj represents a statistic associated with the event of processing token `` j '' being present in the item . figure 5.6 bayesian term-weighting automatic-indexing 123 the `` m '' topics would be stored as the final index to the item . the statistics associated with the processing token are typically frequency of occurrence . but they can also incorporate proximity factors that are useful in items that discuss multiple topics . there is one major assumption made in this model : assumption of binary independence : the topics and the processing token statistics are independent of each other . the existence of one topic is not related to the existence of the other topics . the existence of one processing token is not related to the existence of other processing tokens . in most cases this assumption is not true . some topics are related to other topics and some processing tokens related to other processing tokens . for example , the topics of `` politics '' and `` economics '' are in some instances related to each other (e.g. , an item discussing congress debating laws associated with balance-of-trade) and in many other instances totally unrelated . the same type of example would apply to processing tokens . there are two approaches to handling this problem . the first is to assume that there are dependencies , but that the errors introduced by assuming the mutual independence do not noticeably effect the determination of relevance of an item nor its relative rank associated with other retrieved items . this is the most common approach used in system implementations . a second approach can extend the network to additional layers to handle interdependencies . thus an additional layer of independent topics (its) can be placed above the topic layer and a layer of independent processing tokens (ips) can be placed above the processing token layer . figure 5.7 shows the extended bayesian-network . extending the network creates new processing tokens for those cases where there are dependencies between processing tokens . the new set of independent processing tokens can then be used to define the attributes associated with the set of topics selected to represent the semantics of an item . to compensate for dependencies between topics the final layer of independent topics is created . the degree to which each layer is created depends upon the error that could be introduced by allowing for dependencies between topics or processing tokens . although this approach is the most mathematically correct , it suffers from losing a level of precision by reducing the number of concepts available to define the semantics of an item .