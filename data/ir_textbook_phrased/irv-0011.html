luhn 's ideas in one of luhn 's [6] early papers he states : ` it is here proposed that the frequency of word occurrence in an article furnishes a useful measurement of word significance . it is further proposed that the relative position within a sentence of words having given values of significance furnish a useful measurement for determining the significance of sentences . the significance factor of a sentence will therefore be based on a combination of these two measurements . ' i think this quote fairly summaries luhn 's contribution to automatic-text-analysis . his assumption is that frequency data can be used to extract words and sentences to represent a document . let f be the frequency of occurrence of various word-types in a given position of text and r their rank-order , that is , the order of their frequency of occurrence , then a plot relating f and r yields a curve similar to the hyperbolic curve in figure 2.1 . this is in fact a curve demonstrating zipf 's law [7] * which states that the product of the frequency of use of wards and the rank-order is approximately constant . zipf verified his law on american newspaper english . luhn used it as a null-hypothesis to enable him to specify two cut-offs , an upper and a lower (see figure 2.1 .) , thus excluding non-significant words . the words exceeding the upper cut-off were considered to be common and those below the lower cut-off rare , and therefore not contributing significantly to the content of the article . he thus devised a counting technique for finding significant words . consistent with this he assumed that the resolving power of significant words , by which he meant the ability of words to discriminate content , reached a peak at a rank-order position half way between the two cut-offs and from the peak fell off in either direction reducing to almost zero at the cut-off points . a certain arbitrariness is involved in determining the cut-offs . there is no oracle which gives their values . they have to be established by trial and error . it is interesting that these ideas are really basic to much of the later work in ir . luhn himself used them to devise a method of automatic-abstracting . he went on to develop a numerical measure of significance for sentences based on the number of significant and non-significant words in each portion of the sentence . sentences were ranked according to their numerical score and the highest ranking were included in the abstract (extract really) . edmundson and wyllys [8] have gone on to generalise some of luhn 's work by normalising his measurements with respect to the frequency of occurrence of words in general text . there is no reason why such an analysis should be restricted to just words . it could equally well be applied to stems of words (or phrases) and in fact this has often been done .