feedback the word feedback is normally used to describe the mechanism by which a system can improve its performance on a task by taking account of past performance . in other words a simple input-output system feeds back the information from the output so that this may be used to improve the performance on the next input . the notion of feedback is well established in biological and automatic-control systems . it has been popularised by norbert wiener in his book cybernetics . in information-retrieval it has been used with considerable effect . consider now a retrieval-strategy that has been implemented by means of a matching-function m. furthermore , let us suppose that both the query q and document representatives d are t-dimensional vectors with real components where t is the number of index-terms . because it is my purpose to explain feedback i will consider its-applications to a serial-search only . it is the aim of every retrieval-strategy to retrieve the relevant documents a and withhold the non-relevant documents ` a. unfortunately relevance is defined with respect to the user 's semantic-interpretation of his query . from the point-of-view of the retrieval-system his formulation of it may not be ideal . an ideal formulation would be one which retrieved only the relevant documents . in the case of a serial-search the system will retrieve all d for which m (q , d) gt ; t and not retrieve any d for which m (q , d) lt ; = t , where t is a specified threshold . it so happens that in the case where m is the cosine correlation function , i.e. the decision-procedure m (q , d) - t gt ; 0 corresponds to a linear discriminant function used to linearly separate two sets a and ` a in r [t] . nilsson [14] has discussed in great detail how functions such as this may be ` trained ' by modifying the weights qi to discriminate correctly between two categories . let us suppose for the moment that a and ` a are known in advance , then the correct query-formulation q0 would be one for which m (q0 , d) gt ; t whenever d [[propersubset]] a and m (q0 , d) lt ; = t whenever d [[propersubset]] ` [[alpha]] the interesting thing is that starting with any q we can adjust it iteratively using feedback information so that it will converge to q0 . there is a theorem (nilsson [14] , page 81) which states that providing q0 exists there is an iterative-procedure which will ensure that q will converge to q0 in a finite number of steps . the iterative-procedure is called the fixed-increment error-correction procedure . it goes as follows : qi = qi-1 + cd if m (qi-1 , d) - t lt ; = 0 and d [[propersubset]] a qi = qi-1 - cd if m (qi-1 , d) - t gt ; 0 and d [[propersubset]] ` a and no change made to qi-1 if it diagnoses correctly . c is the correction increment , its value is arbitrary and is therefore usually set to unit . in practice it may be necessary to cycle through the set of documents several times before the correct set of weights are achieved , namely those which will separate a and ` a linearly (this is always providing a solution exists) . the situation in actual retrieval is not as simple . we do not know the sets a and ` a in advance , in fact a is the set we hope to retrieve . however , given a query-formulation q and the documents retrieved by it we can ask the user to tell the system which of the documents retrieved were relevant and which were not . the system can then automatically modify q so that at least it will be able to diagnose correctly those documents that the user has seen . the assumption is that this will improve retrieval on the next run by virtue of the fact that its performance is better on a sample . once again this is not the whole story . it is often difficult to fix the threshold t in advance so that instead documents are ranked in decreasing matching value on output . it is now more difficult to define what is meant by an ideal query-formulation . rocchio [15] in his thesis defined the optimal query q0 as one which maximised : if m is taken to be the cosine function (q , d) / | | q | | | | d | | then it is easy to show that [[phi]] is maximised by where c is an arbitrary proportionality constant . if the summations instead of being over a and ` a are now made over a [[intersection]] bi and ` a [[intersection]] bi where bi is the set of retrieved documents on the ith iteration , then we have a query-formulation which is optimal for bi a subset of the document collection . by analogy to the linear classifier used before , we now add this vector to the query-formulation on the ith step to get : where wi and w2 are weighting coefficients . salton [2] in fact used a slightly modified version . the most important difference being that there is an option to generate qi +1 from qi , or q , the original query . the effect of all these adjustments may be summarised by saying that the query is automatically modified so that index-terms in relevant retrieved documents are given more weight (promoted) and index-terms in non-relevant documents are given less weight (demoted) . experiments have shown that relevance-feedback can be very effective . unfortunately the extent of the effectiveness is rather difficult to gauge , since it is rather difficult to separate the contribution to increased retrieval-effectiveness produced when individual documents move up in rank from the contribution produced when new documents are retrieved . the latter of course is what the user most cares about . finally , a few comments about the technique of relevance-feedback in general . it appears to me that its implementation on an operational basis may be more problematic . it is not clear how users are to assess the relevance , or non-relevance of a document from such scanty evidence as citations . in an operational system it is easy to arrange for abstracts to be output but it is likely that a user will need to browse through the retrieved documents themselves to determine their relevance after which he is probably in a much better position to restate his query himself .