7.1 introduction as discussed in chapter 2 , not all words are equally significant for representing the semantics of a document . in written language , some words carry more meaning than others . usually , noun words (or groups of noun words) are the ones which are most representative of a document-content . therefore , it is usually considered worthwhile to preprocess the text of the documents in the collection to determine the terms to be used as index-terms . during this preprocessing phase other useful text operations can be performed such as elimination of stop-words , stemming (reduction of a word to its grammatical root) , the building of a thesaurus , and-compression . such text operations are discussed in this chapter . we already know that representing documents by sets of index-terms leads to a rather imprecise representation of the semantics of the documents in the collection . for instance , a term like ` the '' has no meaning whatsoever by itself and might lead to the retrieval of various documents which are unrelated to the present user-query . we say that using the set of all words in a collection to index its documents generates too much noise for the retrieval-task . one way to reduce this noise is to reduce the set of words which can be used to refer to (i.e. , to index) documents . thus , the preprocessing of the documents in the collection might be viewed simply as a process of controlling the size of the vocabulary (i.e. , the number of distinct words used as an index-terms) . it is expected that the use of a controlled-vocabulary leads to an improvement in retrieval-performance . while controlling the size of the vocabulary is a common technique with commercial systems , it does introduce an additional step in the indexing process which is frequently not easily perceived by the users . as a result , a common user might be surprised with some of the documents retrieved and with the absence of other documents which he expected to see . for instance , he might remember that a certain document contains the string ` the house of the lord and notice that such a document is not present among the top 20 documents retrieved in 163 164 text operations response to his query request (because the controlled-vocabulary contains neither ` the ' nor ` of ') . thus , it should be clear that , despite a potential improvement in retrieval-performance , text transformations done at preprocessing time might make it more difficult for the user to interpret the retrieval-task . in recognition of this problem , some search-engines in the web are giving up text operations entirely and simply indexing all the words in the text . the idea is that , despite a more noisy index , the retrieval-task is simpler (it can be interpreted as a full-text-search) and more intuitive to a common user . besides document-preprocessing , other types of operations on documents can also be attempted with the aim of improving retrieval-performance . among these we distinguish the construction of a thesaurus representing conceptual term-relationships and the clustering of related documents . thesauri are also covered in this chapter . the discussion on document-clustering is covered in chapter 5 because it is an operation which might depend on the current user-query . text-normalization and the building of a thesaurus are strategies aimed at improving the precision of the documents retrieved . however , in the current world of very-large digital-libraries , improving the efficiency (in terms of time) of the retrieval-process has also become quite critical . in fact , web-search-engines are currently more concerned with reducing query response-time than with improving precision-and-recall figures . the reason is that they depend on processing a high number of queries per unit of time for economic survival . to reduce query response-time , one might consider the utilization of text-compression as a promising alternative . a good compression-algorithm is able to reduce the text to 30-35 % of its original size . thus , compressed text requires less storage space and takes less time to be transmitted over a communication-link . the main disadvantage is the time spent compressing and decompressing the text . until recently , it was generally understood that compression does not provide substantial gains in processing-time because the extra time spent compressing/decompressing text would offset any gains in operating with compressed data . further , the use of compression makes the overall design-and-implementation of the information-system more complex . however , modern compression techniques are slowly changing this understanding towards a more favorable view of the adoption of compression techniques . by modern compression techniques we mean good compression and decompression speeds , fast random-access without the need to decode the compressed text from the beginning , and direct searching on the compressed text without decompressing it , among others . besides compression , another operation on text which is becoming more and more important is encryption . in fact , due to the fast popularization of services in the web (including all types of electronic-commerce) , key (and old) questions regarding security-and-privacy have surfaced again . more than ever before , impersonation and unauthorized-access might result in great prejudice and financial damage to people and organizations . the solution to these problems is not simple but can benefit from the operation of encrypting text . discussing encrypted text is beyond the scope of this book but an objective and brief introduction to the topic can be found in [501] . document-preprocessing 165 in this chapter , we first discuss five preprocessing text operations including thesauri . following that , we very briefly summarize the problem of document-clustering (which is discussed in detail in chapter 5) . finally , a thorough discussion on the issue of text-compression , its modern variations , and its main implications is provided .