automatic-indexing 135 5.6 summary automatic-indexing is the preprocessing stage allowing search of items in an information-retrieval-system . its role is critical to the success of searches in finding relevant items . if the concepts within an item are not located and represented in the index during this stage , the item is not found during search . some techniques allow for the combinations of data at search-time to equate to particular concepts (i.e. postcoordination) . but if the words are not properly identified at indexing time and placed in the searchable data-structure , the system can not combine them to determine the concept at search-time . if an inefficient data-structure is selected to hold the index , the system does not scale to accommodate large numbers of items . the steps in the identification of the processing tokens used in the index process were generally discussed in chapter 3 . chapter 5 focuses on the specific characteristics of the processing tokens to support the different search-techniques . there are many ways of defining the techniques . all of the techniques have statistical algorithmic properties . but looking at the techniques from a conceptual level , the approaches are classified as statistical , natural-language and concept-indexing . hypertext linkages are placed in a separate class because an algorithm to search items that include linkages has to address dependencies between items . normally the processing for processing tokens is restricted to an item . the next item may use some corpus statistics that changed by previous items , but does not consider a tight-coupling between items . in effect , one item may be considered an extension of another , which should effect the concept-identification and representation process . of all the statistical-techniques , an accurate probabilistic technique would have the greatest benefit in the search-process . unfortunately , identification of consistent statistical values used in the probabilistic formulas has proven to be a formidable task . the assumptions that must be made significantly reduce the accuracy of the search-process . vector techniques have very powerful representations and have been shown to be successful . but they lack the flexibility to represent items that contain many distinct but overlapping concepts . bayesian techniques are a way to relax some of the constraints inherent in a pure vector approach , allowing dependencies between concepts within the same item to be represented . most commercial systems do not try to calculate weighted values at index time . it is easier and more flexible to store the basic word-data for each item and calculate the statistics at search-time . this allows tuning the algorithms without having to re-index the database . it also allows the combination of statistical and traditional boolean-techniques within the same system . natural-language-systems attempt to introduce a higher level of abstraction indexing on top of the statistical processes . making use of rules associated with language assist in the disambiguation of terms and provide an additional layer of concepts that are not found in purely statistical systems . use of natural-language-processing provides the additional data that could focus searches , 136 chapter 5 reducing the retrieval of non-relevant items . the tendency of users to enter short queries may reduce the benefits of this approach . concept-indexing is a statistical technique whose goal is to determine a canonical-representation of the concepts . it has been shown to find relevant items that other techniques miss . in its transformation process , some level of precision is lost . the analysis of enhanced recall over potential reduced-precision is still under investigation .