10.2.3 evaluating interactive-systems from the viewpoint of user-interface-design , people have widely differing abilities , preferences , and predilections . important differences for information-access interfaces include relative spatial-ability and memory , reasoning abilities , verbal aptitude , and (potentially) personality differences [227 , 725] . age and cultural-differences can contribute to acceptance or rejection of interface-techniques [557] . an-interface innovation can be useful and pleasing for some users , and foreign and cumbersome for others . thus software-design should allow for flexibility in interaction-style , and new features should not be expected to be equally helpful for all users . an important aspect of human-computer-interaction is the methodology for evaluation of user interface-techniques . precision-and-recall measures have been widely used for comparing the ranking results of non-interactive systems , but are less appropriate for assessing interactive-systems [470] . the standard evaluations 262 user-interfaces and visualization emphasize high recall levels ; in the trec tasks systems are compared to see how well they return the top 1000 documents (see chapter 3) . however , in many interactive settings , users require only a few relevant documents and do not care about high recall to evaluate highly interactive information-access systems , useful metrics beyond precision-and-recall include : time required to learn the system , time required to achieve goals on benchmark tasks , error-rates , and retention of the use of the interface over time . throughout this chapter , empirical-results of user-studies are presented whenever they are available . empirical-data involving human users is time consuming to gather and difficult to draw conclusions from . this is due in part to variation in users ' characteristics and motivations , and in part to the broad scope of information-access activities . formal psychological studies usually only uncover narrow conclusions within restricted contexts . for example , quantities such as the length of time it takes for a user to select an item from a fixed menu under various conditions have been characterized empirically [142] , but variations in interaction behavior for complex-tasks like information-access are difficult to account for accurately . nielsen [605] advocates a more informal evaluation-approach (called heuristic-evaluation) in which user-interface affordances are assessed in terms of more general properties and without concern about statistically significant results .