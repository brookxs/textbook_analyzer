5.2.2.3 signal weighting inverse-document-frequency adjusts the weight of a processing token for an item based upon the number of items that contain the term in the existing database . what it does not account for is the term-frequency-distribution of the processing token in the items that contain the term . the distribution of the frequency of processing tokens within an item can affect the ability to rank items . for example , assume the terms `` saw '' and `` drill '' are found in 5 items with the following frequencies defined in figure 5.5 . both terms are found a total of 50 times in the five items . the term `` saw '' does not give any insight into which item is more likely to be relevant to a search of `` saw '' . if precision is a goal (maximizing relevant items shown first) , then the weighting algorithm could take into consideration the non-uniforrn 118 chapter 5 distribution of term `` drill '' in the items that the term is found , applying even higher weights to it than `` saw . '' the theoretical basis for the algorithm item distribution saw drii a 10 2 b 10 2 c 10 18 d 10 10 e 10 18 figure 5.5 item distribution for saw and drill to emphasize precision is shannon 's work on information-theory (shannon-51) . in information-theory , the information-content value of an object is inversely proportional to the probability of occurrence of the item . an instance of an event that occurs all the time has less information-value than an instance of a seldom occurring event . this is typically represented as information = - log2 (p) , where p is the probability of occurrence of event `` p. '' the information-value for an event that occurs .5 per cent of the time is : information = - log2 (.0005) = - (-10) = 10 the information-value for an event that occurs 50 per cent of the time is : information = - log2 (.50) = - (-1) = 1 if there are many independent occurring events then the calculation for the average information-value across the events is : avejnfo = - yj p * lo ^ (pk) the value of ave jnfo takes its maximum value when the values for every pk is the same . its value decreases proportionally to increases in variances in the values of p ^ the value of pk can be defined as tfji/rqtfk , the ratio of the frequency of occurrence of the term in an item to the total number of occurrences of the item in the data-base . using the avejnfq formula , the terms that have the most uniform-distribution in the items that contain the term have the maximum value . to use this information in calculating a weight , the formula needs the inverse of ave info , where the minimum value is associated with uniform distributions automatic-indexing 119 and the maximum value is for terms that have large variances in distribution in the items containing the term . the following formula for calculating the weighting factor called signal (dennis-67) can be used : signalk = log2 (totf) - a ve jnfo producing a final formula of : weight * = tflk * signalk n weight * = tf , k * [log2 (totfk) -] t tf , k/totfk log2 (tfik/totfk)] an example of use of the weighting factor formula is given for the values in figure 5.5 : signalsaw = log2 (50) - [5 * (10/50log2 (i0/50)}] signaldrill = log2 (50) - [2/50log2 (2/50) + 2/50log2 (2/50) + 18/50log2 (18/50) + 10/50log2 (10/50) + i8/50log2 (18/50) the weighting factor for term `` drill '' that does not have a uniform-distribution is larger than that for term `` saw '' and gives it a higher weight . this technique could be used by itself or in combination with inverse-document-frequency or other algorithms . the overhead of the additional data needed in an index and the calculations required to get the values have not been demonstrated to produce better results than other techniques and are not used in any systems at this time . it is a good example of use of information-theory in developing information-retrieval algorithms . effectiveness of use of this formula can be found in results from harman and also from lockbaum and streeter (harman-86 , lochbaum-89) .