3.3.2 word occurrence as a poisson-process when the words contained in a corpus are ranked and shown to be distributed according to a zipfian distribution , an obvious but important observation can be made : the most frequently occurring words are not really about anything . words like not , of , the , or , to , but , and be obviously play an important functional-role , as part of the syntactic-structure of sentences , but it is hard to imagine users asking for documents about of or about but . define function-words to be those that have only (!) a syntactic-function , for example , of , the , but , and distinguish them from content-words , which are descriptive in the sense that we 're interested in them for the indexing task . this is one of the first - but most certainly not the last - examples foa makes using a priori determinations of a word 's semantic utility based on its statistical-properties . for example , we might hope that function-words occur randomly throughout arbitrary text , while content-words do not . one ubiquitous 74 finding out about model of randomness is as a poisson-process , used in the past to model things like : ï raisins ' distribution across slices of bread ; or ï misprints ' distribution across printed pages ; or ï the distribution of people 's birthdays across days of the year . in the case of our documents , we 'll start with a slightly simpler bernoulli model wherein we imagine an author making binary decisions , picking a keyword k with probability p ^ then in a document of length l the probability that a keyword was selected exactly n times in document d is : pr (/ w = n) = (l) (pk) n (l - pk) l ~ n (3.6) in other words , we 'd expect it to occur an average of pk - l times in a document of length i . as i ógt ; oo and p ó + 0 (and the mean value x = p ï l ó * 1) , the poisson-distribution : pr (/ w = n) = ói-l (3.7) converges to this same distribution . we will generally be interested in a large set of parameters a.fcgt ; each corresponding to a particular keyword l if we imagine a bernoulli-like experiment , where individual function-words are placed with low probability and observed across the many `` experiments '' of words occurring in documents , we can expect that a particular word k will occur n times in a randomly selected document according to a poisson-distribution . (because documents are of different lengths , we must also take care to normalize them all to the same number of experiments .) as an example of how a poisson model might be applied to good use , work pioneered by bookstein and swanson in the mid-1970s proposed that function-words are distributed according to a relatively constant poisson-distribution , while content-words are not [bookstein and swanson , 1974 ; bookstein and kraft , 1977 , croft and harper , 1979] . that is , when a keyword is found in a document , it is for one of two possible reasons : either it just happens (randomly) to be there , or it really weighting and matching against indices 75 means something . robertson and walker [robertson and walker , 1994] distinguish the latter elite occurrences of a keyword : we hypothesize that occurrences of a term in a document have a random or stochastic element , which nevertheless reflects a real but hidden distinction between those ... `` elite '' documents which are about the concept represented by the term and those which are not . we may draw an inference about eliteness from the term-frequency , but this inference will of course be probabilistic . furthermore , relevance (to a query which may of course contain many concepts) is related to eliteness rather than directly to term-frequency , which is assumed to depend only on eliteness . [robertson and walker , 1994 , p. 233 , underline not in original] ? 1 s 2 in addition to discriminating function from content-words , the poisson model has been used to measure the degree to which a content word is effective as a keyword for a document [robertson and walker , 1994] . if we assume that a potential keyword effectively describes some documents in a corpus but occurs at the level of chance throughout the rest of the corpus , the distribution of this keyword across the corpus can be described as the mixture of a poisson-process with some other distribution . the so-called two-poisson model models both distributions (i.e. , one over the rel documents that could accurately be characterized as about this keyword and a second over the rest of the rel documents , which are not) as poisson , but with distinct means xlw and x2wy with the superscripts 1 and 2 referring to the rel and rel distributions , respectively . one advantage of assuming that both distributions are poisson and that we only need to discriminate between two classes (relevant versus nonrelevant) is that a single-parameter pte \ = pr (relevance) controls the probability that the word w is relevant : about w | k occurrences of w (3.8) this probability can then be used as part of a decision theoretic model related to the costs of indexing too many or too few documents with a keyword w (cf. section 5.5.6) . 76 finding out about