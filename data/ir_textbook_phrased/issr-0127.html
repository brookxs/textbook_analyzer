11.1 introduction to information-system evaluation in recent years the evaluation of information-retrieval-systems and techniques for indexing , sorting , searching and retrieving information have become increasingly important (saracevic-95) . this growth in interest is due to two major reasons : the growing number of retrieval-systems being used and additional focus on 258 chapter 11 evaluation-methods themselves . the-internet is an example of an information-space (infospace) whose text-content is growing exponentially along with products to find information for value . information-retrieval technologies are the basis behind the search of information on the internet . in parallel with the commercial interest , the introduction of a large standardized test database and a forum for yearly analysis via trec has provided a methodology for evaluating the performance of algorithms and systems . there are many reasons to evaluate the effectiveness of an information-retrieval-system (belkin-93 , callan-93) : to aid in the selection of a system to procure to monitor and evaluate system effectiveness to evaluate query-generation process for improvements to provide inputs to cost-benefit-analysis of an information-system to determine the effects of changes made to an existing information-system . from an academic perspective , measurements are focused on the specific effectiveness of a system and usually are applied to determining the effects of changing a system 's algorithms or comparing algorithms among systems . from a commercial perspective , measurements are also focused on availability and reliability . in an operational system there is less concern over 55 per cent versus 65 per cent precision than 90 per cent versus 80 per cent availability . for academic purposes , controlled environments can be created that minimize errors in data . in operational systems , there is no control over the users and care must be taken to ensure the data collected are meaningful . the most important evaluation-metrics of information-systems will always be biased by human subjectivity . this problem arises from the specific data collected to measure the user resources in locating relevant-information . metrics to accurately measure user resources expended in information-retrieval are inherently inaccurate . a factor in most metrics in determining how well a system is working is the relevancy of items . relevancy of an item , however , is not a binary evaluation , but a continuous function between an item 's being exactly what is being looked for and its being totally unrelated . to discuss relevancy , it is necessary to define the context under which the concept is used . from a human-judgment standpoint , relevancy can be considered : t subjective - depends upon a specific user 's judgment situational - relates to a user 's requirements cognitive - depends on human-perception and behavior temporal - changes over time measurable - observable at a points in time the subjective nature of relevance judgments has been documented by saracevic and was shown in trec-experiments (harman-95 , saracevic-91) . in trec-2 and information system-evaluation 259 trec-3 , two or three different users were given the same search statement and the same set of possible hits to judge as relevant or not . in general , there was a unanimous agreement on 70-80 per cent of the items judged by the human . even in this environment (i.e. , where the judges are not the creators of the query and are making every effort to be unbiased) there is still significant subjective disagreement on the relevancy of items . in a dynamic-environment , each user has his own understanding of the requirement and the threshold on what is acceptable (see chapter 1) . based upon his cognitive-model of the information-space and the problem , the user judges a particular item . some users consider information they already know to be non-relevant to their information-need . for example , a user being presented with an article that the user wrote does not provide `` new '' relevant-information to answer the user 's query , although the article may be very relevant to the search statement . also the judgment of relevance can vary over time . retrieving information on an `` xt '' class of pcs is not of significant relevance to personal-computers in 1996 , but would have been valuable in 1992 . thus , relevance-judgment is measurable at a point in time constrained by the particular users and their thresholds on acceptability of information . another way of specifying relevance is from information , system and situational views . the information view is subjective in nature and pertains to human-judgment of the conceptual relatedness between an item and the search . it involves the user 's personal judgment of the relevancy (aboutness) of the item to the user 's information-need . when reference experts (librarians , researchers , subject specialists , indexers) assist the user , it is assumed they can reasonably predict whether certain information will satisfy the user 's needs . ingwersen categorizes the information view into four types of `` aboutness '' (ingwersen-92) : author aboutness - determined by the author 's language as matched by the system in natural-language retrieval indexer aboutness - determined by the indexer 's transformation of the author 's natural-language into a controlled-vocabulary request aboutness - determined by the user 's or intermediary 's processing of a seafth statement into a query user aboutness - determined by the indexer 's attempt to represent the document according to presupposition about what the user will want to knowin this context , the system view relates to a match between query terms and terms within an item . it can be objectively observed , manipulated and tested without relying on human-judgment because it uses metrics associated with the matching of the query to the item (barry-94 , schamber-90) . the semantic relatedness between queries and items is assumed to be inherited via the index-terms that represent the 260 chapter 11 semantic-content of the item in a consistent and accurate fashion . other aspects of the system view are presented in section 11.2 . the situation view pertains to the relationship between information and the user 's information-problem situation . it assumes that only users can make valid judgments regarding the suitability of information to solve their information-need . lancaster and warner refer to information and situation views as relevance and pertinence respectively (lancaster-93) . pertinence can be defined as those items that satisfy the user 's information-need at the time of retrieval . the trecevaluation process uses relevance versus pertinence as its criteria for judging items because pertinence is too variable to attempt to measure in meaningful items (i.e. , it depends on each situation) .