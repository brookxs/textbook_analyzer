7.3 relevance-feedback as discussed in the early chapters in this text , one of the major problems in finding relevant items lies in the difference in vocabulary between the authors 176 chapter 7 and the user . thesuari and semantic-networks provide utility in generally expanding a user 's search statement to include potential related search-terms . but this still does not correlate to the vocabulary used by the authors that contributes to a particular database . there is also a significant risk that the thesaurus does not include the latest jargon being used , acronyms or proper nouns . in an interactive-system , users can manually modify an inefficient query or have the system automatically expand the query via a thesaurus . the user can also use relevant items that have been found by the system (irrespective of their ranking) to improve future searches , which is the basis behind relevance-feedback . relevant items (or portions of relevant items) are used to reweight the existing query terms and possibly expand the user 's search statement with new terms . the first major work on relevance-feedback was published in 1965 by rocchio (republished in 1971 : rocchio-71) . rocchio was documenting experiments on reweighting query terms and query-expansion based upon a vector-representation of queries and items . the concepts are also found in the probabilistic-model presented by robertson and sparck jones (robertson-76) . the relevance-feedback concept was that the new query should be based on the old query modified to increase the weight of terms in relevant items and decrease the weight of terms that are in non-relevant items . this technique not only modified the terms in the original query but also allowed expansion of new terms from the relevant items . the formula used is : r , . i nr ^ where qn = the revised vector for the new query qo = the original query r = number of relevant items dr , = the vectors for the relevant items nr = number of non-relevant items dnrj = the vectors for the non-relevant items . the factors r and nr were later modified to be constants that account for the number of items along with the importance of that particular factor in the equation . additionally a constant was added to qo to allow adjustments to the importance of the weight assigned to the original query . this led to the revised version of the formula : user-search techniques 177 where a , p , and y are the constants associated with each factor (usually \ ln or mnr r times a constant) . the factor p 2 ^ dr i is referred to as positive-feedback because it is using the user judgments on relevant items to increase the values of terms for nr the next iteration of searching . the factor y ^ t /) jv / ? j is referred to as negative-feedback since it decreases the values of terms in the query-vector . positive-feedback is weighted significantly greater than negative-feedback . many times only positive-feedback is used in a relevance-feedback environment . positive-feedback is more likely to move a query closer to a user 's information-needs . negative-feedback may help , but in some cases it actually reduces the effectiveness of a query . figure 7.6 gives an example of the impacts of positive and negative feedback . the filled circles represent non-relevant items ; the other circles represent relevant items . the oval represents the items that are returned from the query . the solid box is logically where the query is initially . the hollow box is the query modified by relevance-feedback (positive only or negative only in the figure) . o ∞ o / o o \ o ^ o o o o o ∞ o on oo oo p 1 o o o o o / \ o o / o o \ o o ∞ o l o) oo ∞ o o o o o o o o 1 cl o positive-feedback negative-feedback figure 7.6 impact of relevance-feedback positive-feedback moves the query to retrieve items similar to the items retrieved and thus in the direction of more relevant items . negative-feedback moves the query away from the non-relevant items retrieved , but not necessarily closer to more relevant items . figure 7.7 shows how the formula is applied to three items (two relevant and one non-relevant) . if we use the factors a = 1 , p = % (14 times a constant s/i) , y 178 chapter 7 = % (1/1 times a constant xa) in the foregoing formula we get the following revised query (note : negative values are changed to a zero value in the revised query-vector) : qn = (3 , 0,0,2 , 0) + va (2 +1 , 4 +3,0 +0,0 +0 , 2 +0) - v4 (0 , 0 , 4 , 3 , 2) = (33/4 , l3/4 ,0 {- lkl1/4 ,0) term 1 term 2 term 3 term 4 term 5 qo 3 0 0 2 0 doclr 2 4 0 0 2 doc2r 1 3 0 0 0 doc3nr 0 0 4 3 3 qn 33/4 va 0 va 0 figure 7.7 query-modification via relevance-feedback 5 using the unnormalized similarity formula sim (qk , docj) = / j term ^ termu produces the results shown in figure 7.8 : / = ! docl doc2 doc3 qo 6 3 6 qn 14v4 9.0 3.75 figure 7.8 effect of relevance-feedback in addition to showing the benefits of relevance-feedback , this example illustrates the problems of identifying information . although doc3 is not relevant to the user , the initial query produced one of the highest similarity-measures for it . this was caused by a query-term (term 4) of interest to the user that has a significant weight in doc3 . the fewer the number of terms in a user-query , the more likely a specific term to cause non-relevant items to be returned . the modification to the query by the relevance-feedback process significantly increased the similarity-measure values for the two relevant items (docl and doc2) while decreasing the value of the non-relevant item . it is also of interest to note that the new query added a weight to term 2 that was not in the original query . one reason that the user might not have initially had a value to term 2 is that it might not have been in the user 's vocabulary . for example , the user may have been searching on `` pc '' and ' `` word processor1 '' and not been aware that many authors use the specific term `` macintosh '' rather than `` pc . '' relevance-feedback , in particular positive-feedback , has been proven to be of significant value in producing better queries . some of the early experiments on user-search techniques 179 the smart system (ide-69 , ide-71 , salton-83) indicated the possible improvements that would be gained by the process . but the small collection sizes and evaluation-techniques put into question the actual gains by using relevance-feedback . one of the early problems addressed in relevance-feedback is how to treat query terms that are not found in any retrieved relevant items . just applying the algorithm would have the effect of reducing the relative weight of those terms with respect to other query terms . from the user 's perspective , this may not be desired because the term may still have significant value to the user if found in the future iterations of the search-process . harper and van rijisbergen addressed this issue in their proposed emim weighting-scheme (harper-785 harper-80) . relevance-feedback has become a common feature in most information-systems . when the original query is modified based upon relevance-feedback , the systems ensure that the original query terms are in the modified query , even if negative-feedback would have eliminated them . in some systems the modified query is presented to the user to allow the user to readjust the weights and review the new terms added . recent experiments with relevance-feedback during the trec sessions have shown conclusively the advantages of relevance-feedback . queries using relevance-feedback produce significantly better results than those being manually enhanced . when users enter queries with a few number of terms , automatic-relevance-feedback based upon just the rank values of items has been used . this concept in information-systems called pseudo-relevance-feedback , blind-feedback or local-context-analysis (xu-96) does not require human-relevance-judgments . the highest ranked items from a query are automatically assumed to be relevant and applying relevance-feedback (positive only) used to create and execute an expanded query . the system returns to the user a hit file based upon the expanded query . this technique also showed improved performance over not using the automatic-relevance-feedback process . in the automatic query processing tests from trec (see chapter 10) most systems use the highest ranked hits from the first pass to generate the relevance-feedback for the second pass .