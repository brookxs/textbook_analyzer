4.3.5 ordering the retr set do not worry about large numbers of results : the best ones come first ! (www.altavista.com , 1998) the next step is to move beyond thinking of retr as simply a set . we will suppose that retrieved documents are returned in some order by the search-engine , reflecting its assessment of how well each document matches the query . following current web vernacular , we will call this ordering of the retr set a hitlist and a retrieved document 's position its hitkst rank rank (di) . this is a positive integer assigned to each document in the retr set , in descending order of similarity with respect to the matching-function match {q , d) : match (q , d) eu rank (d) e m ^ rankidi) lt ; rank (dj) lt ; matchiq , dª) gt ; match (q , dj) (4.6) sparck jones | sparck jones , 1972] and others have historically referred to a document 's rank in retr as its `` coordination level '' (cf. eq . 3.36) . strictly speaking , coordination level refers to the number of assessing the retrieval 125 keywords shared by document and query . in boolean-retrieval systems , sensitive only to the presence or absence of keywords , ranking by coordination level may be the only available measure on document/query similarity . for long-queries , hitlist rank and coordination level are likely to be similar , because it is unlikely that different documents will match exactly the same number of words from the query . but for short queries , it is likely that coordination level will only partially order the retr set . this is why van rijsbergen , p. 161 , speaking of the boolean systems typical at that time , said , `` unfortunately , the ranking generated by a matching-function is rarely a simple ordering , but more commonly a weak-ordering . '' most modern search-engines , however , exploit keyword weightings and can provide much more refined measures , thereby providing a total-ordering of the hitlist . according to the-probability-ranking-principle (cf. section 5.5.1) , a retrieval-system is performing optimally if it retrieves documents in order of decreasing probability-of-relevance . for now we simply assume that there is a total-ordering imposed over retr . we will use the hitlist ranking to effectively define a series of retrievals . setting a very high threshold on this ordering would mean retrieving a very small set , while setting a lower threshold will retrieve a much larger one . now consider a particular query q and the set relq of relevant documents associated with it . assuming that retr is totally ordered makes it possible for us to define the fundamental analytic tool for search-engine-performance : the recall/precision curve (re/pre curve) . the basic procedure is to consider each retrieved document in hitlist rank-order and to ask for the precision-and-recall of the retrieval of all documents up to and including this one . consider the first of the two hypothetical retrievals shown in table 4.2 . with respect to this query , we will assume there are exactly five relevant documents out of a total of 25 in the corpus . the very first one retrieved is deemed relevant ; if we stopped retrieval at this point , our recall would be 0.2 (because we would have retrieved one of five relevant documents) , and our precision is perfect (the one retrieved document is relevant) . our good luck continues as we consider the next document , which is also relevant ; this generates a second re/pre data point of (0.4,1.0) . we are not so lucky with the third document retrieved ; precision drops to 0.67 and recall remains at 0.4 . proceeding down the 126 finding out about table 4.2 two hypothetical retrievals query 1 query 2 relevant ? nrel recall precision relevant ? nrel recall precision 1 1 1 0.20 1.00 0 0 0.00 0.00 2 1 2 0.40 1.00 0 0 0.00 0.00 3 0 2 0.40 0.67 0 0 0.00 0.00 4 1 3 0.60 0.75 1 1 0.50 0.25 5 0 3 0.60 0.60 0 1 0.50 0.20 6 0 3 0.60 0.50 0 1 0.50 0.17 7 0 3 0.60 0.43 0 1 0.50 0.14 8 0 3 0.60 0.38 0 1 0.50 0.13 9 0 3 0.60 0.33 0 1 0.50 0.11 10 0 3 0.60 0.30 0 1 0.50 0.10 11 0 3 0.60 0.27 0 1 0.50 0.09 12 0 3 0.60 0.25 0 1 0.50 0.08 13 0 3 0.60 0.23 0 1 0.50 0.08 14 0 3 0.60 0.21 0 1 0.50 0.07 15 1 4 0.80 0.27 1 2 1.00 0.13 16 0 4 0.80 0.25 0 2 1.00 0.13 17 0 4 0.80 0.24 0 2 1.00 0.12 18 0 4 0.80 0.22 0 2 1.00 0.11 19 0 4 0.80 0.21 0 2 1.00 0.11 20 0 4 0.80 0.20 0 2 loo 0.10 21 0 4 0.80 0.19 0 2 loo 0.10 22 0 4 0.80 0.18 0 2 loo 0.09 23 0 4 0.80 0.17 0 2 loo 0.09 24 0 4 0.80 0.17 0 2 loo 0.08 25 1 5 1.00 0.20 0 2 loo 0.08 retrieval in rank-order , and plotting each point in this fashion gives the re/pre curve shown in figure 4.10 . at this point we can already make several observations . asymptotically , we know that the final recall must go to one ; once we have retrieved every document we 've also retrieved every relevant-document . the precision will be the ratio of the number of relevant documents to the total corpus-size . ordinarily , unless we are interested in very general queries or very small sets of documents , this ratio will be very close to zero . the other end of the curve , however , turns out to be much less stable . we would hope that a retrieval-system 's very first candidate for retrieval , the document with hitlist rank = 1 , will be relevant , but it may not be . assessing the retrieval 127 1.00 0.90 ¶ 0.80 ¶ 0.70 -0.60 -0.50 -0.40 - 0.30 - ï 0.20 - ¶ 0.10 - 0.00 0.00 0.10 0.20 0.30 0.40 0.50 recall 0.60 0.70 0.80 0.90 1.00 figure 4.10 recall/precision curve loo ¶ 0.90 ¶ 0.80 -0.70 -0.60 - 0.50 - 0.40 ¶ 0.30 -0.20 -0.10 - 0.00 0.00 0.10 0.20 0.30 0.40 0.50 0.60 0.70 0.80 recall figure 4.11 instability of beginning of re/pre curve 0.90 loo figure 4.11 shows a second pair of hypothetical data points (dashed line) , corresponding to the case that a single irrelevant document is ranked higher than the relevant ones . this relatively small-change in assessment creates a fairly dramatic effect on the curve , with real consequence once 128 finding out about 0.00 0.00 0.10 0.20 0.30 0.40 0.50 0.60 0.70 0.80 recall figure 4.12 best/worst retrieval envelope 0.90 loo we need to juxtapose multiple-queries ' curves (see section 43.7) . such instability is an inevitable consequence of the definitions ofprecision and recall : if the first retrieved document happens to be relevant , its re/pre coordinates will be less than 1 , and ~ ^ j greater than 1 ; otherwise it will belt ; 0gt ; ggt ; . figure 4.12 puts this particular retrieval in the context of the best and worst retrievals we might imagine . the best possible retrieval (hashed) would be to retrieve the five relevant documents first , and then all other documents . this would produce the upper , square re/pre curve . alternatively , the worst possible retrieval (shaded) would retrieve all but the relevant documents before returning these ; this produces the lower line .