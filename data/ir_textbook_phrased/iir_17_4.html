centroid-clustering (207) (208) (209) 207 209 different 17.3 17.3 figure 17.11 shows the first three steps of a centroid-clustering . the first two iterations form the clusters with centroid and with centroid because the pairs and have the highest centroid similarities . in the third iteration , the highest centroid similarity is between and producing the cluster with centroid . like gaac , centroid-clustering is not best-merge persistent and therefore (exercise 17.10) . in contrast to the other three hac algorithms , centroid-clustering is not monotonic . so-called inversions can occur : similarity can increase during clustering as in the example in figure 17.12 , where we define similarity as negative distance . in the first merge , the similarity of and is . in the second merge , the similarity of the centroid of and (the circle) and is . this is an example of an inversion : similarity increases in this sequence of two clustering steps . in a monotonic hac algorithm , similarity is monotonically decreasing from iteration to iteration . increasing similarity in a series of hac clustering steps contradicts the fundamental assumption that small clusters are more coherent than large clusters . an inversion in a dendrogram shows up as a horizontal merge line that is lower than the previous merge line . all merge-lines in and 17.5 are higher than their predecessors because single-link and complete-link-clustering are monotonic clustering-algorithms . despite its non-monotonicity , centroid-clustering is often used because its similarity-measure - the similarity of two centroids - is conceptually simpler than the average of all pairwise similarities in gaac . figure 17.11 is all one needs to understand centroid-clustering . there is no equally simple graph that would explain how gaac works . exercises . for a fixed set of documents there are up to distinct similarities between clusters in single-link and complete-link-clustering . how many distinct cluster similarities are there in gaac and centroid-clustering ?