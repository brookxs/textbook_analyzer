clustering in information-retrieval cluster-hypothesis cluster-hypothesis . documents in the same cluster behave similarly with respect to relevance to information-needs . 14 14 table 16.1 : some applications of clustering in information-retrieval . application what is benefit example clustered ? search-result-clustering search-results more effective information-presentation to user figure 16.2 scatter-gather (subsets of) collection alternative user-interface : `` search without typing '' figure 16.3 collection clustering collection effective information-presentation for exploratory-browsing mckeown et al. (2002) , http://news.google.com language-modeling collection increased precision and/or recall liu and croft (2004) cluster-based-retrieval collection higher efficiency : faster search salton (1971a) table 16.1 shows some of the main applications of clustering in information-retrieval . they differ in the set of documents that they cluster - search-results , collection or subsets of the collection - and the aspect of an information-retrieval-system they try to improve - user-experience , user-interface , effectiveness or efficiency of the search-system . but they are all based on the basic assumption stated by the cluster-hypothesis . clustering of search-results to improve recall . none of the top hits cover the animal sense of jaguar , but users can easily access it by clicking on the cat cluster in the clustered results panel on the left (third arrow from the top) . the first application mentioned in table 16.1 is search-result-clustering where by search-results we mean the documents that were returned in response to a query . the default presentation of search-results in information-retrieval is a simple list . users scan the list from top to bottom until they have found the information they are looking for . instead , search-result-clustering clusters the search-results , so that similar documents appear together . it is often easier to scan a few coherent groups than many individual documents . this is particularly useful if a search-term has different word-senses . the example in figure 16.2 is jaguar . three frequent senses on the web refer to the car , the animal and an apple operating-system . the clustered results panel returned by the viv√≠simo search-engine (http://vivisimo.com) can be a more effective user-interface for understanding what is in the search-results than a simple list of documents . an example of a user-session in scatter-gather . a collection of new york times news stories is clustered (`` scattered '') into eight clusters (top row) . the user manually gathers three of these into a smaller collection international stories and performs another scattering operation . this process repeats until a small cluster with relevant documents is found (e.g. , trinidad) . a better user-interface is also the goal of scatter-gather , the second application in table 16.1 . scatter-gather clusters the whole collection to get groups of documents that the user can select or gather . the selected groups are merged and the resulting set is again clustered . this process is repeated until a cluster of interest is found . an example is shown in figure 16.3 . automatically generated clusters like those in figure 16.3 are not as neatly organized as a manually constructed hierarchical-tree like the open-directory at http://dmoz.org . also , finding descriptive labels for clusters automatically is a difficult problem (section 17.7 , page 17.7) . but cluster-based navigation is an interesting alternative to keyword searching , the standard information-retrieval-paradigm . this is especially true in scenarios where users prefer browsing over searching because they are unsure about which search-terms to use . as an alternative to the user-mediated iterative-clustering in scatter-gather , we can also compute a static hierarchical-clustering of a collection that is not influenced by user-interactions (`` collection clustering '' in table 16.1) . google-news and its precursor , the columbia newsblaster system , are examples of this approach . in the case of news , we need to frequently recompute the clustering to make sure that users can access the latest breaking stories . clustering is well suited for access to a collection of news stories since news reading is not really search , but rather a process of selecting a subset of stories about recent events . the fourth application of clustering exploits the cluster-hypothesis directly for improving search-results , based on a clustering of the entire collection . we use a standard inverted-index to identify an initial set of documents that match the query , but we then add other documents from the same clusters even if they have low similarity to the query . for example , if the query is car and several car documents are taken from a cluster of automobile documents , then we can add documents from this cluster that use terms other than car (automobile , vehicle etc) . this can increase recall since a group of documents with high mutual similarity is often relevant as a whole . more recently this idea has been used for language-modeling . equation 102 , page 102 , showed that to avoid sparse-data problems in the language-modeling-approach to ir , the model of document can be interpolated with a collection model . but the collection contains many documents with terms untypical of . by replacing the collection model with a model derived from 's cluster , we get more accurate estimates of the occurrence probabilities of terms in . clustering can also speed up search . as we saw in section 6.3.2 (page 6.3.2) search in the vector-space-model amounts to finding the nearest-neighbors to the query . the inverted-index supports fast nearest-neighbor-search for the standard ir setting . however , sometimes we may not be able to use an inverted-index efficiently , e.g. , in latent-semantic-indexing (chapter 18) . in such cases , we could compute the similarity of the query to every document , but this is slow . the cluster-hypothesis offers an alternative : find the clusters that are closest to the query and only consider documents from these clusters . within this much smaller set , we can compute similarities exhaustively and rank documents in the usual way . since there are many fewer clusters than documents , finding the closest cluster is fast ; and since the documents matching a query are all similar to each other , they tend to be in the same clusters . while this algorithm is inexact , the expected decrease in search-quality is small . this is essentially the application of clustering that was covered in section 7.1.6 (page 7.1.6) . exercises . define two documents as similar if they have at least two proper-names like clinton or sarkozy in common . give an example of an information-need and two documents , for which the cluster-hypothesis does not hold for this notion of similarity . make up a simple one-dimensional example (i.e. points on a line) with two clusters where the inexactness of cluster-based-retrieval shows up . in your example , retrieving clusters close to the query should do worse than direct nearest-neighbor-search .