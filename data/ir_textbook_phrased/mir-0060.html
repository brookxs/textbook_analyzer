3.2.2 alternative measures since recall and precision , despite their popularity , are not always the most appropriate measures for evaluating retrieval-performance , alternative measures have been proposed over the years . a brief review of some of them is as follows . the harmonic mean as discussed above , a single measure which combines recall and precision might be of interest . one such measure is the harmonic mean f of recall and precision [422] which is computed as where r (j) is the recall for the j-th document in the ranking , p (j) is the precision for the j-th document in the ranking , and f (j) is the harmonic mean of r (j) and p (j) (thus , relative to the j-th document in the ranking) . the function f assumes values in the interval [0,1] . it is 0 when no relevant documents have been retrieved and is 1 when all ranked documents are relevant . further , the harmonic mean f assumes a high value only when both recall and precision are high . therefore , determination of the maximum value for f can be interpreted as an attempt to find the best possible compromise between recall and precision . the e measure another measure which combines recall and precision was proposed by van ri-jsbergen [785] and is called the e evaluation-measure . the idea is to allow the user to specify whether he is more interested in recall or in precision . the e measure is defined as follows . where r (j) is the recall for the j-th document in the ranking , p (j) is the precision for the j-th document in the ranking , e (j) is the e evaluation-measure relative to r (j) and p {j) , and b is a user specified parameter which reflects the relative-importance of recall and precision . for 6 = 1 , the e (j) measure works as the complement of the harmonic mean f (j) . values of b greater than 1 indicate that the user is more interested in precision than in recall while values of b smaller than i indicate that the user is more interested in recall than in precision . retrieval-performance evaluation 83 user-oriented measures recall and precision are based on the assumption that the set of relevant documents for a query is the same , independent of the user . however , different users might have a different interpretation of which document is relevant and which one is not . to cope with this problem , user-oriented measures have been proposed such as coverage ratio , novelty ratio , relative recall , and recall effort [451] . as before , consider a reference collection , an example information request / , and a retrieval-strategy to be evaluated . let r be the set of relevant documents for / and a be the answer set retrieved . also , let u be the subset of r which is known to the user . the number of documents in u is \ u \ . the intersection of the sets a and u yields the documents known to the user to be relevant which were retrieved . let \ rk \ be the number of documents in this set . further , let \ ru \ be the number of relevant documents previously unknown to the user which were retrieved . figure 3.6 illustrates the situation . the coverage ratio is defined as the fraction of the documents known (to the user) to be relevant which has actually been retrieved i.e. , coverage = \ rk \ \ u \ the novelty ratio is defined as the fraction of the relevant documents retrieved which was unknown to the user i.e. , novelty = \ ru \ \ ru \ + \ rk \ a high-coverage ratio indicates that the system is finding most of the relevant documents the user expected to see . a high novelty ratio indicates that the system is revealing (to the user) many new relevant documents which were previously unknown . relevant docs relevant docs known to the user m answer set relevant docs known to the user which were retrieved \ rk \ relevant docs previously unknown to the user which were retrieved figure 3.6 coverage and novelty ratios for a given example information request . 84 retrieval-evaluation additionally , two other measures can be defined as follows . the relative recall is given by the ratio between the number of relevant documents found (by the system) and the number of relevant documents the user expected to find . in the case when the user finds as many relevant documents as he expected , he stops searching and the relative recall is equal to 1 . the recall effort is given by the ratio between the number of relevant documents the user expected to find and the number of documents examined in an attempt to find the expected relevant documents . other measures other measures which might be of interest include the expected search length , which is good for dealing with sets of documents weakly ordered , the satisfaction , which takes into account only the relevant documents , and the frustration , which takes into account only the non-relevant documents [451] .