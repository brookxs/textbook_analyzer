8.6.1 string-matching allowing errors this problem (called `` approximate-string-matching ') can be stated as follows : given a short pattern p of length m , a long text t of length n , and a maximum allowed number of errors fc , find all the text positions where the pattern occurs with at most k errors . this statement corresponds to the levenshtein-distance . with minimal modifications it is adapted to searching whole wrords matching the pattern with k errors . this problem is newer than exact string-matching , although there are already a number of solutions . we sketch the main approaches . dynamic-programming the classical solution to approximate-string-matching is based on dynamic-programming . a matrix c [0 . . m ,0 . . nj is filled column by column , where c [? \ jj pattern-matching 217 represents the minimum number of errors needed to match pi . . $ to a suffix of ti , , j . this is computed as follows c [0j] = 0 c [t ,0] = i c [ij] = if (pi = tj) then c [i-lj ~ i] else 1 + min (c [i - lj] , c [i , j - l] , c [i - 1 , j - 1]) where a match is reported at text positions j such that c [m , j] lt ; k (the final positions of the occurrences are reported) . therefore , the algorithm is o (mn) time . since only the previous column of the-matrix is needed , it can be implemented in o (m) space . its preprocessing time is o (m) . figure 8.21 illustrates this algorithm . in recent years several algorithms have been presented that achieve o (kn) time in the worst-case or even less in the average case , by taking advantage of the properties of the dynamic-programming matrix (e.g. , values in neighbor cells differ at most by one) . automaton it is interesting to note that the problem can be reduced to a non-deterministic finite automaton (nfa) . consider the nfa for k = 2 errors shown in figure 8.22 . each row denotes the number of errors seen . the first one 0 , the second one 1 , and so on . every column represents matching the pattern up to a given position . at each iteration , a new text character is read and the automaton changes its states . horizontal arrows represent matching a character , vertical arrows represent insertions into the pattern , solid diagonal arrows represent replacements , and dashed diagonal arrows represent deletions in the pattern (they are ^ - transitions) . the automaton accepts a text position as the end of a match s u r g e r y 0 0 0 0 0 0 0 0 s i 0 1 1 1 1 1 i u 2 1 0 1 2 2 2 2 r 3 2 1 0 1 2 2 3 v 4 3 2 1 1 2 3 3 e 5 4 3 2 2 1 2 3 y 6 5 4 3 3 2 2 2 figure 8.21 the dynamic-programming-algorithm search ` survey ' in the text ` surgery '' with two errors . bold entries indicate matching positions . 218 indexing and searching 1 error 2 errors figure 8.22 an nfa for approximate-string-matching of the pattern ` survey ' with two errors . the shaded states are those active after reading the text ` surgery ' . unla-belled transitions match anv character . with k errors whenever the (fc - f l) - th rightmost state is active . it is not hard to see that once a state in the automaton is active , all the states of the same column and higher rows are active too . moreover , at a given text character , if we collect the smallest active rows at each column , we obtain the current column of the dynamic-programming-algorithm . figure 8.22 illustrates this (compare the figure with figure 8.21) . one solution is to make this automaton deterministic (dfa) . although the search phase is o (7i) , the dfa can be huge . an alternative solution is based on bit-parallelism and is explained next . bit-parallelism bit-parallelism has been used to parallelize the computation of the dynamic-programming matrix (achieving average complexity o (kn/w)) and to parallelize the computation of the nfa (without converting it to deterministic) , obtaining o (knwlw) time in the worst-case . such algorithms achieve o (n) search-time for short patterns and are currently the fastest ones in many cases , running at 6 to 111 mb per second on our reference machine . filtering finally , oilier approaches first filter the text , reducing the area where1 dynamic-programming needs to be used . these algorithms achieve ` sublinear * expected time in many causes for low error ratios (i.e. , not all text characters are inspected . pattern-matching 219 o (kn \ oga {m) / m) is a typical figure) , although the nitration is not effective for more errors . filtration is based on the fact that some portions of the pattern must appear with no errors even in an approximate occurrence . the fastest algorithm for low error levels is based on filtering : if the pattern is split into / c +1 pieces , any approximate occurrence must contain at least one of the pieces with no errors , since k errors can not alter all the k + 1 pieces . hence , the search begins with a multipattern exact search for the pieces and it later verifies the areas that may contain a match (using another algorithm) .