context-sensitive spelling-correction 3.3.4 this enumeration can be expensive if we find many corrections of the individual terms , since we could encounter a large number of combinations of alternatives . several heuristics are used to trim this space . in the example above , as we expand the alternatives for flew and form , we retain only the most frequent combinations in the collection or in the query-logs , which contain previous queries by users . for instance , we would retain flew from as an alternative to try and extend to a three-term corrected query , but perhaps not fled fore or flea form . in this example , the biword fled fore is likely to be rare compared to the biword flew from . then , we only attempt to extend the list of top biwords (such as flew from) , to corrections of heathrow . as an alternative to using the biword statistics in the collection , we may use the logs of queries issued by users ; these could of course include queries with spelling errors . exercises . if denotes the length of string , show that the edit-distance between and is never more than compute the edit-distance between paris and alice . write down the array of distances between all prefixes as computed by the algorithm in figure 3.5 . write pseudocode showing the details of computing on-the-fly the jaccard-coefficient while scanning the postings of the - gram index , as mentioned on page 3.3.4 . compute the jaccard coefficients between the query bord and each of the terms in figure 3.7 that contain the bigram or . consider the four-term query catched in the rye and suppose that each of the query terms has five alternative terms suggested by isolated-term correction . how many possible corrected phrases must we consider if we do not trim the space of corrected phrases , but instead try all six variants for each of the terms ? for each of the prefixes of the query -- catched , catched in and catched in the -- we have a number of substitute prefixes arising from each term and its alternatives . suppose that we were to retain only the top 10 of these substitute prefixes , as measured by its number of occurrences in the collection . we eliminate the rest from consideration for extension to longer prefixes : thus , if batched in is not one of the 10 most common 2-term queries in the collection , we do not consider any extension of batched in as possibly leading to a correction of catched in the rye . how many of the possible substitute prefixes are we eliminating at each phase ? are we guaranteed that retaining and extending only the 10 commonest substitute prefixes of catched in will lead to one of the 10 commonest substitute prefixes of catched in the ?