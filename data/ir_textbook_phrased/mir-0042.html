2.8.2 inference-network model the two most traditional schools of thought in probability are based on the frequentist view and the epistemological view . the frequentist view takes probability as a statistical notion related to the laws of chance . the epistemological 50 modeling figure 2.9 basic inference-network model . view interprets probability as a degree of belief whose specification might be devoid of statistical experimentation . this second viewpoint is important because we frequently refer to probabilities in our daily lives without a clear definition of the statistical experiment which yielded those probabilities . the inference-network model [772 , 771] takes an epistemological view of the information-retrieval problem . it associates random variables with the index-terms , the documents , and the user queries . a random-variable associated with a document dj represents the event of observing that document (i.e. , the model assumes that documents are being observed in the search for relevant documents) . the observation of the document dj asserts a belief upon the random variables associated with its index-terms . thus , observation of a document is the cause for an increased belief in the variables associated with its index-terms . index term and document variables are represented as nodes in the network . edges are directed from a document node to its term nodes to indicate that observation of the document yields improved belief on its term nodes . the random-variable associated with the user-query models the event that the information request specified by the query has been met . this random-variable is also represented by a node in the network . the belief in this (query) node is a function of the beliefs in the nodes associated with the query terms . thus , edges are directed from the index term nodes to the query node . figure 2.9 illustrates an inference-network for information-retrieval . the document d3 has a ? 2 , kii and kt as its index-terms . this is modeled by directing the edges from the node d3 to the nodes 2 , k ^ and kt . the query q is composed of the index-terms k \ , 2 , and fcj . this is modeled by directing the edges from the nodes k \ % 2 * and k {to the node q. notice that figure 2.9 also includes three extra nodes : q2 , # 1 , and / . the nodes $ 2 and qi are used to model an (alternative) boolean formulation qj for the query q (in this case , q \ = (k \ a klt ; i) v kt) . when such alternative probabilistic-models 51 (additional) information is available , the user-information need / is supported by both q and q \ . in what follows , we concentrate our attention on the support provided to the query node q by the observation of a document d3 . later on , we discuss the impact of considering multiple query representations for an information-need / . this is important because , as turtle and croft have demonstrated , a keyword-based query formulation (such as q) can be combined with a boolean-like query-formulation (such as q {-rrb- to yield improved retrieval-performance for the same information-need . the complete inference-network model also includes text nodes and query-concept nodes but the model discussed above summarizes the essence of the approach . a simplifying assumption is made which states that all random variables in the network are binary . this seems arbitrary but it does simplify the modeling task and is general enough to capture all the important relationships in the information-retrieval problem . definition let k be a t-dimensional vector defined by k = (i , 2 , ï ï ï , kt) where k \ , k2 , ... , kt are binary random variables i.e. , k % ä {0,1} . these variables define the 2l possible states for k. further , let d3 be a binary random-variable associated with a document dj and let q be a binary random-variable associated with the user-query . notice that q is used to refer to the query , to the random-variable associated with it , and to the respective node in the network . this is also the case for dj and for each index term ki . we allow this overloading in syntax because it should always be clear whether we are referring to either the query or to its associated random-variable . the ranking of a document dj with respect to a query q is a measure of how much evidential support the observation of dj provides to the query q . in an inference-network , the ranking of a document dj is computed as p (q a dj) where q and d3 are short representations for q = 1 and dj = 1 , respectively . in general , such a ranking is given by vfc va : p (qadj) = l-p (qadj) 52 modeling which is obtained by basic conditioning and the application of bayes ' rule . notice that p {q \ dj x k) = p (q \ k) because the ki nodes separate the query node q from the document node d3 . also , the notation q a dj is a short representation for the instantiation of a document node d3 (i.e. , the observation of the document) separates its children index term nodes making them mutually independent (see bayesian-theory for details) . thus , the degree of belief asserted to each index term node ki by instantiating the document node dj can be computed separately . this implies that p (k \ d3) can be computed in product-form which yields (from equation 2.6) , p (q / \ dj) = tp (q \ k) x p {k % \ dj)] x p (d3) (2.7) p {q / \ d3) = l-p (q / \ dj where p {ki \ d3) = 1 - p {kl \ d3) . through proper specification of the probabilities p (q \ k) i p (kt \ dj) , and p (dj) , we can make the inference-network cover a wide range of useful information-retrieval ranking strategies . later on , we discuss how to use an inference-network to subsume the boolean-model and tf-idf ranking schemes . let us first cover the specification of the p (d3) probabilities . prior-probabilities for inference-networks since the document nodes are the root nodes in an inference-network , they receive a prior-probability distribution which is of our choosing . this prior-probability reflects the probability associated to the event of observing a given document dj (to simplify matters , a single-document node is observed at a time) . since we have no prior preferences for any document in particular , we usually adopt a prior-probability distribution which is uniform . for instance , in the original work on inference-networks [772 , 771] , the probability of observing a document d3 is set to l/n where n is the total number of documents in the system . thus , the choice of the value 1/ar for the prior-probability p {dj) is a simple and natural specification given that our collection is composed of n documents . however , other specifications for p (d3) might also be interesting . for instance , in the cosine formula of the vector-model , the contribution of an index term to alternative probabilistic-models 53 the rank of the document d3 is inversely proportional to the norm of the vector dj . the larger the norm of the document vector , the smaller is the relative contribution of its index-terms to the document final rank . this effect can be taken into account through proper specification of the prior-probabilities p (dj) as follows . = \ - p {d3) where \ d3 | stands for the norm of the vector d3 . therefore , in this case , the larger the norm of a document-vector , the smaller its associated prior-probability . such specification reflects a prior-knowledge that we have about the behavior of vector-based ranking strategies (which normalize the ranking in the document space) . as commanded by bayesian postulates , previous knowledge of the application-domain should be asserted in the specification of the priors in the network , as we have just done . inference-network for the boolean-model here we demonstrate how an inference-network can be tuned to subsume the boolean-model . first , for the boolean-model , the prior-probabilities p {d3) are all set to i/at because the boolean-model makes no prior distinction on documents . thus , p (d3) = i regarding the conditional-probabilities p (ki \ dj) and p (q \ k) , the specification is as follows . 0 otherwise p (kt \ dj) = l-pihldj) which basically states that , when the document dj is being observed , only the nodes associated with the index-terms of the document dj are active (i.e. , have an induced probability greater than 0) . for instance , observation of a document node dj whose term vector is composed of exactly the index-terms a :2 , kt , and kt (see figure 2.9) activates the index term nodes {k2 , kt , kt} and no others . once the beliefs in the index term nodes have been computed , we can use them to compute the evidential support they provide to the user-query q as 54 modeling follows . p (q \ k) = / 1 if 3 $ ô i (qcc ä qdnf) a (vfct , 9i {k) = gi (qcc)) 1 ; \ 0 otherwise p {q \ k) = 1-p (lt ; ? | fc) where qcc and gdn / are as defined for the classic boolean-model . the above equation basically states that one of the conjunctive components of the user-query (expressed in disjunctive-normal-form) must be matched by the set of active terms in k (in this case , those activated by the document observed) exactly . substituting the above definitions for p (q \ h) , p (ki \ dj) , and p (dj) into equation 2.7 , it can be easily shown that the set of documents retrieved is exactly the set of documents returned by the boolean-model as defined in section 2.5.2 . thus , an inference-network can be used to subsume the boolean-model without difficulties . inference-network for tf-idf ranking strategies for tf-idf ranking strategies (i.e. , those related to the vector-model) , we adopt prior-probabilities which reflect our prior-knowledge of the importance of document-normalization . thus , we set the prior p (dj) to l / | dj | as follows . p (dj) = -1 - (2.8) p (dj) = 1 further , we have to decide where to introduce the tf (term-frequency) and the idf (inverse-document-frequency) factors in the network . for that purpose , we consider that the tf and idf factors are normalized (as in equation 2.1) and that these normalized factors are strictly smaller than 1 . we first focus on capturing the impact of the tf factors in the network . normalized tf factors are taken into account through the beliefs asserted upon the index term nodes as follows . p (ki \ dj) = fij (2.9) these equations simply state that , according to the observed document dj , the relevance of a term hi is determined by its normalized term-frequency factor . we are now in a position to consider the influence of idf factors . they are taken into account through the specification of the impact of index term nodes alternative probabilistic-models 55 on the query node . define a vector ki given by , ki = k \ (9i (k) = 1 a v ^ 9j {%) = 0) the vector k % is a reference to the state of the vector k in which the node ki is active and all others are inactive . the motivation is that tf-idf ranking strategies sum up the individual-contributions of index-terms and ki allows us to consider the influence of the term ki in isolation . we are now ready to define the influence of the index term nodes in the query node q as _ i idfi if k = ha gi (q) = 1 ('' \ o if j ^ # vft ($) = o (2 * 10) p (q \ k) = 1-p (q \ k) where idfz here is a normalized version of the idf factor defined in equation 2.2 . by applying equations 2.8 , 2.9 , and 2.10 to equation 2.7 , we can then write jj x ói p {ds) i = f ijpcjfeil ^)) x p {dj) x y ^ p (ki \ di) x __ i ' y _____ v \ t ¶ v 1 / 7 t v óóóóóóóó ky t a 15 lt ; * ª 7 11 1 a 6ci / 2 ^ mjl vt rf - ~ ^ a (g = 1 1 ~ ^ j = l-pfgad , -) which provides a tf-idf-like ranking . unfortunately , cj depends on a product of the various probabilities p (ki \ dj) which vary from document to document and thus the ranking is distinct from the one provided by the vector-model . despite this peculiarity in the tf-idf ranking generated , it has been shown that an inference-network is able to provide good retrieval-performance with general collections . the reason is that the network allows us to consistently combine evidence from distinct evidential sources to improve the final ranking , as we now discuss . combining evidential sources in figure 2.9 , the first query node q is the standard keyword-based query-formulation for the user-information need / . the second query q \ is a boolean-iike query-formulation for the same information-need (i.e. , an additional evidential source collected from a specialist) . the joint support these two query formulations provide to the information-need node / can be modeled through , for 56 modeling instance , an or operator (i.e. , / = q v qi) . in this case , the ranking provided by the inference-network is computed as , p (i a dj) = ^ 2 pcw x p (k \ do) x p (ds) k = x ^ 1 ~ p (5l *) p (^)) x p (^ ldi) x p (^) k which might yield a retrieval-performance which surpasses the retrieval-performance obtained with each of the query nodes in isolation as demonstrated in [771] .