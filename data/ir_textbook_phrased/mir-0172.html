9.3.3 source-selection source-selection is the process of determining which of the distributed document-collections are most likely to contain relevant documents for the current query , and therefore should receive the query for processing . one approach is to always assume that every collection is equally likely to contain relevant documents and simply broadcast the query to all collections . this approach is appropriate when documents are randomly partitioned or there is significant semantic overlap between the collections . when document-collections are partitioned into semantically meaningful collections or it is prohibitively expensive to search every collection every time , the collections can be ranked according to their likelihood of containing relevant documents . the basic technique is to treat each collection as if it were a single large document , index the collections , and evaluate the query against the collections to produce a ranked listing of collections . we can apply a standard cosine-similarity-measure using a query-vector and collection vectors . to calculate a term-weight in the collection vector using tf-idf style weighting (see chapter 2) , term-frequency tf-hj is the total number of occurrences of term i in collection j , and the inverse-document-frequency idft for term i is log (jv/nj) , where n is the total number of collections and nt is the number of collections in which terin i appears . a danger of this approach is that although a particular collection may receive a high query-relevance score , there may not be individual documents within the collection that receive a high query-relevance score , essentially resulting in a false drop and unnecessary work to score the collection . moffat and zobel [574] distributed-ir 253 propose avoiding this problem by indexing each collection as a series of blocks , where each block contains b documents . when b equals 1 , this is equivalent to indexing all of the documents as a single , monolithic collection . when b equals the number of documents in each collection , this is equivalent to the original solution . by varying # ? , a tradeoff is made between collection-index size and likelihood of false drops . an alternative to searching a collection-index was proposed by voorhees [792] , who proposes using training queries to build a content-model for the distributed-collections . when a new query is submitted to the system , its similarity to the training queries is computed and the content-model is used to determine which collections should be searched and how many hits from each collection should be returned .