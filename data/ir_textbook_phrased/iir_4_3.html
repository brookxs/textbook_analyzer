single-pass in-memory indexing single-pass in-memory indexing spimi figure 4.4 : inversion of a block in single-pass in-memory indexing the spimi algorithm is shown in figure 4.4 . the part of the algorithm that parses documents and turns them into a stream of term-docid pairs , which we call tokens here , has been omitted . spimi-invert is called repeatedly on the token stream until the entire collection has been processed . tokens are processed one by one (line 4) during each successive call of spimi-invert . when a term occurs for the first time , it is added to the dictionary (best implemented as a hash) , and a new postings list is created (line 6) . the call in line 7 returns this postings list for subsequent occurrences of the term . a difference between bsbi and spimi is that spimi adds a posting directly to its postings list (line 10) . instead of first collecting all termid-docid pairs and then sorting them (as we did in bsbi) , each postings list is dynamic (i.e. , its size is adjusted as it grows) and it is immediately available to collect postings . this has two advantages : it is faster because there is no sorting required , and it saves memory because we keep track of the term a postings list belongs to , so the termids of postings need not be stored . as a result , the blocks that individual calls of spimi-invert can process are much larger and the index-construction process as a whole is more efficient . because we do not know how large the postings list of a term will be when we first encounter it , we allocate space for a short postings list initially and double the space each time it is full (lines 8-9) . this means that some memory is wasted , which counteracts the memory savings from the omission of termids in intermediate-data-structures . however , the overall memory-requirements for the dynamically constructed index of a block in spimi are still lower than in bsbi . when memory has been exhausted , we write the index of the block (which consists of the dictionary and the postings lists) to disk (line 12) . we have to sort the terms (line 11) before doing this because we want to write postings lists in lexicographic-order to facilitate the final merging step . if each block 's postings lists were written in unsorted order , merging blocks could not be accomplished by a simple linear-scan through each block . each call of spimi-invert writes a block to disk , just as in bsbi . the last step of spimi (corresponding to line 7 in figure 4.2 ; not shown in figure 4.4) is then to merge the blocks into the final inverted-index . in addition to constructing a new dictionary structure for each block and eliminating the expensive sorting step , spimi has a third important component : compression . both the postings and the dictionary terms can be stored compactly on disk if we employ compression . compression increases the efficiency of the algorithm further because we can process even larger blocks , and because the individual blocks require less space on disk . we refer readers to the literature for this aspect of the algorithm (section 4.7) . the time-complexity of spimi is because no sorting of tokens is required and all operations are at most linear in the size of the collection .