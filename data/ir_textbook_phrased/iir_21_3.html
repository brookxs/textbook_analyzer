hubs-and-authorities two hub score authority score this approach stems from a particular insight into the creation of web-pages , that there are two primary kinds of web-pages useful as results for broad-topic searches . by a broad topic search we mean an informational query such as `` i wish to learn about leukemia '' . there are authoritative sources-of-information on the topic ; in this case , the national cancer institute 's page on leukemia would be such a page . we will call such pages authorities ; in the computation we are about to describe , they are the pages that will emerge with high authority scores . on the other hand , there are many pages on the web that are hand-compiled lists of links to authoritative web-pages on a specific topic . these hub pages are not in themselves authoritative sources of topic-specific information , but rather compilations that someone with an interest in the topic has spent time putting together . the approach we will take , then , is to use these hub pages to discover the authority pages . in the computation we now develop , these hub pages are the pages that will emerge with high hub scores . a good hub page is one that points to many good authorities ; a good authority page is one that is pointed to by many good hub pages . we thus appear to have a circular definition of hubs-and-authorities ; we will turn this into an iterative-computation . suppose that we have a subset of the-web containing good hub and authority pages , together with the hyperlinks amongst them . we will iteratively compute a hub score and an authority score for every web-page in this subset , deferring the discussion of how we pick this subset until section 21.3.1 . for a web-page in our subset of the-web , we use to denote its hub score and its authority score . initially , we set for all nodes . we also denote by the existence of a hyperlink from to . the core of the iterative-algorithm is a pair of updates to the hub and authority scores of all pages given by equation 262 , which capture the intuitive notions that good hubs point to good authorities and that good authorities are pointed to by good hubs . (262) (263) 262 what happens as we perform these updates iteratively , recomputing hub scores , then new authority scores based on the recomputed hub scores , and so on ? let us recast the equations equation 262 into matrix-vector form . let and denote the vectors of all hub and all authority scores respectively , for the pages in our subset of the-web graph . let denote the adjacency-matrix of the subset of the-web graph that we are dealing with : is a square matrix with one row and one column for each page in the subset . the entry is 1 if there is a hyperlink from page to page , and 0 otherwise . then , we may write equation 262 (264) (265) 264 264 264 (266) (267) 266 18.1 266 (268) (269) this leads to some key consequences : the iterative updates in equation 262 (or equivalently , equation 264) , if scaled by the appropriate eigenvalues , are equivalent to the power-iteration method for computing the eigenvectors of and . provided that the principal eigenvalue of is unique , the iteratively computed entries of and settle into unique steady-state values determined by the entries of and hence the link-structure of the graph . in computing these eigenvector entries , we are not restricted to using the power-iteration method ; indeed , we could use any fast method for computing the principal-eigenvector of a stochastic matrix . the resulting computation thus takes the following form : assemble the target subset of web-pages , form the graph induced by their hyperlinks and compute and . compute the principal-eigenvectors of and to form the vector of hub scores and authority scores . output the top-scoring hubs and the top-scoring authorities . hits hyperlink-induced topic search worked example . assuming the query jaguar and double-weighting of links whose anchors contain the query word , the-matrix for figure 21.4 is as follows : (270) the hub and authority vectors are : (271) (272) here , is the main authority - two hubs (and) are pointing to it via highly weighted jaguar links . end worked example . since the iterative updates captured the intuition of good hubs and good authorities , the high-scoring pages we output would give us good hubs-and-authorities from the target subset of web-pages . in section 21.3.1 we describe the remaining detail : how do we gather a target subset of web-pages around a topic such as leukemia ? subsections choosing the subset of the-web