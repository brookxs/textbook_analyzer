index-term-weighting traditionally the two most important factors governing the effectiveness of an index language have been thought to be the exhaustivity of indexing and the specificity of the index language . there has been much debate about the exact-meaning of these two terms . not wishing to enter into this controversy i shall follow keen and digger [17] in giving a working definition of each . for any document , indexing exhaustivity is defined as the number of different topics indexed , and the index language specificity is the ability of the index language to describe topics precisely . keen and digger further define indexing specificity as the level of precision with which a document is actually indexed . it is very difficult to quantify these factors . human indexers are able to rank their indexing approximately in order of increasing exhaustivity or specificity . however , the same is not easily done for automatic-indexing . it is of some importance to be able to quantify the notions of indexing exhaustivity and specificity because of the predictable effect they have on retrieval-effectiveness . it has been recognised (lancaster [21]) that a high level of exhaustivity of indexing leads to high recall * and low precision * . conversely , a low level of exhaustivity leads to low recall and high precision . the converse is true for levels of indexing specificity , high specificity leads to high precision and low recall , etc. . it would seem , therefore , that there is an optimum level of indexing exhaustivity and specificity for a given user population . quite a few people (sparck jones [22 , 23] , salton and yang [24]) , have attempted to relate these two factors to document-collection statistics . for example , exhaustivity can be assumed to be related to the number of index-terms assigned to a given document , and specificity related to the number of documents to which a given term is assigned in a given collection . the importance of this rather vague relationship is that the two factors are related to the distribution of index-terms in the collection . the relationships postulated are consistent with the observed trade-off between precision-and-recall just mentioned . changes in the number of index-terms per document lead to corresponding changes in the number of documents per term and vice versa . i am arguing that in using distributional-information about index-terms to provide , say , index-term-weighting we are really attacking the old problem of controlling exhaustivity and specificity . * these terms are defined in the introduction on page 10 . if we go back to luhn 's original ideas , we remember that he postulated a varying discrimination-power for index-terms as a function of the rank-order of their frequency of occurrence , the highest discrimination-power being associated with the middle frequencies . his model was proposed for the selection of significant terms from a document . however , the same frequency-counts can be used to provide a weighting-scheme for the individual terms in a document . in fact , there is a common weighting-scheme in use which gives each index term a weight directly proportional to its frequency of occurrence in the document . at first this scheme would appear to be inconsistent with luhn 's hypothesis that the discrimination power drops off at higher frequencies . however , referring back to figure 2.1 , the scheme would be consistent if the upper cut-off is moved to the point where the peak occurs . it is likely that this is in fact what has happened in experiments using this particular form of weighting . attempts have been made to apply weighting based on the way the index-terms are distributed in the entire collection . the index term vocabulary of a document-collection often has a zipfian distribution , that is , if we count the number of documents in which each index term occurs and plot them according to rank-order , then we obtain the usual hyperbolic shape . sparck jones [22] showed experimentally that if there are n documents and an index term occurs in n of them then a weight of log (n/n) + 1 leads to more effective retrieval than if the term were used unweighted . if indexing specificity is assumed to be inversely proportional to the number of documents in which an index term occurs then the weighting can be seen to be attaching more importance to the more specific terms . the difference between the last mode of weighting and the previous one may be summarised by saying that document-frequency weighting places emphasis on content-description whereas weighting by specificity attempts to emphasise the ability of terms to discriminate one document from another . salton and yang [24] have recently attempted to combine both methods of weighting by looking at both inter document frequencies and intra document frequencies . their conclusions are really an extension of those reached by luhn . by considering both the total frequency of occurrence of a term and its distribution over the documents , that is , how many times it occurs in each document , they were able to draw several conclusions . a term with high total frequency of occurrence is not very useful in retrieval irrespective of its distribution . middle frequency terms are most useful particularly if the distribution is skewed . rare terms with a skewed-distribution are likely to be useful but less so than the middle frequency ones . very rare terms are also quite useful but come bottom of the list except for the ones with a high total frequency . the experimental-evidence for these conclusions is insufficient to make a more precise statement of their merits . salton and his co-workers have developed an interesting tool for describing whether an index is ` good ' or ` bad ' . they assume that a good index term is one which , when assigned as an index term to a collection of documents , renders the documents as dissimilar as possible , whereas a bad term is one which renders the documents more similar . this is quantified through a term discrimination value which for a particular term measures the increase or decrease in the average dissimilarity between documents on the removal of that term . therefore , a good term is one which on removal from the collection of documents , leads to a decrease in the average dissimilarity (adding it would hence lead to an increase) , whereas a bad term is one which leads on removal to an increase . the idea is that a greater separation between documents will enhance retrieval-effectiveness but that less separation will depress retrieval-effectiveness . although superficially this appears reasonable , what really is required is that the relevant documents become less separated in relation to the non-relevant ones . experiments using the term discrimination model have been reported [25 , 26] . a connection between term discrimination and inter document-frequency has also been made supporting the earlier results reported by salton , wong and yang [27] . the main results have been conveniently summarised by yu and salton [28] , where also some formal-proofs of retrieval-effectiveness improvement are given for strategies based on frequency data . for example , the inverse-document-frequency weighting-scheme described above , that is assigning a weight proportional to log (n/n) + 1 , is shown to be formally more effective than not using these weights . of course , to achieve a proof of this kind some specific assumptions about how to measure effectiveness and how to match documents with queries have to be made . they also establish the effectiveness of a technique used to conflate low frequency terms , which increases recall , and of a technique used to combine high-frequency terms into phrases , which increases precision .