the swets model * as early as 1963 swets [12] expressed dissatisfaction with existing methods of measuring retrieval-effectiveness . his background in signal-detection led him to formulate an evaluation-model based on statistical-decision-theory . in 1967 he evaluated some fifty different retrieval-methods from the point-of-view of his model [13] . the results of his evaluation were encouraging but not conclusive . subsequently , brookes [14] suggested some reasonable modifications to swets ' measure of effectiveness , and robertson [15] showed that the suggested modifications were in fact simply related to an alternative measure already suggested by swets . * bookstein [16] has recently re-examined this model showing how swets implicitly relied on an ` equal variance ' assumption . it is interesting that although the swets model is theoretically attractive and links ir measurements to a ready made and well-developed statistical-theory , it has not found general acceptance amongst workers in the field . before proceeding to an explanation of the swets model , it is as well to quote in full the conditions that the desired measure of effectiveness is designed to meet . at the beginning of his 1967 report swets states : ' a desirable measure of retrieval-performance would have the following properties : first , it would express solely the ability of a retrieval-system to distinguish between wanted and unwanted items - that is , it would be a measure of `` effectiveness '' only , leaving for separate consideration factors related to cost or `` efficiency '' . second , the desired measure would not be confounded by the relative willingness of the system to emit items - it would express discrimination-power independent of any `` acceptance criterion '' employed , whether the criterion is characteristic of the system or adjusted by the user . third , the measure would be a single number - in preference , for example , to a pair of numbers which may co-vary in a loosely specified way , or a curve representing a table of several pairs of numbers - so that it could be transmitted simply and immediately apprehended . fourth , and finally , the measure would allow complete ordering of different performances , and assess the performance of any one system in absolute terms - that is , the metric would be a scale with a unit , a true zero , and a maximum value . given a measure with these properties , we could be confident of having a pure and valid index of how well a retrieval-system (or method) were performing the function it was primarily designed to accomplish , and we could reasonably ask questions of the form `` shall we pay x dollars for y units of effectiveness ? '' . ' he then goes on to claim that ` the measure i proposed [in 1963] , one drawn from statistical-decision-theory , has the potential [my italics] to satisfy all four desiderata ' . so , what is this measure ? to arrive at the measure , we must first discuss the underlying model . swets defines the basic variables precision , recall , and fallout in probabilistic terms . recall = an estimate of the conditional-probability that an item will be retrieved given that it is relevant [we denote this p (b/a)] . precision = an estimate of the conditional-probability that an item will be relevant given that it is retrieved [i.e. p (a/b)] . fallout = an estimate of the conditional-probability that an item will be retrieved given that it is non-relevant [i.e. p (b / ` a] . he accepts the validity of measuring the effectiveness of retrieval by a curve either precision-recall or recall-fallout generated by the variation of some control variable [[lambda]] (e.g. co-ordination level) . he seeks to characterise each curve by a single number . he rejects precision-recall in favour of recall-fallout since he is unable to do it for the former but achieves limited success with the latter . in the simplest case we assume that the variable [[lambda]] is distributed normally on the set of relevant and non-relevant documents . the two distributions are given respectively by n (u1 , [[sigma]] 1) and n (u2 , [[sigma]] 2) . the density-functions are given by [[florin]] 1 ([[lambda]] | a) and [[florin]] 2 ([[lambda]] | ` a) . we may picture the distribution as shown in figure 7.5 . the usual set-up in ir is now to define a decision-rule in terms of [[lambda]] , to determine which documents are retrieved (the acceptance criterion) . in other words we specify [[lambda]] c such that a document for which the associated [[lambda]] exceeds [[lambda]] c is retrieved . we now measure the effectiveness of a retrieval-strategy by measuring some appropriate variables (such as r and p , or r and f) at various values of [[lambda]] c . it turns out that the differently shaded areas under the curves in figure 7.5 correspond to recall and fallout . moreover , we find the operating characteristic (oc) traced out by the point (f [[lambda]] , r [[lambda]]) due to variation in [[lambda]] c is a smooth curve fully determined by two points , in the general case of unequal variance , and by one point in the special case of equal variance . to see this one only needs to plot the (f [[lambda]] , r [[lambda]]) points on double probability paper (scaled linearly for the normal deviate) to find that the points lie on a straight line . a slope of 45deg . corresponds to equal variance , and otherwise the slope is given by the ratio of [[sigma]] 1 and [[sigma]] 2 . figure 7.6 shows the two cases . swets now suggests , regardless of slope , that the distance 0i (actually [[radical]] 20i) be used as a measure of effectiveness . this amounts to using : which is simply the difference between the means of the distribution normalised by the average standard-deviation . unfortunately this measure does rather hide the fact that a high s1 value may be due to a steep slope . the slope , and s1 , would have to be given which fails to meet swets ' second condition . we , also , still have the problem of deciding between two strategies whose oc 's intersect and hence have different s1 values and slopes . brookes [14] in an attempt to correct for the s1 bias towards systems with slopes much greater than unity suggested a modification to s1 . mathematically brookes 's measure is brookes also gives statistical reasons for preferring s2 to s1 which need not concern us here . geometrically s2 is the perpendicular distance from 0 to oc (see figure 7.6) . interestingly enough , robertson [15] showed that s2 is simply related to the area under the recall-fallout curve . in fact , the area is a strictly increasing function of s2 . it also has the appealing interpretation that it is equal to the percentage of correct choices a strategy will make when attempting to select from a pair of items , one drawn at random from the non-relevant set and one drawn from the relevant set . it does seem therefore that s2 goes a long way to meeting the requirements laid down by swets . however , the appropriateness of the model is questionable on a number of grounds . firstly , the linearity of the oc curve does not necessarily imply that [[lambda]] is normally distributed in both populations , although they will be ` similarly ' distributed . secondly , [[lambda]] is assumed to be continuous which certainly is not the case for the data checked out both by swets and brookes , in which the co-ordination level used assumed only integer values . thirdly , there is no evidence to suggest that in the case of more sophisticated matching-functions , as used by the smart system , that the distributions will be similarly distributed let alone normally . finally the choice of fallout rather than precision as second variable is hard to justify . the reason is that the proportion of non-relevant retrieved for large-systems is going to behave much like the ratio of ` non-relevant ' retrieved to ` total documents in system ' . for comparative purposes ` total document ' may be ignored leaving us with ` non-relevant retrieved ' which is complementary to ` relevant retrieved ' . but now we may as well use precision instead of fallout .