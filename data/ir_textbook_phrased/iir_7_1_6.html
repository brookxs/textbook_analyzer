cluster pruning cluster pruning pick documents at random from the collection . call these leaders . for each document that is not a leader , we compute its nearest leader . followers given a query , find the leader that is closest to . this entails computing cosine similarities from to each of the leaders . the candidate-set consists of together with its followers . we compute the cosine scores for all documents in this candidate-set . the use of randomly chosen leaders for clustering is fast and likely to reflect the distribution of the document vectors in the vector-space : a region of the vector-space that is dense in documents is likely to produce multiple leaders and thus a finer partition into sub-regions . this illustrated in figure 7.3 . figure 7.3 : cluster pruning . variations of cluster pruning introduce additional parameters and , both of which are positive integers . in the pre-processing step we attach each follower to its closest leaders , rather than a single closest leader . at query time we consider the leaders closest to the query . clearly , the basic scheme above corresponds to the case . further , increasing or increases the likelihood of finding documents that are more likely to be in the set of true top-scoring documents , at the expense of more computation . we reiterate this approach when describing clustering in chapter 16 (page 16.1) . exercises . we suggested above (figure 7.2) that the postings for static quality ordering be in decreasing order of . why do we use the decreasing rather than the increasing order ? when discussing champion lists , we simply used the documents with the largest tf values to create the champion list for . but when considering global champion lists , we used idf as well , identifying documents with the largest values of . why do we differentiate between these two cases ? if we were to only have one-term queries , explain why the use of global champion lists with suffices for identifying the highest scoring documents . what is a simple modification to this idea if we were to only have - term queries for any fixed integer ? explain how the common global ordering by values in all high and low lists helps make the score computation efficient . consider again the data of exercise 6.4.4 with nnn.atc for the query-dependent scoring . suppose that we were given static quality scores of 1 for doc1 and 2 for doc2 . determine under equation 35 what ranges of static quality score for doc3 result in it being the first , second or third result for the query best car-insurance . sketch the frequency-ordered postings for the data in figure 6.9 . let the static quality scores for doc1 , doc2 and doc3 in figure 6.11 be respectively 0.25 , 0.5 and 1 . sketch the postings for impact ordering when each postings list is ordered by the sum of the static quality score and the euclidean normalized tf values in figure 6.11 . the nearest-neighbor problem in the plane is the following : given a set of data points on the plane , we preprocess them into some data-structure such that , given a query point , we seek the point in that is closest to in euclidean-distance . clearly cluster pruning can be used as an approach to the nearest-neighbor problem in the plane , if we wished to avoid computing the distance from to every one of the query points . devise a simple example on the plane so that with two leaders , the answer returned by cluster pruning is incorrect (it is not the data point closest to) .