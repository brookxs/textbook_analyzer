5.2.7 `` latent-semantic '' claims within the ir community , svd was first applied to the index matrix by deerwester et al. [deerwester et al. , 1990 ; dumais , 1991] and was called latent-semantic-indexing (lsi) . the `` latent-semantic '' claim derives from the authors * belief that the reduced dimension representation of documents in fact reveals semantic correlations among index-terms . further , they argue that evidence collected across entire corpora transcend individually `` fallible '' document instances . that is , while one document 's www . netlib . org . s vdpack 160 finding out about author might use the word car and another the synonym auto , the correlation of both of these with other terms like highway , gasoline , and driving will result in an abstracted document feature/dimension on which queries using either keyword , car or auto , will project equivalently . `` synonymous '' retrieval has been accomplished ! landauer and dumais have recently extended this algebraic-manipulation of the index relation into an ambitious model of human-memory [landauer and dumais , 1997] . much of psychology is concerned with the problem of how children , those most powerful learning-agents , are able to learn so much from such a `` poverty of the stimulus . '' that is , by many forms of analysis the stimuli driving learning do not by themselves contain sufficient information to induce the elaborate conceptual-structures children demonstrate . applying these ideas to textual-corpora , landauer and dumais `` trained '' an lsi model with presentation of paragraph after paragraph drawn from more than 30,000 encyclopedia articles . using retrieval on a standardized synonym test as their performance-measure , the emerging eigenvector representation (compressed to 300 dimensions) showed a rate of improvement comparable to that of schoolchildren ! because this performance required `` indirect inference '' like that supported by lsi eigenvectors and beyond what could be accomplished on the basis of simple word cooccurrence alone , landauer and dumais suggested that a new lsi provides an important model of human-memory . 1 '' argument for [sjome domains of knowledge contain vast numbers of weak correlations that ... can greatly amplify learning by a process of inference ___ [a] substantial portion of the information needed ... can be inferred from the contextual statistics of usage alone . [landauer and dumais , 1997] at the very least , lsi demonstrates how traditional associative-memory models [james , 1893 ; hebb , 1949 ; baddeley , 1976 ; anderson and kline , 1979] can be extended to exploit higher-order correlations . the earlier work trying to connect a small number of factor-analytic , `` semantically '' meaningful dimensions [koll , 1979 ; borko and bernick , 1963] is also interesting in this respect . jones and furnas have also investigated how well cosine/inner product reflects human similarity judgments [jones and furnas , 1987] . in any case , a cognitive interpretation of these issues promises to remain an active area of investigation . mathematical foundations 161 we now consider how relevance-feedback assessments might also be used to provide document-similarity information , and how they can be used to reduce the dimensionality of documents ' representations .