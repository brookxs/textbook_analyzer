7.2.1 lexical-analysis of the text lexical-analysis is the process of converting a stream of characters (the text of the documents) into a stream of words (the candidate words to be adopted as index-terms) . thus , one of the major objectives of the lexical-analysis phase is the identification of the words in the text . at first glance , all that seems to be involved is the recognition of spaces as word separators (in which case , multiple 166 text operations figure 7.1 logical view of a document throughout the various phases of text-preprocessing . spaces are reduced to one space) . however , there is more to it than this . for instance , the following four particular cases have to be considered with care [263] : digits , hyphens , punctuation-marks , and the case of the letters (lower and upper case) . numbers are usually not good index-terms because , without a surrounding context , they are inherently vague . for instance , consider that a user is interested in documents about the number of deaths due to car accidents between the years 1910 and 1989 . such a request could be specified as the set of index-terms {deaths , car , accidents , years , 1910 , 1989} . however , the presence of the numbers 1910 and 1989 in the query could lead to the retrieval , for instance , of a variety of documents which refer to either of these two years . the problem is that numbers by themselves are just too vague . thus , in general it is wise to disregard numbers as index-terms . however , we have also to consider that digits might appear mixed within a word . for instance , ' 510b . c / is a clearly important index term . in this case , it is not clear what rule should be applied . furthermore , a sequence of 16 digits identifying a credit-card number might be highly relevant in a given context and , in this case , should be considered as an index term . a preliminary approach for treating digits in the text might be to remove all words containing sequences of digits unless specified otherwise (through regular-expressions) . further , an advanced lexical-analysis procedure might perform some date and number normalization to unify formats . hyphens pose another difficult decision to the lexical-analyzer . breaking up hyphenated words might be useful due to inconsistency of usage . for instance , this allows treating `` state-of-the-art ' and ` state-of-the-art ' identically . however , there are words which include hyphens as an integral part . for instance , gilt-edge , b-49 , etc. . again , the most suitable procedure seems to adopt a general role and specify the exceptions on a case by case basis . normally , punctuation-marks are removed entirely in the process of lexical-analysis . while some punctuation-marks are an integral part of the word (for document-preprocessing 167 instance , ' 510b.c .7) , removing them does not seem to have an impact in retrieval-performance because the risk of misinterpretation in this case is minimal . in fact , if the user specifies ' 510b.c in his query , removal of the dot both in the query-term and in the documents will not affect retrieval . however , very particular scenarios might again require the preparation of a list of exceptions . for instance , if a portion of a program-code appears in the text , it might be wise to distinguish between the variables ` x.id ' and * xid . ' in this case , the dot mark should not be removed . the case of letters is usually not important for the identification of index-terms . as a result , the lexical-analyzer normally converts all the text to either lower or upper case . however , once more , very particular scenarios might require the distinction to be made . for instance , when looking for documents which describe details about the command-language of a unix-like operating-system , the user might explicitly desire the non-conversion of upper cases because this is the convention in the operating-system . further , part of the semantics might be lost due to case conversion . for instance , the words bank and bank have different meanings รณ a fact common to many other pairs-of-words . as pointed out by fox [263] , all these text operations can be implemented without difficulty . however , careful thought should be given to each one of them because they might have a profound impact at document-retrieval time . this is particularly worrisome in those situations in which the user finds it difficult to understand what the indexing strategy is doing . unfortunately , there is no clear solution to this problem . as already mentioned , some web-search-engines are opting for avoiding text operations altogether because this simplifies the interpretation the user has of the retrieval-task . whether this strategy will be the one of choice in the long-term remains to be seen .