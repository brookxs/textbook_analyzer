text-search algorithms 225 9.2 software text-search algorithms in software streaming techniques , the item to be searched is read into memory and then the algorithm is applied . although nothing in the architecture described above prohibits software streaming from being applied to many simultaneous searches against the same item , it is more frequently used to resolve a particular search against a particular item . there are four major algorithms associated with software text-search : the brute-force approach , knuth-morrispratt , boyer-moore , shift-or algorithm , and rabin-karp . of all of the algrithms , boyer-moore has been the fastest requiring at most o (n + m) comparisons (smit82) . knuth-pratt-morris and boyer-moore both require o (n) preprocessing of search-strings (knuth-77 , boyer-77 , rytter-80) . the brute-force approach is the simplest string-matching algorithm . the idea is to try and match the search string against the input-text . if as soon as a mismatch is detected in the cmparison process , shift the nput text one position and start the comparison process over . the expectednumber of comparisons when searching an input-text string of n characters for a pattern of m characters is (baeza-yates-89) : nc = ----- (1 - ym) (n-m + \) + 0 (1) c√≥ 1 / c where nc is the expected number of comparisons and c is the size of the alphabet for the text . the knuth-pratt-morris algorithm made a major imprvement in previous algorithms in that even in the worst-case it does not depend upon the length of the text pattern being searched for . the basic concept behind the algorithm is that whenever a mismatch is detected , the previousmatched characters define the number of characters that can be skipped in the input stream prior to starting the comparison process again . for example given : position 12 3 4 5 6 7 8 input stream = a b d ad e f g search-pattern = a b d f when the mismatch occurs in position 4 with a `` f in the pattern and a `` b '' in the input stream , a brute-force approach may shift just one position in the input-text and restart the comparison . but since the first three positions of the pattern 226 chapter 9 matched (a b d) , then shifting one position can not find an `` a '' because it has already been identified as a `` b '' . the algorithm allows the comparison to jump at least the three positions associated with the recognized `` a b d '' . since the mismatch on the position could be the beginning of the search string , four positions can not be skipped . to know the number of positions to jump based upon a mismatch in the search-pattern , the search-pattern is pre-processed to define a number of characters to be jumped for each position . the shift table that specifies the number of places to jump given a mismatch is shown in figure 9.3 . in the table it should be noted that the alignment is primarily based on aligning over the repeats of the letters `` a '' and `` ab '' . figure 9.4 provides an example application of the algorithm (salton-89) where s is the search-pattern and i is the input-text stream . boyer-moore recognized that the string-algorithm could be significantly enhanced if the comparison process started at the end of the search-pattern processing right to left versus the start of the search-pattern . the advantage is that large jumps are possible when the mismatched character in the input stream does not exist in the search-pattern which occurs frequently . this leads to two possible sources of determining how many input characters to be jumped . as in the knuthmorris-pratt technique any characters that have been matched in the search-pattern will require an alignment with that substring . additionally the character in the input stream that was mismatched also requires alignment with its next occurrence search-pattern = abcabcacab position in pattern pattern character length previous number of input repeating substring characters to jump 1 a 0 1 2 b 0 1 3 c 0 2 4 a 0 4 5 b 1 5 6 c 2 6 7 a 3 3 8 c 4 3 9 a 0 8 10 b 1 8 figure 9.3 shift characters table text-search algorithms 227 p 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 sabcabcacab i babcbabcabcaabca t mismatch in position 1 shift one position p 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 s abcabcacab 1 babcbabcabcaabca t mismatch in position 5 , no repeat pattern , skip 3 places p 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 s abcabcacab i babcbabcabcaabca t mismatch in position 5 , shift one position p 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 s abcabcacab i babcbabcabcaabca t mismatch in position 13 , longest repeating-pattern is `` a b c a '' thus skip 3 p 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 s abcabcab i babcbabcabcaabca alignment after last shift figure 9.4 example of knuth-morris-pratt algorithm in the search-pattern or the complete pattern can be moved . this can be defined as : algoi - on a mismatch , the character in the input stream is compared to the search-pattern to determine the shifting of the search-pattern (number of characters in input stream to be skipped) to align the input character to a character in the search-pattern . if the character does not exist in the 228 chapter 9 search-pattern then it is possible to shift the length of the search-pattern matched to that position . algo2 - on a mismatch occurs with previous matching on a substring in the input-text , the matching-process can jump to the repeating ocurrence in the pattern of the initially matched subpattern - thus aligning that portion of the search-pattern that is in the input-text . upon a mismatch , the comparison process can skip the maximum (algoi , algo2) . figure 9.5 gives an example of this process . in this example the search-pattern is (a b d a a b) and the alphabet is (a , b , c , d , e , f) with m = 6 and c = 6 . position 1 2 3 4 5 6 7 8 9 10 11 12 13 input stream f a b f a a b b d a b a b search-pattern a b d a a b t a. mismatch in position 4 : algo] = 3 , algo2 = 4 , thus skip 4 places position 1 2 3 4 5 6 7 8 9 10 11 12 13 input stream f a b f a a b b d a b a b search-pattern a b d a a b t b. mismatch in position 9 : algoi = 1 , algo2 = 4 thus skip four places position 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 input stream f a b f a a b b d a b d a a b search-pattern a b d a a b c. new aligned search continues with a match figure 9.5 boyer-moore-algorithm the comparison starts at the right end of the search-pattern and works towards the start of the search-pattern . in the first comparison (figure 9.5 a.) the mismatch text-search algorithms 229 occurs in position 4 after matching on positions 7 , 6 , and 5 . . algoi wants to align the next occurrence of the input-text stream mismatch character `` f * which does not exist in the search-pattern thus allowing for a skip of three positions . algo2 recognizes that the mismatch occurred after 3 previous search-pattern characters had matched . based upon the pattern stream it knows that the subpattern consisting of the first three characters (a b) repeats in the first two positions of the search-pattern . thus given a mismatch in position 4 , the search-pattern can be moved four places to align the subpattern consisting of the first two characters (a b) over their known occurrence in positions 6 , and 7 in the input-text . in the next comparison (figure 9.5 b.) there is a mismatch in position 9 . the input character that mismatched is a `` d '' and the fewest positions to shift to align the next occurrence of a `` d '' in the search-pattern over it is one position . the analysis for algo2 is the same as before . with the next jump of four positions , the two patterns will match . the original boyer-moore-algorithm has been the basis for additional text-search techniques . it was originally designed to support scanning for a single search string . it was expanded to handle multiple search-strings on a single pass (kowalski-83) . enhanced and simplified versions of the boyer-moore-algorithm have been developed by may researchers (mollier-nielsen-84 , iyengar-80 , commentz-walter-79 , baeza-yates-90 , galil-79 , horspol-80) . a different approach that has similarity to n-grams and signature-files defined in chapter 4 is to divide the text into / w-character substrings , calculate a hash-function (signature) value for each of the strings (harrison-71) . a hash value is calculated for the search-pattern and compared to that of the text . karp and rabin discovered an efficient signature function to calculate these values ; h (k) = k mod q , where q is a large prime-number (karp-87) . the signature value for each location in the text which is based upon the value calculated for the previous location . hashing-functions do not gauranttee uniqueness . their algorithm wll find those positions in the text of an item that have the same hash value as the search-pattern . but the actual text must then be compared to ensure there is a match . detailed implementation of the karp-rabin algorithm is presented by baeza-yates (baeza-yates-92) . in his comparison of all of the algorithms on a search of 1000 random patterns in random text , the horspool simplification of the boyer-moore-algorithm showed the best execution-time for patterns of any length . the major drawback of the boyer-moore class of algorithms is the significant preprocessing time to set up the tables . many of these algorithms are also implemented with hardware . another approach based upon knuth-pratt-morris uses a finite-state-machine to process multiple query terms (aho-75) . the pattern-matching machine consists of a set of states . the machine processes the input-text by successively reading in the next symbol and based upon the current-state , make the state transitions while indicating matches when they occur . the machines operation is based upon three functions ; goto (i.e. , state-transition) , a failure function and an output function . figure 9.6 shows the functions for the set of words he , she , his , 230 chapter 9 and her . the initial-state is labeled state 0 . the goto function is a directed-graph where the letter (s) on the connecting line between states (circles) specify the transition for that input given the current-state . for example in figure 9.6 , if the current-state is 1 and a e or i are received , then the machine will go to steates 2 and 6 respectively . the absence of an arrow or current input character that is not on a line leading from the current nore represents a failure condition . when a failure occurs , the failure function maps a state into another state (it could be to itself) to continue the search-process . certain states are defined as output states . whenever they are reached it means one or more query terms have been matched . (a) goto function 1 2 3 4 5 6 7 8 9 0 0 0 1 2 0 3 0 3 (b) failure function state 2 output he 5 7 she , he his hers (c) output function figure 9.6 tables for aho-corasick algorithm thus if an h has been received and the system is in state 1 . if the next input symbol is an e the system moves to state 2 , if an i is received then it moves to state 6 , if any other letter is received , it will be an error and failure function (the third column in 9.6 (b)) specifies the system should move to state 0 and the same input character is applied to this state . text-search algorithms 231 the number of characters compared is the same for both the ahocorasick and the kmp algorithms . in the new algorithm the number of state-transitions required to process a string is independent of the number of search-terms and the operation to perfom the search is linear with respect to the number of characters in the input stream . the order of magnitude of the number of characters compared is equal to w * o (t) where w is a constant greater than 1 and t is the number of characters in the input-string . this is a major enhancement over both knuth-morris-pratt which is proportional to the number of characters in the query and boyer-moore which can only handle one query-term . these concepts were expanded by baeza-yates and gonnet and can handle `` do n't care '' symbols and compliment symbols (baeza-yates-92a) . the search also handles the cases of up to k mismatches . their approach uses a vector of m differnet states , where m is the length of the search-pattern and state i gives the state of the search between the positions 1 , . . . , i of the pattern and positions (j - / + 1) , ... , y of the text where y is the current position in the text . this n effect expands the process to act like it has m simultaneous comparators working . if sy is the set of states (1 lt ; i lt ; m) after reading the jth character of the text . it represents the number of characters that are different in the corresponding positions between pat \ 9 ... , pah and textj.i + u - √Ø √Ø , textj where pat is the search-pattern and text is the text being searched . if sg = 0 then there is a perfect match . otherwise it provides a fiizzy search capability where the search-term length and the found term length are the same and the value is for the number of mismatches . for example let the search-pattern be ababc (m = 5) and a segment of input-text to be cbbabababcaba then figure 9.7 shows the value for sy_i vector . for example vector value vector position a b aba aba a b a b ... c bbababal babe a b c b c b c c a b a ... input-text stream ... 1 1 0 2 3 3 0 4 figure 9.7 vector for position j - i the vector value for vector position 3 is 0 because the three pat characters aba have no matches with the corresponding three characters bab from the input-text stream . when one position in the text is advanced , the new vector is shown in figure 9.8 . 232 chapter 9 a a b aba aba a b a b c bbababa vector value vector position babe 0 1 a b c 2 2 be 0 3 be 4 4 1 b c a b a ... input-text stream ... figure 9.8 vector for position 7 if t (x) is a table such that tj (x) = 0 if x = patv , otherwise t , (x) = 1 . thus everywhere that the current vector value is zero (i.e. , the apttern matches) , the t (x) value will be zero . eery other location will have a t (x) value of one . thus for example 9.7 above the t5 (x) will appear (1,0,1,0,1) and for figure 9.8 it will be (0,1,0,1,1) which is called t (new) below . it is then possible to define : s (ij) = s (i , j-i) + ti (textj) if s (0 , j) = 0 then the following shows the effect of moving the one position from figure 9.7 (call old) to figure 8 (call new) : s (l , new) = s (0 , old) + t ^ new) = 0 + 0 = 0 s (2 , new) = s (l , old) + t2 (new) = 1 + 1 = 2 s (3 , new) = s (2 , old) + t3 (new) = 0 + 0 = 0 s (4 , new) = s (3 , old) + t4 (new) = 3 +1 = 4 s (5 , new) = s (4 , old) + t5 (new) = 0 +1 = 1 because of these operations , they called the algorithm the shift-add algorithm . to extend the technique to allow for `` do n't care '' symbols , compliments of a character o class (i.e. , matches a character that does not belong to the class) , or any finite-set of symbols , three possibilities will exist for any position in the pattern : a character from the alphabet a `` do n't care '' character (*) a compliment of a chracter or class of characters (c) text-search algorithms 233 letting m ' be the total of the number of elements in each class with * assigned a value of 1 and compliments not cosidered . let m be the size of the pattern . the pattern : [pp] a [a `` eiou] * a [p ... tx ... z] values each class 2 1 5 11 5 + 3 has m = 6 and m ' = 18 . the shift-add algorithm is extended by modifying the table t , such that , for each position every character in the class is processed . thus if the alhabet equals (a , b , c , d) and the pattern is : azgt ; [ab] b [abc] with m = 5 and m '' = 8 . if b = l (as for string interring) , the entries for th table t are : t (a) = 11000 t (b) = 10011 t (c) = 11101 t (d) = 01101 baeza-yates and gonnet describe the details of the implementation of this algorithm in the referenced paper . one advantage to this algorithm is that it can easily be implemented in a hardware solution . the shift-add algorithm is extended by wu and manber to handle insertions and deletions as well as positional mismatches (wu-92) .