8.8.2 compressed indices inverted-files inverted-files are quite amenable to compression . this is because the lists of occurrences are in increasing order of text position . therefore , an obvious choice is to represent the differences between the previous position and the current one . these differences can be represented using less space by using techniques that favor small numbers (see chapter 7) . notice that , the longer the lists , the smaller the differences . reductions in 909 ? for block-addressing indices with blocks of 1 kb size have been reported . it is important to notice that compression does not necessarily degrade time performance . most of the time spent in answering a query is in the disk transfer . keeping the index compressed allows the transference of less data , and it may be worth the cpu work (if decompressing . notice also that the lists of compression 225 occurrences are normally traversed in a sequential manner , which is not affected by a differential compression . query times on compressed or decompressed indices are reported to be roughly similar . the text can also be compressed independently of the index . the text will be decompressed only to display it , or to traverse it in case of block addressing . notice in particular that the online search-technique described for compressed text in section 8.8.1 uses a vocabulary . it is possible to integrate both techniques (compression and indexing) such that they share the same vocabulary for both tasks and they do not decompress the text to index or to search . suffix-trees and suffix-arrays some efforts to compress suffix-trees have been pursued . important reductions of the space requirements have been obtained at the cost of more expensive searching . however , the reduced space requirements happen to be similar to those of uncompressed suffix-arrays , which impose much smaller performance penalties . suffix-arrays are very hard to compress further . this is because they represent an almost perfectly random-permutation of the pointers to the text . however , the subject of building suffix-arrays on compressed text has been pursued . apart from reduced space requirements (the index plus the compressed text take less space than the uncompressed text) , the main advantage is that both index-construction and querying almost double their performance . construction is faster because more compressed text fits in the same memory-space , and therefore fewer text blocks are needed . searching is faster because a large part of the search-time is spent in disk-seek operations over the text area to compare suffixes . if the text is smaller , the seeks reduce proportionally . a compression-technique very similar to that shown in section 8.8.1 is used . however , the huffman-code on words is replaced by a hu-tucker coding . the hu-tucker code respects the lexicographical relationships between the words , and therefore direct binary-search over the compressed text is possible (this is necessary at construction and search-time) . this code is suboptimal by a very small percentage (2-3 % in practice , with an analytical upper-bound of 5 %) . indexing times for 250 mb of text on the reference machine are close to 1.6 mb/min if compression is used , while query times are reduced to 0.5 seconds in total and 0.3 seconds for the text alone . supra-indices should reduce the total search-time to 0.15 seconds . signature-files there are many alternative ways to compress signature-files . all of them are based on the fact that only a few bits are set in the whole file . it is then possible 226 indexing and searching to use efficient methods to code the bits which are not set , for instance run-length-encoding . different considerations arise if the file is stored as a sequence of bit masks or with one file per bit of the mask . they allow us to reduce space and hence disk times , or alternatively to increase b (so as to reduce the false drop-probability) keeping the same space-overhead . compression ratios near 70 % are reported .