7.3.1 widrow-hoff the widrow-hoff (a.k.a. least mean squared (lms)) algorithm is the best-understood and principled approach to training a linear system to minimize this squared error loss [widrow and hoff , i960] . it does this by making a small move (scaled by the parameter 77) in the direction of the gradient of error . this gradient is defined exactly by the derivative of equation 7.5 with respect to the document vector : (7.6) 266 finding out about it is also important to remember that changes made to a single-document in response to a single query can make no guarantees about improved performance with respect to other documents and other queries . for example , two documents might both be moved closer to a query (as proposed by brauen and rocchio) but their relative rankings may not change at all !