dot products 6.2 bag-of-words how do we quantify the similarity between two documents in this vector-space ? a first attempt might consider the magnitude of the vector difference between two document-vectors . this measure suffers from a drawback : two documents with very similar-content can have a significant vector difference simply because one is much longer than the other . thus the relative distributions of terms may be identical in the two documents , but the absolute term frequencies of one may be far larger . cosine-similarity (24) dot-product inner-product euclidean lengths the effect of the denominator of equation 24 is thus to length-normalize the vectors and to unit vectors and . we can then rewrite (24) as (25) worked example . consider the documents in figure 6.9 . we now apply euclidean normalization to the tf values from the table , for each of the three documents in the table . the quantity has the values 30.56 , 46.84 and 41.30 respectively for doc1 , doc2 and doc3 . the resulting euclidean normalized tf values for these documents are shown in figure 6.11 . figure 6.11 : euclidean normalized tf values for documents in figure 6.9 . end worked example . thus , (25) can be viewed as the dot-product of the normalized versions of the two document-vectors . this measure is the cosine of the angle between the two vectors , shown in figure 6.10 . what use is the similarity-measure ? given a document (potentially one of the in the collection) , consider searching for the documents in the collection most similar to . such a search is useful in a system where a user may identify a document and seek others like it - a feature available in the results lists of search-engines as a more like this feature . we reduce the problem of finding the document (s) most similar to to that of finding the with the highest dot products (values) . we could do this by computing the dot products between and each of , then picking off the highest resulting values . worked example . figure 6.12 shows the number of occurrences of three terms (affection , jealous and gossip) in each of the following three novels : jane austen 's sense and sensibility (sas) and pride and prejudice (pap) and emily brontë 's wuthering heights (wh) . of course , there are many other terms occurring in each of these novels . in this example we represent each of these novels as a unit vector in three-dimensions , corresponding to these three terms (only) ; we use raw term frequencies here , with no idf multiplier . the resulting weights are as shown in figure 6.13 . now consider the cosine similarities between pairs of the resulting three-dimensional vectors . a simple computation shows that sim ((sas) , (pap)) is 0.999 , whereas sim ((sas) , (wh)) is 0.888 ; thus , the two books authored by austen (sas and pap) are considerably closer to each other than to brontë 's wuthering heights . in fact , the similarity between the first two is almost perfect (when restricted to the three terms we consider) . here we have considered tf weights , but we could of course use other term-weight functions . end worked example . viewing a collection of documents as a collection of vectors leads to a natural view of a collection as a term-document-matrix and jealousy would under stemming be considered as a single dimension . this matrix view will prove to be useful in chapter 18 .