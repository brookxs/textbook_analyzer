3.3.4 language distribution we next move beyond characteristics of single keywords to an analysis of the distribution of the entire set of index-terms . any index , whether constructed manually or automatically based on word-frequency patterns , is defined by a tension between exhaustivity on the one hand and specificity on the other . an index is exhaustive if it includes many topics . it is specific if users can precisely identify their information-needs . unfortunately , these two intuitively reasonable desiderata are in some sense at odds with one another , as suggested by figure 3.4 . the best explanation of this trade-off is in terms of precision-and-recall weighting and matching against indices 79 (cf. section 4.3.4) : high recall is easiest when an index is exhaustive but is not very specific ; high precision is best accomplished when the index is not very exhaustive but is highly specific . if we assume that the same index must serve many users , each with varying expectations regarding the precision-and-recall of their retrieval , the best index will be at some balance point between these goals . if we index a document with many keywords , it will be retrieved more often ; hence we can expect higher recall , but precision may suffer . van rijsbergen has talked about this extreme as a `` document '' orientation , or representation bias [van rijsbergen , pp. 24 , 29] . a documentoriented approach to index-building focuses the system builder 's attention on a careful representation of each document , based on an analysis of what it is about . however , an index 's fundamental purpose is to reconcile a corpus 's many document descriptions with the many anticipated users ' queries . we could equally well analyze the problem from a query-oriented perspective - how well do the query terms discriminate one document from another ? from the users ' perspective , we 'd like to have these queries match meaningfully onto the vocabulary of our index . from the perspective of the corpus , we 'd like to be able to discriminate one document from another . these are very different perspectives on an index , and they reflect a fundamental vocabulary mismatch [furnasetal , 1987] between the way users describe their interests and the way documents have been described . if an indexing vocabulary is specific , then a user should expect that just the right keyword in a magic bullet query will elicit all and only relevant documents . the average number of documents assigned to specific keywords should be low . in an exhaustive indexing , the many aspects of a document will each be reflected by expressive keywords ; on average many keywords will be assigned to a document : ikw \ exhaustivity oc {ó -} \ docj the important observation is that these two averages must be taken across different distributions . we already know from zipf s law that the 80 finding out about documents keyword distribution ndex ndoc document-corpus figure 3.5 indexing graph number of occurrences varies dramatically from one keyword to another . once we make an assumption about how keywords occur within separate documents , we can derive the distribution of keywords across documents . however , the distribution of keywords assigned to documents can be expected to be much more uniform ; documents are about a nearly uniform or constant number of topics . figure 3.5 represents the index as a graph , where edges connect keyword nodes on the left with document nodes on the right . the index graph is a bipartite-graph , with its nodes divided into two subsets (keywords and documents) and nodes in one set having connections only with those in the other . if we assume that the total number of edges must remain constant , we can assume that the total-area under both distributions is the same . the quantity capturing the exhaustivity/specificity trade-off is therefore the ratio of vocab to corpus-size ndoc although this analysis is crude , it does highlight two important features of every index . first , in most applications ndoc is fixed and vocab is a matter of discretion , a free variable that can be tuned to increase or decrease specificity and exhaustivity . second , certainly in weighting and matching against indices 81 most modern applications (i.e. , with the huge disk volumes now common) , ndoc ^ gt ; vocab . this is one of the most important ways in which experimental collections (including ait) differ from real corpora . a useful indexing vocabulary can be expected to be of a relatively constant size , vocab ´ 103 to 105gt ; while corpora sizes are likely to vary dramatically , ndoczt 104tol09 . along similar lines , it is always useful to think about what this means in the context of the www , where the notion of a closed corpus disappears . the www is an organic , constantly growing set of documents ; our vocabulary for describing it is more constrained . several other basic features of an index are shown in figure 3.5 . the flipped histogram along the left side is meant to reflect the zipfian distribution of keywords , with the most frequent keywords beginning at the top . recall that this distribution captures the total number of word occurrences , regardless of how these occurrences are distributed across interdocument boundaries . a second distribution is also sketched , suggesting how the number of documents versus word occurrences might be distributed ; we can expect these two quantities to be at least loosely correlated . the distinction between intra - and interdocument word-frequencies is a topic we 'll return to in section 3.3.7 .