4.4 rave : a relevance-assessment vehicle section 4.3.2 argued that the opinions of many users concerning the relevance of a document to a query provides a more robust characterization than any single expert . it seems , however , that our move from omniscient to consensual relevance has only made the problem of evaluation that much more difficult : test-corpora must be large enough to provide robust tests for retrieval-methods , and multiple-queries are necessary to evaluate the overall performance of an ir-system . getting even a single person 's opinion about the relevance of a document to a particular query is hard , and we are now interested in getting many ! this section describes rave , a relevance-assessment vehicle that demonstrates that it is possible to operationally define relevance in the manner we suggest . rave is a suite of software routines that allow an ir experimenter to effectively collect large numbers of relevance-assessments for an arbitrary document-corpus . it has been used with a number of different classes of students to collect the relevance-assessments used for evaluation with respect to the ait corpus ; your teacher may have you participate in a similar experiment . it can also be used to collect assessments for other document corpora and query sets .