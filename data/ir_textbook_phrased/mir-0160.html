8.10 bibliographic discussion a detailed explanation of a full inverted-index and its construction and querying process can be found in [26] . this work also includes an analysis of the algorithms on inverted-lists using the distribution of natural-language , the in-place construction is described in [572] , another construction algorithm is presented in [341] . the idea of block addressing inverted-indices was first presented in a system called glimpse [540] , which also first exposed the idea of performing complex-pattern-matching using the vocabulary of the inverted-index . block addressing indices are analyzed in [42] , where some performance-improvements are proposed . the variant that indexes sequences instead of words has been implemented in a system called grampse , which is described in [497] . suffix-arrays were presented in [538] together with the algorithm to build them in o (n log n) character comparisons . they were independently discovered 228 indexing and searching by [309] under the name of tat arrays . ' the algorithm to build large suffix-arrays is presented in [311] . the use of supra-indices over suffix-array is proposed in [37] , while the modified binary-search techniques to reduce disk-seek time are presented in [56] . the linear-time construction of suffix-trees is described in [780] . the material on signature-files is based on [243] . the different alternative ways of storing the signature-file are explained in [242] . the original references for the sequential search-algorithms are : kmp [447] , bm [110] , bmh [376] , bms [751] , shift-or [39] , bdm [205] and bndm [592] . the multipattem versions are found in [9 , 179] , and multibdm in [196] . many enhancements of bit-parallelism to support extended patterns and allow errors are presented in [837] . many ideas from that paper were implemented in a widely distributed-software for online searching called agrep [836] . the reader interested in more details about sequential-searching algorithms may look for the original references or in good books on algorithms such as [310 , 196] . one source for the classical solution to approximate-string-matching is [716] . an o (kn) worst-case algorithm is described in [480] . the use of a dfa is proposed in [781] . the bit-parallel approach to this problem started in [837] , although currently the fastest bit-parallel algorithms are [583] and [43] . among all the filtering-algorithms , the fastest one in practice is based on an idea presented in [837] , later enhanced in [45] , and finally implemented in [43] . a good source from which to learn about regular-expressions and building a dfa is [375] . the bit-parallel implementation of the nfa is explained in [837] . regular-expression searching on suffix-trees is described in [40] , while searching allowing errors is presented in [779] . the huffman-coding was first presented in [386] , while the word-oriented alternative is proposed in [571] . sequential-searching on text compressed using that technique is described in [577] . compression used in combination with inverted-files is described in [850] , with suffix-trees in [430] , with suffix-arrays in [575] , and with signature-files in [243 , 242] . a good general reference on compression is [78] .