5.4.2 query-expansion based on a statistical thesaurus in this section , we discuss a query-expansion technique based on a global statistical thesaurus [200] , despite also being a global-analysis technique , the approach is quite distinct from the one described above which is based on a similarity-thesaurus . the global thesaurus is composed of classes which group correlated terms in the context of the whole collection . such correlated terms can then be used to expand the original user-query . to be effective , the terms selected for expansion must have high term discrimination values [699] which implies that they must be low frequency terms . however , it is difficult to cluster low frequency terms effectively due to the small amount of information , about them (they occur in few documents) . to circumvent this problem , we cluster documents into automatic global-analysis 135 classes instead and use the low frequency terms in these documents to define our thesaurus classes . in this situation , the document clustering-algorithm must produce small and tight clusters . a document-clustering algorithm which produces small and tight clusters is the complete link algorithm which works as follows (naive formulation) . (1) initially , place each document in a distinct cluster . (2) compute the similarity between all pairs of clusters . (3) determine the pair of clusters [cu , cv] with the highest inter-cluster similarity . (4) merge the clusters cu and cv . (5) verify a stop criterion . if this criterion is not met then go back to step 2 . (6) return a hierarchy of clusters . the similarity between two clusters is defined as the minimum of the similarities between all pairs of inter-cluster documents (i.e. , two documents not in the same cluster) . to compute the similarity between documents in a pair , the cosine formula of the vector-model is used . as a result of this minimality criterion , the resultant clusters tend to be small and tight . consider that the whole document-collection has been clustered using the complete link algorithm . figure 5.3 illustrates a small portion of the whole cluster hierarchy in which sirn (cu , cv) = 0.15 and sim (cu + v , cz) = 0.11 where cujrv is a reference to the cluster which results from merging cu and cv . notice that the similarities decrease as we move up in the hierarchy because high level clusters include more documents and thus represent a looser grouping . thus , the tightest clusters lie at the bottom of the clustering hierarchy . given the document cluster hierarchy for the whole collection , the terms that compose each class of the global thesaurus are selected as follows . 誰 obtain from the user three parameters : threshold class (tc) , number of figure 5.3 hierarchy of three clusters (inter-cluster similarities indicated in the ovals) generated by the complete link algorithm . 136 query-operations documents in a class (ndc) , and minimum inverse-document-frequency (midf) . 誰 use the parameter tc as a threshold-value for determining the document clusters that will be used to generate thesaurus classes . this threshold has to be surpassed by sim (cu} cv) if the documents in the clusters cu and cv are to be selected as sources of terms for a thesaurus class . for instance , in figure 5.3 , a value of 0.14 for tc returns the thesaurus class cu + v while a value of 0.10 for tc returns the classes cu + v and cu + v+z . 誰 use the parameter ndc as a limit on the size of clusters (number of documents) to be considered . for instance , if both cu + v and cu + u +2 are preselected (through the parameter tc) then the parameter ndc might be used to decide between the two . a low value of ndc might restrict the selection to the smaller cluster cu + v. 誰 consider the set of documents in each document-cluster preselected above (through the parameters tc and ndc) . only the lower frequency documents are used as sources of terms for the thesaurus classes . the parameter midf defines the minimum value of inverse-document-frequency for any term which is selected to participate in a thesaurus class . by doing so , it is possible to ensure that only low frequency terms participate in the thesaurus classes generated (terms too generic are not good synonyms) . given that the thesaurus classes have been built , they can be used for query-expansion . for this , an average term-weight wtc for each thesaurus class c is computed as follows . where \ c \ is the number of terms in the thesaurus class c and wt , c is a pre ~ computed weight associated with the term-class pair [kt , c] . this average term-weight can then be used to compute a thesaurus class weight we as the above weight formulations have been verified through experimentation and have yielded good results . experiments with four test-collections (adi , medlars , cacm , and lsi ; see chapter 8 for details on these collections) indicate that global-analysis using a thesaurus built by the complete link algorithm might yield consistent improvements in retrieval-performance . the main problem with this approach is the initialization of the parameters tc , ndc , and midf . the threshold-value tc depends on the collection and can be difficult to set properly . inspection of the cluster hierarchy is almost always necessary for assisting with the setting of tc . care must be exercised because a trends and research-issues 137 high value of tc might yield classes with too few terms while a low value of tc might yield too few classes . the selection of the parameter ndc can be decided more easily once tc has been set . however , the setting of the parameter midf might be difficult and also requires careful consideration .