the binary independence-model the binary independence-model (bim) we present in this section is the model that has traditionally been used with the prp . it introduces some simple assumptions , which make estimating the probability function practical . here , `` binary '' is equivalent to boolean : documents and queries are both represented as binary term incidence vectors . that is , a document is represented by the vector where if term is present in document and if is not present in . with this representation , many possible documents have the same vector-representation . similarly , we represent by the incidence vector (the distinction between and is less central since commonly is in the form of a set of words) . `` independence '' means that terms are modeled as occurring in documents independently . the model recognizes no association between terms . this assumption is far from correct , but it nevertheless often gives satisfactory results in practice ; it is the `` naive '' assumption of naive-bayes models , discussed further in section 13.4 (page) . indeed , the binary independence-model is exactly the same as the multivariate bernoulli naive-bayes-model presented in section 13.3 (page) . in a sense this assumption is equivalent to an assumption of the vector-space-model , where each term is a dimension that is orthogonal to all other terms . we will first present a model which assumes that the user has a single step information-need . as discussed in chapter 9 , seeing a range of results might let the user refine their information-need . fortunately , as mentioned there , it is straightforward to extend the binary independence-model so as to provide a framework for relevance-feedback , and we present this model in section 11.3.4 . to make a probabilistic-retrieval strategy precise , we need to estimate how terms in documents contribute to relevance , specifically , we wish to know how term-frequency , document-frequency , document-length , and other statistics that we can compute influence judgments about document-relevance , and how they can be reasonably combined to estimate the probability of document-relevance . we then order documents by decreasing estimated probability-of-relevance . we assume here that the relevance of each document is independent of the relevance of other documents . as we noted in section 8.5.1 (page) , this is incorrect : the assumption is especially harmful in practice if it allows a system to return duplicate or near duplicate documents . under the bim , we model the probability that a document is relevant via the probability in terms of term incidence vectors . then , using bayes rule , we have : (63) (64) (65) subsections deriving a ranking-function for query terms probability-estimates in theory probability-estimates in practice probabilistic-approaches to relevance-feedback