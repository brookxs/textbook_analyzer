the smart measures in 1966 , rocchio gave a derivation of two overall indices of merit based on recall and precision . they were proposed for the evaluation of retrieval-systems which ranked documents , and were designed to be independent of cut-off . the first of these indices is normalised recall . it roughly measures the effectiveness of the ranking in relation to the best possible and worst possible ranking . the situation is illustrated in figure 7.9 for 25 documents where we plot on the y-axis and the ranks on the x-axis . normalised recall (rnorm) is the area between the actual case and the worst as a proportion of the area between the best and the worst . if n is the number of relevant documents , and ri the rank at which the ith document is retrieved , then the area between the best and actual case can be shown to be (after a bit of algebra) : (see salton [23] , page 285) . a convenient explicit form of normalised recall is : where n is the number of documents in the system and n - n the area between the best and the worst-case (to see this substitute ri = n - i + 1 in the formula for ab - aa) . the form ensures that rnorm lies between 0 (for the worst-case) and 1 (for the best case) . in an analogous manner normalised precision is worked out . in figure 7.10 we once more have three curves showing (1) the best case , (2) the actual case , and (3) the worst-case in terms of the precision values at different rank positions . the calculation of the areas is a bit more messy but simple to do (see salton [23] , page 298) . the area between the actual and best case is now given by : the log function appears as a result of approximating [[sigma]] 1/r by its continuous analogue [[integral]] 1/r dr , which is logr + constant . the area between the worst and best case is obtained in the same way as before using the same substitution , and is : the explicit form , with appropriate normalisation , for normalised precision is therefore : once again it varies between 0 (worst) and 1 (best) . a few comments about these measures are now in order . firstly their behaviour is consistent in the sense that if one of them is 0 (or 1) then the other is 0 (or 1) . in other words they both agree on the best and worst performance . secondly , they differ in the weights assigned to arbitrary positions of the precision-recall-curve , and these weights may differ considerably from those which the user feels are pertinent (senko [21]) . or , as salton [23] (page 289) puts it : ` the normalised precision-measure assigns a much larger weight to the initial (low) document ranks than to the later ones , whereas the normalised recall measure assigns a uniform weight to all relevant documents ' . unfortunately , the weighting is arbitrary and given . thirdly , it can be shown that normalised recall and precision have interpretations as approximations to the average recall and precision values for all possible cut-off levels . that is , if r (i) is the recall at rank position i , and p (i) the corresponding precision value , then : fourthly , whereas cooper has gone to some trouble to take account of the random element introduced by ties in the matching-function , it is largely ignored in the derivation of pnorm and rnorm . one further comment of interest is that robertson15 has shown that normalised recall has an interpretation as the area under the recall-fallout curve used by swets . finally mention should be made of two similar but simpler measures used by the smart system . they are : and do not take into account the collection-size n , n is here the number of relevant documents for the particular test query .