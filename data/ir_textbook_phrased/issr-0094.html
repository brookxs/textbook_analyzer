6.4 hierarchy of clusters hierarchical-clustering in information-retrieval focuses on the area of hierarchical-agglomerative-clustering methods (hacm) (willet-88) . the term agglomerative means the clustering process starts with unclustered items and performs pairwise similarity measures to determine the clusters . divisive is the term applied to starting with a cluster and breaking it down into smaller clusters . the objectives of creating a hierarchy of clusters are to : item i 33/2 17/2 item 2 23/2 51/2 item 3 30/2 18/2 item 4 8/2 24/2 item 5 31/2 47/2 document and term-clustering 157 reduce the overhead of search provide for a visual-representation of the information-space expand the retrieval of relevant items . search overhead is reduced by performing top-down searches of the centroids of the clusters in the hierarchy and trimming those branches that are not relevant (discussed in greater depth in chapter 7) . it is difficult to create a visual-display of the total item space . use of dendograms along with visual-cues on the size of clusters (e.g. , size of the ellipse) and strengths of the linkages between clusters (e.g. , dashed lines indicate reduced similarities) allows a user to determine alternate paths of browsing the database (see figure 6.12) . the dendogram allows the user to determine which clusters to be reviewed are likely to have items of interest . even without the visual-display of the hierarchy , a user can use the figure 6.12 dendogram logical hierarchy to browse items of interest . a user , once having identified an item of interest , can request to see other items in the cluster . the user can increase the specificity of items by going to children clusters or by increasing the generality of items being reviewed by going to a parent cluster . most of the existing hacm approaches can be defined in terms of the lance-williams dissimilarity update formula (lance-66) . it defines a general formula for calculating the dissimilarity d between any existing cluster ck and a new cluster cy created by combining clusters c , and cr 158 chapter 6 d (cijsck) = aid (ci , ck) + ajd (cj9ck) + pd (ciscj) + y | d (c , , ck) - d (cj?ck) | by proper selection of a , p , and y , the current techniques for hacm can be represented (frakes-92) . in comparing the various methods of creating hierarchical clusters voorhees and later el-hamdouchi and willet determined that the group average method produced the best results on document-collections (voorhees-86 , el-hamdouchi-89) . the similarity between two clusters can be treated as the similarity between all objects in one cluster and all objects in the other cluster . voorhees showed that the similarity between a cluster-centroid and any item is equal to the mean similarity between the item and all items in the cluster . since the centroid is the average of all items in the cluster , this means that similarities between centroids can be used to calculate the similarities between clusters . ward 's method (ward-63) chooses the minimum square euclidean-distance between points (e.g. , centroids in this case) normalized by the number of objects in each cluster . he uses the formula for the variance i , choosing the minimum variance : i , j = ((m1mj) / (m1 + m})) dh} 2 di / = zk = l (xi (k - xhkf where m , is the number of objects in classs and dj?j2 is the squared euclidean-distance . the process of selection of centroids can be improved by using the reciprocal nearest-neighbor algorithm (murtaugh-83 , murtaugh-85) . the techniques discribed in section 6.2 created independent-sets of classes . the automatic-clustering techniques can also be used to create a hierarchy of objects (items or terms) . the automatic approach has been applied to creating item hierarchies more than in hierarchical statistical thesaurus-generation . in the manual creation of thesauri , network relationships are frequently allowed between terms and classes creating an expanded thesaurus called semantic-networks (e.g. , in topic and retrievalware) . hierarchies have also been created going from general categories to more specific classes of terms . the human creator ensures that the generalization or specification as the hierarchy is created makes semantic sense . automatic creation of a hierarchy for a statistical thesaurus introduces too many errors to be productive . but for item hierarchies the algorithms can also be applied . centroids were used to reduce computation required for adjustments in term assignments to classes . for both terms and items , the centroid has the same structure as any of the items or terms when viewed as a vector from the item/term matrix (see figure 6.2) . a term is a vector composed of a column whereas an item is a vector composed of a row . the scatter/gather system (hearst-96) is an example of this technique . in the scatter/gather system an initial set of clusters was generated . document and term-clustering 159 each of these clusters was re-clustered to produce a second level . this process iterated until individual items were left at the lowest level . when the creation of the classes is complete , a centroid can be calculated for each class . when there are a large number of classes , the next higher level in the hierarchy can be created by using the same algorithms used in the initial clustering to cluster the centroids . the only change required may be in the thresholds used . when this process is complete , if there are still too many of these higher level clusters , an additional iteration of clustering can be applied to their centroids . this process will continue until the desired number-of-clusters at the highest level is achieved . a cluster can be represented by a category if the clusters were monolithic (membership is based upon a specific attribute) . if the cluster is polythetic , generated by allowing for multiple attributes (e.g. , words/concepts) , then it can best be represented by using a list of the most significant words in the cluster . an alternative is to show a two or three-dimensional-space where the clusters are represented by clusters of points . monolithic clusters have two advantages over polythetic (sanderson-99) : how easy it is for a user to understand the topic of the cluster and the confidence that every item within the cluster will have a significant focus on the topic . for example , yahoo is a good example of a monolithic cluster environment . sanderson and croft proposed the following methodology to building a concept-hierarchy . rather than just focusing the construction of the hierarchy , they looked at ways of extracting terms from the documents to represent the hierarchy . the terms had the following characteristics : terms had to best reflect the topics a parent term would refer to a more general concept then its child a child would cover a related subtopic of the parent a directed-acyclic-graph would represent relationships versus a pure hierarchy . ambiguous terms would have separate entries in the hierarchy for each meaning . as a concept-hierarchy , it should be represented similar to wordnet (miller-95) which uses synonyms , antonyms , hyponyrn/hypernym (is-a/is-a-type - of) * an ^ meronym/holonym (has-part/is-a-part - of) . some techniques for generating hierarchies are grefenstette 's use of the similarity of contexts for locating synonyms (grefenstette-94) , use of key-phrases (e.g. , `` such as '' , `` and other '') as an indicator of hyponym/hypernym relationships (hearst-98) , use of head and modifier noun and verb-phrases to determine hierarchies (woods-97) and use of a cohesion statistic to measure the degree of association between terms (forsyth-86) . 160 chapter 6 sanderson and croft used a test based upon subsumption . it is defined given two terms x and y , x subsumes y if : p (x/y) gt ; .8 , p (y/x) lt ; 1 . x subsumes y if the documents which y occurs in are almost (.8) a subset of the documents that x occurs in . the factor of .8 was heuristically used because an absolute condition was eliminating too many useful relationships . x is thus a parent of y . the set of documents to be clustered was determined by a query and the query terms were used as the initial set of terms for the monolithic cluster . this set was expanded by adding more terms via query-expansion using peudorelevance feedback (blind-feedback , local-context-analysis) which is described in chapter 7 . they then used the terms and the formula above to create the hierarchies .