5.3.2 information in relfhk section 5.2.7 raised several important cognitive questions arising from attempts to study `` semantic '' interpretation of lsi/svd dimensions . the connection to the psychologically important analysis of mds adds even more . if we interpret relevance-feedback information as constraints about which documents a user likes , how much can we reduce dimensionality without 164 finding out about violating the relevance-feedback constraints they are giving us ? that is , how much can we reduce the representational space before we 're changing somebody 's order ? second , how many relevance-feedback statements do we need to accurately determine a good compression ? how many people have to tell us things before we have enough information to form this reduced representation ? these questions also connect to ones related to learning these representations (cf. chapter 7) and to our mechanisms , as part of the interface or as part of a special experimental-system like rave , for efficiently collecting large volumes ofrelevance feedback (cf. section 4.4) . most of these questions remain unanswered , but a beginning is simply counting the number of preference-constraints provided by each relevance-feedback labeling of a hitlist by a user . first note that the total number of preference statements required to completely determine n elements grows very rapidly as (2) gt ; corresponding to the fact that preference order information is defined over pairs of pairs of evaluated documents . against this backdrop , each relevance-feedback labeling produces : nplus = | 0 | (5.27) ndcare = | # | (5.28) nminus - | e | (5.29) nretr = nplus + ndcare + nminus (5.30) npref = nplus ï (ndcare + nminus) + (ndcare ï nminus) (5.31) when this information is used as part of error-correction learning , another useful quantity is the number of documents over which the relevance-feedback preference relation and the ranked list disagree : disagree = {(diy d /) | (df - ~ lt ; dj) a (rank (di) lt ; rank (dj))} (532) because this relatively small number of data points will always be dwarfed by the number of total preferences across the entire corpus , the goal becomes to constrain the application of relevance-feedback data to those subsets of the corpus possibly appropriate to a particular query . and because we intend to learn from the browsing users , we can afford to be patient : the documents are only written once but browsing users will continue to read them and provide relevance-feedback for some time .