using query likelihood language-models in ir language-modeling is a quite general formal-approach to ir , with many variant realizations . the original and basic method for using language-models in ir is the query likelihood model . in it , we construct from each document in the collection a language-model . our goal is to rank documents by , where the probability of a document is interpreted as the likelihood that it is relevant to the query . using bayes rule (as introduced in probirsec) , we have : (98) the most common way to do this is using the multinomial unigram-language-model , which is equivalent to a multinomial naive-bayes-model (page 13.3) , where the documents are the classes , each treated in the estimation as a separate `` language '' . under this model , we have that : (99) for retrieval based on a language-model (henceforth lm) , we treat the generation of queries as a random-process . the approach is to infer a lm for each document . estimate , the probability of generating the query according to each of these document-models . rank the documents according to these probabilities .