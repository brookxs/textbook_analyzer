connectivity servers 21 connectivity server connectivity queries which urls link to a given url ? which urls does a given url link to ? link-analysis 21 suppose that the-web had four billion pages , each with ten links to other pages . in the simplest form , we would require 32 bits or 4 bytes to specify each end (source and destination) of each link , requiring a total of (250) 5 we assume that each web-page is represented by a unique integer ; the specific scheme used to assign these integers is described below . we build an adjacency table that resembles an inverted-index : it has a row for each web-page , with the rows ordered by the corresponding integers . the row for any page contains a sorted list of integers , each corresponding to a web-page that links to . this table permits us to respond to queries of the form which pages link to ? in similar fashion we build a table whose entries are the pages linked to by . this table representation cuts the space taken by the naive representation (in which we explicitly represent each link by its two end points , each a 32-bit integer) by 50 % . our description below will focus on the table for the links from each page ; it should be clear that the techniques apply just as well to the table of links to each page . to further reduce the storage for the table , we exploit several ideas : similarity between lists : many rows of the table have many entries in common . thus , if we explicitly represent a prototype row for several similar rows , the remainder can be succinctly expressed in terms of the prototypical row . locality : many links from a page go to `` nearby '' pages - pages on the same host , for instance . this suggests that in encoding the destination of a link , we can often use small integers and thereby save space . we use gap encodings in sorted lists : rather than store the destination of each link , we store the offset from the previous entry in the row . in a lexicographic-ordering of all urls , we treat each url as an alphanumeric string and sort these strings . figure 20.5 shows a segment of this sorted order . for a true lexicographic sort of web-pages , the domain-name part of the url should be inverted , so that www.stanford.edu becomes edu.stanford.www , but this is not necessary here since we are mainly concerned with links local to a single host . figure 20.5 : a lexicographically ordered set of urls . to each url , we assign its position in this ordering as the unique identifying integer . figure 20.6 shows an example of such a numbering and the resulting table . in this example sequence , www.stanford.edu/biology is assigned the integer 2 since it is second in the sequence . we next exploit a property that stems from the way most websites are structured to get similarity and locality . most websites have a template with a set of links from each page in the site to a fixed set of pages on the site (such as its copyright notice , terms of use , and so on) . in this case , the rows corresponding to pages in a website will have many table entries in common . moreover , under the lexicographic-ordering of urls , it is very likely that the pages from a website appear as contiguous rows in the table . figure 20.6 : a four-row segment of the table of links . we adopt the following strategy : we walk down the table , encoding each table row in terms of the seven preceding rows . in the example of figure 20.6 , we could encode the fourth row as `` the same as the row at offset 2 (meaning , two rows earlier in the table) , with 9 replaced by 8 '' . this requires the specification of the offset , the integer (s) dropped (in this case 9) and the integer (s) added (in this case 8) . the use of only the seven preceding rows has two advantages : (i) the offset can be expressed with only 3 bits ; this choice is optimized empirically (the reason for seven and not eight preceding rows is the subject of exercise 20.4) and (ii) fixing the maximum offset to a small value like seven avoids having to perform an expensive search among many candidate prototypes in terms of which to express the current row . what if none of the preceding seven rows is a good prototype for expressing the current row ? this would happen , for instance , at each boundary between different websites as we walk down the rows of the table . in this case we simply express the row as starting from the empty set and `` adding in '' each integer in that row . by using gap encodings to store the gaps (rather than the actual integers) in each row , and encoding these gaps tightly based on the distribution of their values , we obtain further space reduction . in experiments mentioned in section 20.5 , the series of techniques outlined here appears to use as few as 3 bits per link , on average - a dramatic reduction from the 64 required in the naive representation . while these ideas give us a representation of sizable web-graphs that comfortably fit in memory , we still need to support connectivity queries . what is entailed in retrieving from this representation the set of links from a page ? first , we need an index-lookup from (a hash of) the url to its row number in the table . next , we need to reconstruct these entries , which may be encoded in terms of entries in other rows . this entails following the offsets to reconstruct these other rows - a process that in principle could lead through many levels of indirection . in practice however , this does not happen very often . a heuristic for controlling this can be introduced into the construction of the table : when examining the preceding seven rows as candidates from which to model the current row , we demand a threshold of similarity between the current row and the candidate prototype . this threshold must be chosen with care . if the threshold is set too high , we seldom use prototypes and express many rows afresh . if the threshold is too low , most rows get expressed in terms of prototypes , so that at query time the reconstruction of a row leads to many levels of indirection through preceding prototypes . exercises . we noted that expressing a row in terms of one of seven preceding rows allowed us to use no more than three bits to specify which of the preceding rows we are using as prototype . why seven and not eight preceding rows ? (hint : consider the case when none of the preceding seven rows is a good prototype .) we noted that for the scheme in section 20.4 , decoding the links incident on a url could result in many levels of indirection . construct an example in which the number of levels of indirection grows linearly with the number of urls .