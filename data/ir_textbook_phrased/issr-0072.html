5.2.2 vector-weighting one of the earliest systems that investigated statistical-approaches to information-retrieval was the smart system at cornell university (buckley-95 , salton-83) . the system is based upon a vector-model . the semantics of every item are represented as a vector . a vector is a one-dimensional set of values , where the order/position of each value in the set is fixed and represents a particular domain . in information-retrieval , each position in the vector typically represents a processing token . there are two approaches to the domain of values in the vector : binary and weighted . under the binary approach , the domain contains the value of one or zero , with one representing the existence of the processing token in the item . in the weighted approach , the domain is typically the set of all real positive numbers . the value for each processing token represents the relative-importance of that processing token in representing the semantics of the item . figure 5.2 shows how an item that discusses petroleum refineries in mexico would be represented . in the example , the major topics discussed are indicated by the index-terms for each column (i.e. , petroleum , mexico , oil , taxes , refineries and shipping) . binary vectors require a decision-process to determine if the degree that a particular processing token represents the semantics of an item is sufficient to include it in the vector . in the example for figure 5.2 , a five-page item may have had only one sentence like `` standard taxation of the shipment of the oil to refineries is enforced . '' for the binary vector , the concepts of i4tax '' and `` shipment * are below the threshold of importance (e.g. , assume threshold is 1.0) 112 chapter 5 petroleum mexico oil taxes refineries shipping binary (1,1,1,0 , 1 , 0) weighted (2.8 , 1.6 , 3.5 , .3 , 3.1 , .1) figure 5.2 binary and vector-representation of an item and they not are included in the vector . a weighted vector acts the same as a binary vector but it provides a range of values that accommodates a variance in the value of the relative-importance of a processing token in representing the semantics of the item . the use of weights also provides a basis for determining the rank of an item . the vector approach allows for a mathematical and a physical representation using a vector-space-model . each processing token can be considered another dimension in an item representation-space . in chapter 7 it is shown that a query can be represented as one more vector in the same ndimensional space . figure 5.3 shows a three-dimensional vector-representation assuming there were only three processing tokens , petroleum mexico and oil . oil figure 53 vector-representation automatic-indexing 113 the original document-vector has been extended by additional-information such as citations/references to add more information for search and clustering purposes . there have not been significant improvements in retrieval using these techniques . introduction of text generated from multimedia sources introduces a new rationale behind extending the vocabulary associated with an item . in the case where the text is not generated directly by an author but is the result of audio-transcription , the text will contain a significant number of word errors . audio-transcription maps the phonemes that are in an audio item to the words most closely approximating those phonemes in a dictionary . good audio-transcription of broadcast-news still has 15 % of the words in error and conversational-speech still has 40 % or more of the words in error . these will be valid words but the wrong word . one mechanism to reduce the impact of the missing words is to use the existing database to expand the document . this is accomplished by using the transcribed document as a query against the existing database , selecting a small number of the highest ranked results , determining the most important (highest frequency) words across those items and adding those words to the original document . the new document will then be normalized and reweighted based upon the added words (singhal-99) . this technique reduced the losses in retrieval-effectiveness from 15-27 % to 7-13 % when the audio transcriptions had high errors (40 % or more) . it has marginal benefit when the transcription has errors in the 15 % range . there are many algorithms that can be used in calculating the weights used to represent a processing token . part of the art in information-retrieval is deriving changes to the basic algorithms to account for normalization (e.g. , accounting for variances in number of words in items) . the following subsections present the major algorithms starting with the most simple term-frequency algorithm .