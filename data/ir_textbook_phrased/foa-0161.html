7.6.1 exploiting linkage for context * all samples of language , including the documents indexed by web-search-engines , depend heavily on shared-context for comprehension . a document 's author makes assumptions , often tacit , about the intended audience , and when this document appears in a `` traditional '' medium (conference-proceedings , academic journal , etc.) , it is likely that typical readers will understand it as intended . but one of the many things the-web changes is the huge new audience it brings to documents , many of whom will not share the author 's intended context . but because most search-engines attempt to index indiscriminately across the entire www , the global word-frequency statistics they collect can only reflect gross averages . the utility of an index term , as a * portions previously published in | menczer and belew , 2000j . 280 finding out about discriminator of relevant from irrelevant items , can become a muddy average of its application across multiple distinct subcorpora within which these words have more focused meaning [steier and belew , 1994a ; steier and belew , 1994b] . hypertext information environments like the-web contain addiqueryingfor tional structure-information [chakrabarti et al. , 1998a] . t this linkage link topology-information is typically exploited by browsing users . but linkage topology - the `` spatial '' structure imposed over documents by their hypertext-links to one another - can be used to generate a concrete notion of context within which each document is understood : two documents and the words they contain are imagined to be in the same context if they are close together in this space . even in unstructured portions of the-web , authors tend to cluster documents about related topics by letting them point to each other via links . such linkage topology is useful inasmuch as browsers have a better-than-random expectation that following links can provide them with guidance . if this were not the case , browsing would be a waste of time . this suggests that agents (infobots , spiders , etc.) that navigate over such structural links might be able to discover this context . for example , agents browsing through pages about rock climbing and rock 'n roll should attribute different weights to the word rock , depending on whether the query they are trying to satisfy is about music or sports . where an agent is situated in an `` environment '' (neighborhood of highly interlinked documents) provides it with the local-context within which to analyze word-meanings - a structured , situated approach to polisemy . the words that surround links in a document provide an agent with valuable information to evaluate links and thus guide its path decisions a statistical approach to action-selection . the idea of decentralizing the index-building process is not new . dividing the task into localized indexing , performed by a set of gatherers , and centralized searching , performed by a set of brokers , has been suggested since the early days of the-web by the harvest project [bowman et al. , 1994] . web watcher [armstrong et al. , 1995] and letizia [lieberman , 1997] are agents that learn to mimic the user by looking over his or her shoulder while browsing . then they perform look-ahead searches and make real-time suggestions for pages that might interest the user . fab [balabanovic , 1997] and amalthaea [moukas and zacharia , 1997] are multiagent adaptive-filtering systems inspired by genetic adaptive-information-retrieval 281 algorithms , artificial-life , and market models . term-weighting and relevance-feedback are used to adapt a matching between a set of discovery agents (typically search-engine parasites) and a set of user-profiles (corresponding to single - or multiple-user interests) . here we focus on infospiders , a multiagent-system developed by fillipo menczer [menczer et al , 1995 ; menczer , 1997 ; menczer and belew , 1998 ; menczer , 1998 ; menczer and belew , 2000] . in infospiders an evolving population of many agents is maintained , with each agent browsing from document to document online , making autonomous decisions about which links to follow and adjusting its strategy . populationwide dynamics bias the search toward more promising areas and control the total amount of computing-resources devoted to the search activity . basic features of the algorithm are discussed , and then an example of how these agents perform as searchers through a hypertext version of the encyclopaedia britannica are presented herein .