other types of indexes in the indexes we have considered so far , postings lists are ordered with respect to docid . as we see in chapter 5 , this is advantageous for compression - instead of docids we can compress smaller gaps between ids , thus reducing space requirements for the index . however , this structure for the index is not optimal when we build ranked (chapters 6 7) - as opposed to boolean - retrieval-systems . in ranked-retrieval , postings are often ordered according to weight or impact , with the highest-weighted postings occurring first . with this organization , scanning of long postings lists during query-processing can usually be terminated early when weights have become so small that any further documents can be predicted to be of low similarity to the query (see chapter 6) . in a docid-sorted index , new documents are always inserted at the end of postings lists . in an impact-sorted index impactordered , the insertion can occur anywhere , thus complicating the update of the inverted-index . security is an important consideration for retrieval-systems in corporations . a low-level employee should not be able to find the salary roster of the corporation , but authorized managers need to be able to search for it . users ' results lists must not contain documents they are barred from opening ; the very existence of a document can be sensitive-information . figure : a user-document matrix for access-control-lists . element is 1 if user has access to document and 0 otherwise . during query-processing , a user 's access postings list is intersected with the results list returned by the text part of the index . user authorization is often mediated through access-control-lists or acls . acls can be dealt with in an information-retrieval-system by representing each document as the set of users that can access them (figure 4.8) and then inverting the resulting user-document matrix . the inverted acl index has , for each user , a `` postings list '' of documents they can access - the user 's access list . search-results are then intersected with this list . however , such an index is difficult to maintain when access-permissions change - we discussed these difficulties in the context of incremental-indexing for regular postings lists in section 4.5 . it also requires the processing of very long postings lists for users with access to large document subsets . user membership is therefore often verified by retrieving access information directly from the file-system at query time - even though this slows down retrieval . we discussed indexes for storing and retrieving terms (as opposed to documents) in chapter 3 . exercises . can spelling-correction compromise document-level security ? consider the case where a spelling-correction is based on documents to which the user does not have access . exercises . total index-construction time in blocked sort-based indexing is broken down in table 4.3 . fill out the time column of the table for reuters-rcv1 assuming a system with the parameters given in table 4.1 . table : the five steps in constructing an index for reuters-rcv1 in blocked sort-based indexing . line numbers refer to figure 4.2 . step-time 1 reading of collection (line 4) 2 10 initial sorts of records each (line 5) 3 writing of 10 blocks (line 6) 4 total disk transfer time for merging (line 7) 5 time of actual merging (line 7) total table 4.4 : collection statistics for a large-collection . symbol statistic value # documents 1,000,000,000 # tokens per document 1000 # distinct terms 44,000,000 repeat exercise 4.6 for the larger collection in table 4.4 . choose a block-size that is realistic for current technology (remember that a block should easily fit into main-memory) . how many blocks do you need ? assume that we have a collection of modest size whose index can be constructed with the simple in-memory indexing-algorithm in figure 1.4 (page) . for this collection , compare memory , disk and time requirements of the simple algorithm in figure 1.4 and blocked sort-based indexing . assume that machines in mapreduce have 100 gb of disk space each . assume further that the postings list of the term the has a size of 200 gb . then the mapreduce algorithm as described can not be run to construct the index . how would you modify mapreduce so that it can handle this case ? for optimal-load-balancing , the inverters in mapreduce must get segmented postings files of similar sizes . for a new collection , the distribution of key-value pairs may not be known in advance . how would you solve this problem ? apply mapreduce to the problem of counting how often each term occurs in a set of files . specify map and reduce operations for this task . write down an example along the lines of figure 4.6 . we claimed (on page 4.5) that an auxiliary index can impair the quality of collection statistics . an example is the term-weighting method idf , which is defined as where is the total number of documents and is the number of documents that term occurs in idf . show that even a small auxiliary index can cause significant error in idf when it is computed on the main index only . consider a rare term that suddenly occurs frequently (e.g. , flossie as in tropical storm flossie) .