2.7.3 neural-network-model in an information-retrieval-system , document-vectors are compared with query-vectors for the computation of a ranking . thus , index-terms in documents and queries have to be matched and weighted for computing this ranking . since neural-networks are known to be good pattern matchers , it is natural to consider their usage as an alternative model for information-retrieval . it is now well established that our brain is composed of billions of neurons . each neuron can be viewed as a basic processing unit which , when stimulated by input-signals , might emit output signals as a reactive action . the signals emitted by a neuron are fed into other neurons (through synaptic connections) which can themselves emit new output signals . this process might repeat itself through several layers of neurons and is usually referred to as a spread-activation process . as a result , input information is processed (i.e. , analyzed and interpreted) which might lead the brain to command physical reactions (e.g. , motor actions) in response . a neural-network is an oversimplified graph-representation of the mesh of interconnected neurons in a human-brain . the nodes in this graph are the processing units while the edges play the role of the synaptic connections . to simulate the fact that the strength of a synaptic connection in the human-brain changes over time , a weight is assigned to each edge of our neural-network . at each instant , the state of a node is defined by its activation level (which is a function of its initial-state and of the signals it receives as input) . depending on its activation level , a node a might send a signal to a neighbor node b . the strength of this signal at the node b depends on the weight associated with the edge between the nodes . a and b . a neural-network for information-retrieval can be defined as illustrated in figure 2.7 . the model depicted here is based on the work in [815] . we first alternative algebraic-models 47 observe that the neural-network in figure 2.7 is composed of three layers : one for the query terms , one for the document terms , and a third one for the documents themselves . observe the similarity between the topology of this neural-network and the topology of the inference and belief-networks depicted in figures 2.9 and 2.10 . here , however , the query-term nodes are the ones which initiate the inference-process by sending signals to the document term nodes . following that , the document term nodes might themselves generate signals to the document nodes . this completes a first phase in which a signal travels from the query-term nodes to the document nodes (i.e. , from the left to the right in figure 2.7) . the neural-network , however , does not stop after the first phase of signal propagation . in fact , the document nodes in their turn might generate new signals which are directed back to the document term nodes (this is the reason for the bidirectional edges between document term nodes and document nodes) . upon receiving this stimulus , the document term nodes might again fire new signals directed to the document nodes , repeating the process . the signals become weaker at each iteration and the spread-activation process eventually halts . this process might activate a document di even when such a document does not contain any query terms . thus , the whole process can be interpreted as the activation of a built-in thesaurus . to the query-term nodes is assigned an initial (and fixed) activation level equal to 1 (the maximum) . the query-term nodes then send signals to the document term nodes which are attenuated by normalized query-term weights whq . for a vector-based ranking , these normalized weights can be derived from the weights wi : q defined for the vector-model by equation 2.4 . for instance , where the normalization is done using the norm of the query-vector . once the signals reach the document term nodes , these might send new signals out directed towards the document nodes . these signals are attenuated by normalized document term-weights wij derived from the weights wij defined for the vector-model by equation 2.3 . for instance , where the normalization is done using the norm of the document vector . the signals which reach a document node are summed up . thus , after the first round of signal propagation , the activation level of the document node associated to the document dj is given by x / = rt v ^ i = i 48 modeling which is exactly the ranking provided by the classic vector-model . to improve the retrieval-performance , the network continues with the spreading-activation process after the first round of propagation . this modifies the initial vector ranking in a process analogous to a user-relevance-feedback cycle (see chapter 5) . to make the process more effective , a minimum activation threshold might be defined such that document nodes below this threshold send no signals out . details can be found in [815] . there is no conclusive evidence that a neural-network provides superior retrieval-performance with general collections . in fact , the model has not been tested extensively with large document collections . however , a neural-network does present an alternative modeling paradigm . further , it naturally allows retrieving documents which are not initially related to the query terms รณ an appealing functionality .