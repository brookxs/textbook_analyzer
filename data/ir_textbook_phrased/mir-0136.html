8.2 inverted-files an inverted-file (or inverted-index) is a word-oriented mechanism for indexing a text-collection in order to speed up the searching-task . the inverted-file structure is composed of two elements : the vocabulary and the occurrences . the vocabulary is the set of all different words in the text . for each such word a list of all the text positions where the word appears is stored . the set of all those lists is called the ` occurrences1 (figure 8.1 shows an example) . these positions can refer to words or characters . word positions (i.e. , position i refers to the i-th word) simplify 1 6 9 11 17 19 24 28 33 40 46 inverted 50 55 files j 60 this is a text . a text has many words . words are made from letters . 193 text vocabulary occurrences letters somade so ... many 28 . text 11 , 19 ... inverted-index words 33 , 40 . . figure 8.1 a sample text and an inverted-index built on it . the words are converted to lower-case and some are not indexed . the occurrences point to character positions in the text . phrase and proximity-queries , while character positions (i.e. , the position i is the z-th character) facilitate direct-access to the matching text positions . some authors make the distinction between inverted-files and inverted-lists . in an inverted-file , each element of a list points to a document or file name , while inverted-lists match our definition . we prefer not to make such a distinction because , as we will see later , this is a matter of the addressing granularity , which can range from text positions to logical blocks . the space required for the vocabulary is rather small . according to heaps ' law (see chapter 6) the vocabulary grows as o (n ^) , where (3 is a constant between 0 and 1 dependent on the text , being between 0.4 and 0.6 in practice . for instance , for 1 gb of the trec-2 collection the vocabulary has a size of only 5 mb . this may be further reduced by stemming and other normalization techniques as described in chapter 7 . the occurrences demand much more space . since each word appearing in the text is referenced once in that structure , the extra space is o (n) . even omitting stopwords (which is the default practice when words are indexed) , in practice the space-overhead of the occurrences is between 30 % and 40 % of the text size . to reduce space requirements , a technique called block addressing is used . the text is divided in blocks , and the occurrences point to the blocks where the word appears (instead of the exact positions) . the classical indices which point to the exact occurrences are called ` full inverted-indices / by using block addressing not only can the pointers be smaller because there are fewer blocks than positions , but also all the occurrences of a word inside a single block are collapsed to one reference (see figure 8.2) . indices of only 5 % overhead over the text size are obtained with this technique . the price to pay is that , if the exact occurrence positions are required (for instance , for a proximity-query) , then an online-search over the qualifying blocks has to be performed . for instance , block addressing indices with 256 blocks stop working well with texts of 200 mb . table-1 8.1 presents the projected space taken by inverted-indices for texts of 194 indexing and searching block 1 block 2 block 3 block 4 this is a text . a text has many words . words are made from letters vocabulary text inverted-index figure 8.2 the sample text split into four blocks , and an inverted-index using block addressing built on it . the occurrences denote block numbers . notice that both occurrences of ` words1 collapsed into one . different sizes , with and without the use of stopwords . the full inversion stands for inverting all the words and storing their exact positions , using four bytes per pointer . the document addressing index assumes that we point to documents which are of size 10 kb (and the necessary number of bytes per pointer , i.e. one , two , and three bytes , depending on text size) . the block addressing index assumes that we use 256 or 64k blocks (one or two bytes per pointer) independently of the text size . the space taken by the pointers can be significantly reduced by using compression . we assume that 45 % of all the words are stop-words , and that there is one non-stopword each 11.5 characters . our estimation for the vocabulary is based on heaps ' lawt with parameters v = 30 ? 20-5 . all these decisions were taken according to our experience and experimentally validated . the blocks can be of fixed size (imposing a logical block structure over the text-database) or they can be defined using the natural division of the text-collection into files , documents . web-pages , or others . the division into blocks of fixed size improves efficiency at retrieval-time , i.e. the more variance in the block sizes , the more amount of text sequentially traversed on average . this is because larger blocks match queries more frequently and are more expensive to traverse . alternatively , the division using natural cuts may eliminate the need for online traversal . for example , if one block per retrieval-unit is used and the exact-match positions are not required , there is no need to traverse the text for single-word queries , since it is enough to know which retrieval units to report . but if , on the other hand , many retrieval units are packed into a single block , the block has to be traversed to determine which units to retrieve . it is important to notice that in order to use block addressing , the text must be readily available at search-time . this is not the case for remote text (as in web-search-engines) , or if the text is in a cd-rom that has to be mounted , for instance . some restricted queries not needing exact positions can still be solved if the blocks are retrieval units . inverted-files 195 index small collection (1 mb) medium (200 collection mb) large-collection (2 gb) addressing words 45 % 73 % 36 % 64 % 35 % 63 % addressing documents 19 % 26 % 18 % 32 % 26 % 47 % addressing 64k blocks 27 % 41 % 18 % 32 % 5 % 9 % addressing 256 blocks 18 % 25 % 1.7 % 2.4 % 0.5 % 0.7 % table 8.1 sizes of an inverted-file as approximate percentages of the size the whole text collection . four granularities and three collections are considered . for each collection , the right column considers that stopwords are not indexed while the left column considers that all words are indexed .