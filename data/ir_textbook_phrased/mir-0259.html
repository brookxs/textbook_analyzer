13.4.6 indices most indices use variants of the inverted-file (see chapter 8) . in short , an inverted-file is a list of sorted words (vocabulary) , each one having a set of pointers to the pages where it occurs . some search-engines use elimination of stopwords to reduce the size of the index . also , it is important to remember that a logical view of the text is indexed . normalization operations may include removal of punctuation and multiple-spaces to just one space between each word , uppercase to lowercase letters , etc. (see chapter 7) . to give the user some idea about each document retrieved , the index is complemented with a short description of each web-page (creation date , size , the title and the first lines or a few headings are typical) . assuming that 500 bytes are required to store the url and the description of each web-page , we need 50 gb to store the description for 100 million pages . as the user initially receives only a subset of the complete answer to each query , the search-engine usually keeps the whole answer set in memory , to avoid having to recompute it if the user asks for more documents . state-of-the-art indexing-techniques can reduce the size of an inverted-file to about 30 % of the size of the text (less if stopwords are used) . for 100 million pages , this implies about 150 gb of disk space . by using compression techniques , the index-size can be reduced to 10 % of the text [825] . a query is answered by doing a binary-search on the sorted list of words of the inverted-file . if we are searching multiple words , the results have to be combined to generate the final answer . this step will be efficient if each word is not too frequent . another possibility is to compute the complete answer while the user requests more web-pages , using a lazy-evaluation scheme . more details on searching over an inverted-file can be found in chapter 8 . inverted-files can also point to the actual occurrences of a word within a document (full inversion) . however , that is too costly in space for the-web , because each pointer has to specify a page and a position inside the page (word numbers can be used instead of actual bytes) . on the other hand , having the positions of the words in a page , we can answer phrase searches or proximity-queries by finding words that are near each other in a page . currently , some search-engines are providing phrase searches , but the actual implementation is not known . finding words which start with a given prefix requires two binary searches in the sorted list of words . more complex searches , like words with errors , 384 searching the-web arbitrary wild cards or , in general , any regular-expression on a word , can be performed by doing a sequential-scan over the vocabulary (see chapter 8) . this may seem slow , but the best sequential algorithms for this type of query can search around 20 mb of text stored in ram in one second (5 mb is more or less the vocabulary-size for 1 gb of text) . thus , for several gigabytes we can answer those queries in a few seconds . for the-web this is still too slow but not completely out of the question . in fact , using heaps ' law and assuming / ? = 0.7 for the-web , the vocabulary-size for 1 tb is 630 mb which implies a searching time of half a minute . pointing to pages or to word positions is an indication of the granularity of the index . the index can be less dense if we point to logical blocks instead of pages . in this way we reduce the variance of the different document sizes , by making all blocks roughly the same size . this not only reduces the size of the pointers (because there are fewer blocks than documents) but also reduces the number of pointers because words have locality-of-reference (that is , all the occurrences of a non-frequent word will tend to be clustered in the same block) . this idea was used in glimpse [540] which is at the core of harvest [108] . queries are resolved as for inverted-files , obtaining a list of blocks that are then searched sequentially (exact sequential search can be done over 30 mb per second in ram) . glimpse originally used only 256 blocks , which was efficient up to 200 mb for searching words that were not too frequent , obtaining an index of only 2 % of the text . by tuning the number of blocks and the block-size , reasonable space-time trade-offs can be achieved for larger document-collections (for more details see chapter 8) . these ideas can not be used (yet) for the-web because sequential search can not be afforded , as it implies a network-access . however , in a distributed-architecture where the index is also distributed , logical blocks make sense .