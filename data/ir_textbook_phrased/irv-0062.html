form of retrieval-function the previous section was rather abstract and left the connection of the various probabilities with ir rather open . although it is reasonable for us to want to calculate p (relevance/document) it is not at all clear as to how this should be done or whether the inversion through bayes ' theorem is the best way of getting at it . nevertheless , we will proceed assuming that p (x/wi) is the appropriate function to estimate . this function is of course a joint-probability function and the interaction between the components of x may be arbitrarily complex . to derive a workable decision-rule a simplifying assumption about p (x/wi) will have to be made . the conventional mathematically convenient way of simplifying p (x/wi) is to assume the component variables xi of x to be stochastically independent . technically this amounts to making the major assumption p (x/wi) = p (x1/wi) p (x2/wi) ... p (xn/wi) a1 later i shall show how this stringent assumption may be relaxed . we also for the moment ignore the fact that assuming independence conditional on both w1 and w2 separately has implications about the dependence conditional on w1 [[logicalor]] w2 . let us now take the simplified form of p (x/wi) and work out what the decision-rule will look like . first we define some variables pi = prob (xi = 1/w1) qi = prob (xi = 1/w2) . in words pi (qi) is the probability that if the document is relevant (non-relevant) that the ith index term will be present . the corresponding probabilities for absence are calculated by subtracting from 1 , i.e. 1 - pi = prob (xi = 0/w1) . the likelihood functions which enter into d3 will now look as follows to appreciate how these expressions work , the reader should check that p ((0,1,1,0,0,1) / w1) = (1 - p1) p2p3 (1 - p4) (1 - p5) p6 . substituting for p (x/wi) in d3 and taking logs , the decision-rule will be transformed into a linear discriminant function . where the constants ai , bi and e are obvious . and the importance of writing it this way , apart from its simplicity , is that for each document x to calculate g (x) we simply add the coefficients ci for those index-terms that are present , i.e. for those ci for which xi = 1 . the ci are often looked up as weights ; robertson and sparck jones [1] call ci a relevance weight , and salton calls exp (ci) the term-relevance . i shall simply refer to it as a coefficient or a weight . hence the name weighting-function for g (x) . the constant c which has been assumed the same for all documents x will of course vary from query to query , but it can be interpreted as the cut-off applied to the retrieval-function . the only part that can be varied with respect to a given query is the cost-function , and it is this variation which will allow us to retrieve more or less documents . to see this let us assume that l11 = l22 = 0 and that we have some choice in setting the ratio l21/l11 by picking a value for the relative-importance we attach to missing a relevant-document compared with retrieving a non-relevant one . in this way we can generate a ranking , each rank position corresponding to a different ratio l21/l12 . let us now turn to the other part of g (x) , namely ci and let us try and interpret it in terms of the conventional ` contingency ' table . there will be one such table for each index term ; i have shown it for the index term i although the subscript i has not been used in the cells . if we have complete information about the relevant and non-relevant documents in the collection then we can estimate pi by r/r and qi by (n - r) / (n - r) . therefore g (x) can be rewritten as follows : this is in fact the weighting-formula f4 used by robertson and sparck jones1 in their so called retrospective experiments . for later convenience let us set there are a number of ways of looking at ki . the most interesting interpretation of ki is to say that it measures the extent to which the ith term can discriminate between the relevant and non-relevant documents . typically the ` weight ' ki (n , r , n , r) is estimated from a contingency-table in which n is not the total number of documents in the system but instead is some subset specifically chosen to enable ki to be estimated . later i will use the above interpretation of ki to motivate another function similar to ki to measure the discrimination power of an index term .