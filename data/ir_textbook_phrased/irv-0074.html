discrimination gain hypothesis in the derivation above i have made the assumption of independence or dependence in a straightforward way . i have assumed either independence on both w1 and w2 , or dependence . but , as implied earlier , this is not the only way of making these assumptions . robertson and sparck jones [1] make the point that assuming independence on the relevant and non-relevant documents can imply dependence on the total set of documents . to see this consider two index-terms i and j , and p (xi , xj) = p (xi , xj / w1) p (w1) + p (xi , xi / w2) p (w2) p (xi) p (xj) = [p (xi / w1) p (w1) + p (xi , w2) p (w2)] [p (xj / w1) p (w1) + p (xj , w2) p (w2)] if we assume conditional-independence on both w1 and w2 then p (xi , xj) = p (xi , / w1) p (xj , w1) p (w1) + p (xi / w2) p (xj / w2) p (w2) for unconditional independence as well , we must have p (xi , xj) = p (xi) p (xj) this will only happen when p (w1) = 0 or p (w2) = 0 , or p (xi / w1) = p (xi/w2) , or p (xj/w1) = p (xj / w2) , or in words , when at least one of the index-terms is useless at discriminating relevant from non-relevant documents . in general therefore conditional-independence will imply unconditional dependence . now let us assume that the index-terms are indeed conditionally independence then we get the following remarkable results . kendall and stuart [26] define a partial correlation-coefficient for any two distributions by where [[rho]] (. , . / w) and [[rho]] (. , .) are the conditional and ordinary correlation coefficients respectively . now if x and y are conditionally independent then [[rho]] (x , y/w) = 0 which implies using the expression for the partial correlation that [[rho]] (x , y) = [[rho]] (x , w) [[rho]] (y , w) since | [[rho]] (x , y) | lt ; = 1 , | [[rho]] (x , w) | lt ; = 1 , | [[rho]] (y , w) | lt ; = 1 this in turn implies that under the hypothesis of conditional-independence | [[rho]] (x , y) | lt ; | [[rho]] (x , w) | or | [[rho]] (y , w) | (**) hence if w is a random-variable representing relevance then the correlation between it and either index term is greater than the correlation between the index-terms . qualitatively i shall try and generalise this to functions other than correlation coefficients , linfott [27] defines a type of informational correlation-measure by rij = (1 - exp (-2 i (xi , xj))) [1/2] 0 lt ; = rij lt ; = 1 or where i (xi , xj) is the now familiar expected mutual-information measure . but rij reduces to the standard correlation-coefficient [[rho]] (. , .) if (xi , xj) is normally distributed . so it is not unreasonable to assume that for non-normal distributions rij will behave approximately like [[rho]] (. , .) and will in fact satisfy (**) as well . but rij is strictly monotone with respect to i (x , i , xj) so it too will satisfy (**) . therefore we can now say that under conditional-independence the information contained in one index term about another is less than the information contained in either term about the conditioning variable w . in symbols we have i (xi , xj) lt ; i (xi , w) or i (xj , w) , where i (. , w) is the information radius with its weights interpreted as prior-probabilities . remember that i (. , w) was suggested as the measure of discrimination-power . i think this result deserves to be stated formally as an hypothesis when w is interpreted as relevance . discrimination gain hypothesis : under the hypothesis of conditional-independence the statistical-information contained in one index term about another is less than the information contained in either index term about relevance . i must emphasise that the above argument leading to the hypothesis is not a proof . the argument is only a qualitative one although i believe it could be tightened up . despite this it provides (together with the hypothesis) some justification and theoretical basis for the use of the mst based on i (xi , xj) to improve retrieval . the discrimination hypothesis is a way of firming up the association hypothesis under conditional-independence . one consequence of the discrimination hypothesis is that it provides a rationale for ranking the index-terms connected to a query-term in the dependence tree in order of i (term , query-term) values to reflect the order of discrimination-power values . the basis for this is that the more strongly connected an index term is to the query-term (measured by emim) the more discriminatory it is likely to be . to see what is involved more clearly i have shown an example set-up in figure 6.2 . let us suppose that x1 is the variable corresponding to the query-term and that i (x1 , x2) lt ; i (x1 , x3) lt ; i (x1 , x4) lt ; i (x1 , x5) then our hypothesis says that without knowing in advance how good a discriminator each of the index-terms 2,3,4,5 is , it is reasonable to assume that i (x2 , w) lt ; i (x3 , w) lt ; i (x4 , w) lt ; i (x5 , w) . clearly we can not guarantee that the index-terms will satisfy the last ordering but it is the best we can do given our ignorance .