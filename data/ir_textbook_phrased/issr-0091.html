document and term-clustering 151 6.2.2.2 clustering using existing clusters an alternative methodology for creating clusters is to start with a set of existing clusters . this methodology reduces the number of similarity calculations required to determine the clusters . the initial assignment of terms to the clusters is revised by revalidating every term-assignment to a cluster . the process stops when minimal-movement between clusters is detected . to minimize calculations , centroids are calculated for each cluster . a centroid is viewed in physics as the center of mass of a set of objects . in the context of vectors , it will equate to the average of all of the vectors in a cluster . one way to understand this process is to view the centroids of the clusters as another point in the n-dimensional space where n is the number of items . the first assignment of terms to clusters produces centroids that are not related to the final clustering-of-terms . the similarity between all existing terms and the centroids of the clusters can be calculated . the term is reallocated to the cluster (s) that has the highest similarity . this process is iterated until it stabilizes . calculations using this process are of the order o (n) . the initial assignment of terms to clusters is not critical in that the iterative-process changes the assignment of terms to clusters . a graphical-representation of terms and centroids illustrates how the v v ^ ^ nj i h / vv vv v ^ / '' '' '' ó ^ yvvv v \ v \ f vvvvn j vv vv \ ivv v v vv v i fl v v] vv v vv vvv j \ vv vy a vvv 1 figure 6.6 b. initial centroids for clusters v v \ ^ / vv vvv \ x '' ó '' \ yvvv v \ \ f vvvvn ivv ^ v \ vv v v vv v i f iv jvv v vv vvv j \ vv vy a7vv / figure 6.6 a centroids after reassigning terms 152 chapter 6 classes move after the initial assignment . the solid black-box represents the centroid for each of the classes . in figure 6.6 b. the centroids for the first three arbitrary class are shown . the ovals in figure 6.6 b. show the ideal cluster assignments for each term . during the next iteration the similarity between every term and the clusters is performed reassigning terms as needed . the resulting new centroid for the new clusters are again shown as black squares in figure 6.6 a . the new centroids are not yet perfectly associated with the ideal clusters , but they are much closer . the process continues until it stabilizes . the following example of this technique uses figure 6.2 as our weighted environment , and assumes we arbitrarily placed class 1 = (terml and term2) , class 2 = (term3 and term 4) and class 3 = (term5 and term 6) . this would produce the following centroids for each class : class 1 = (0 +4) / 2 , (3 + l) / 2 , (3 + 0) 12 , (0 + l) / 2 , (2 + 2) / 2 = 4/2 , 4/2 , 3/2 , 1/2 , 4/2 class 2 = 0/2 , 7/2 , 0/2 , 3/2 , 5/2 class 3 = 2/2 3/2 , 3/2 , 0/2 , 5/2 each value in the centroid is the average of the weights of the terms in the cluster for each item in the database . for example in class 1 the first value is calculated by averaging the weights of terml and term2 in item 1 . for class 2 and 3 the numerator is already the sum of the weights of each term . for the next step , calculating similarity values , it is often easier to leave the values in fraction form . applying the simple similarity-measure defined in section 6.2.2.1 between each of the 8 terms and 3 centroids just calculated comes up with the following assignment of similarity weights and new assignment of terms to classes in the row assign shown in figure 6.7 : terml term2 term3 term4 tenn5 term6 term ? term8 class 1 29/2 29/2 24/2 27/2 17/2 32/2 15/2 24/2 class 2 31/2 20/2 38/2 45/2 12/2 34/2 6/2 17/2 class 3 28/2 21/2 22/2 24/2 17/2 30/2 11/2 19/2 assign c!ass2 class 1 class2 class2 class3 class2 class 1 classl figure 6.7 iterated class assignments in the case of term 5 , where there is tie for the highest similarity , either class could be assigned . one technique for breaking ties is to look at the similarity weights of the other items in the class and assign it to the class that has the most similar weights . the majority of terms in class 1 have weights in the high 20 's / 2 , thus term 5 was assigned to class 3 . term 7 is assigned to class 1 even though document and term-clustering 153 its similarity weights are not in alignment with the other terms in that class . figure 6.8 shows the new centroids and results of similarity comparisons for the next iteration . class 1 = 8/3 , 2/3 , 3/3 , 3/3 , 4/3 class 2 = 2/4 , 12/4 , 3/4 , 3/4 , 11/4 class 3 = 0/1 , 1/1 ,3 / 1,0 / 1 , 1/1 terml term2 term3 term4 term5 term6 term ? term8 class 1 23/3 45/3 16/3 27/3 15/3 36/3 23/3 34/3 class 2 67/4 45/4 70/4 78/4 33/4 72/4 17/4 40/4 class 3 12/1 3/1 6/1 6/1 11/1 6/1 9/1 3/1 assign class2 classl class2 class2 class3 class2 class3 classl figure 6.8 new centroids and cluster assignments in this iteration of the process , , the only change is term 7 moves from class 1 to class 3 . this is reasonable , given it was not that strongly related to the other terms in class 1 . although the process requires fewer calculations than the complete term-relationship method , it has inherent limitations . the primary problem is that the number of classes is defined at the start of the process and can not grow . it is possible for there to be fewer classes at the end of the process . since all terms must be assigned to a class , it forces terms to be allocated to classes , even if their similarity to the class is very weak compared to other terms assigned .