choosing the subset of the-web in assembling a subset of web-pages around a topic such as leukemia , we must cope with the fact that good authority pages may not contain the specific query-term leukemia . this is especially true , as we noted in section 21.1.1 , when an authority page uses its web presence to project a certain marketing image . for instance , many pages on the ibm website are authoritative sources-of-information on computer-hardware , even though these pages may not contain the term computer or hardware . however , a hub compiling computer-hardware resources is likely to use these terms and also link to the relevant pages on the ibm website . building on these observations , the following procedure has been suggested for compiling the subset of the-web for which to compute hub and authority scores . given a query (say leukemia) , use a text-index to get all pages containing leukemia . call this the root-set of pages . build the base set of pages , to include the root-set as well as any page that either links to a page in the root-set , or is linked to by a page in the root-set . we then use the base set for computing hub and authority scores . the base set is constructed in this manner for three reasons : a good authority page may not contain the query text (such as computer-hardware) . if the text query manages to capture a good hub page in the root-set , then the inclusion of all pages linked to by any page in the root-set will capture all the good authorities linked to by in the base set . conversely , if the text query manages to capture a good authority page in the root-set , then the inclusion of pages which point to will bring other good hubs into the base set . in other words , the `` expansion '' of the root-set into the base set enriches the common pool of good hubs-and-authorities . running hits across a variety of queries reveals some interesting insights about link-analysis . frequently , the documents that emerge as top hubs-and-authorities include languages other than the language of the query . these pages were presumably drawn into the base set , following the assembly of the root-set . thus , some elements of cross-language-retrieval (where a query in one language retrieves documents in another) are evident here ; interestingly , this cross-language effect resulted purely from link-analysis , with no linguistic translation taking place . we conclude this section with some notes on implementing this algorithm . the root-set consists of all pages matching the text query ; in fact , implementations (see the references in section 21.4) suggest that it suffices to use 200 or so web-pages for the root-set , rather than all pages matching the text query . any algorithm for computing eigenvectors may be used for computing the hub/authority score vector . in fact , we need not compute the exact values of these scores ; it suffices to know the relative values of the scores so that we may identify the top hubs-and-authorities . to this end , it is possible that a small number of iterations of the power-iteration method yields the relative ordering of the top hubs-and-authorities . experiments have suggested that in practice , about five iterations of equation 262 yield fairly good results . moreover , since the link-structure of the-web graph is fairly sparse (the average web-page links to about ten others) , we do not perform these as matrix-vector products but rather as additive updates as in equation 262 . figure : a sample run of hits on the query japan elementary schools . figure 21.6 shows the results of running hits on the query japan elementary schools . the figure shows the top hubs-and-authorities ; each row lists the title tag from the corresponding html page . because the resulting string is not necessarily in latin characters , the resulting print is (in many cases) a string of gibberish . each of these corresponds to a web-page that does not use latin characters , in this case very likely pages in japanese . there also appear to be pages in other non-english languages , which seems surprising given that the query string is in english . in fact , this result is emblematic of the functioning of hits - following the assembly of the root-set , the (english) query string is ignored . the base set is likely to contain pages in other languages , for instance if an english-language hub page links to the japanese-language home-pages of japanese elementary schools . because the subsequent computation of the top hubs-and-authorities is entirely link-based , some of these non-english pages will appear among the top hubs-and-authorities . exercises . if all the hub and authority scores are initialized to 1 , what is the hub/authority score of a node after one iteration ? how would you interpret the entries of the matrices and ? what is the connection to the co-occurrence-matrix in chapter 18 ? what are the principal eigenvalues of and ? figure : web-graph for exercise 21.3.1 . for the-web graph in figure 21.7 , compute pagerank , hub and authority scores for each of the three pages . also give the relative ordering of the 3 nodes for each of these scores , indicating any ties . pagerank : assume that at each step of the pagerank random-walk , we teleport to a random page with probability 0.1 , with a uniform-distribution over which particular page we teleport to . hubs/authorities : normalize the hub (authority) scores so that the maximum hub (authority) score is 1 . hint 1 : using symmetries to simplify and solving with linear-equations might be easier than using iterative-methods . hint 2 : provide the relative ordering (indicating any ties) of the three nodes for each of the three scoring measures .