3.6 calculating tf-idf-weighting following the careful empirical-investigation of salton and buckley [salton and buckley , 1988d ; salton and buckley , 1990] and many others since [harman , 1992a] , we will concentrate on the tf-idf-weighting , which multiplies the raw term-frequency (tf) of a term in a document by the term 's inverse-document-frequency (idf) weight : idfk = log (^ ^ j (3.40) = fkd where fkd is the frequency with which keyword fc occurs in document d , ndoc is the total number of documents in the corpus , and d is the number of documents containing keyword k. due to the wide variety observed in users ' query-patterns , methods for weighting queries vary more , primarily depending on the length of the query . we will consider two weighting methods , especially designed for ushorf and `` long '' queries . short queries (of as few as one or two terms ; cf. [silverstein et al , 1999]) seem typical of those issued by web-search-engine users . for these , we can assume multiple occurrences of the same keyword will be rare , and we ignore length-normalization . this weighting and matching against indices 97 leaves us with simply the term 's inverse frequency-weight : tyk (3-42) long-queries are often generated indirectly , as the result of relevance-feedback from the users in response to prior retrievals . the long query corresponds to a particular document that the users like ; searching for others like a known target is called query-by-example . by symmetry , it makes sense to use the same weighting of terms in this query-cum-document as we used for documents (equation 3.40) : wkq ^ qn = fkq idfy (3.43) notice that once the lengths of the q and d vectors in the denominator of equation 3.39 are known , the computation of sim requires a simple sum of products over all terms shared by query and document . because both these lengths can be computed independently , it makes sense to compute them first . ^ implementation : in fact , the document length len (d) can be computed before any storing , , document query activity takes place : lenglhs (3.44) with these definitions in place , we can begin to design an algorithm for computing similarity .