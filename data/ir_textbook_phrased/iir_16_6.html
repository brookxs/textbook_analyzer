references and further reading berkhin (2006b) gives a general up-to-date survey of clustering-methods with special attention to scalability . the classic reference for clustering in pattern-recognition , covering both - means and em , is (duda et al. , 2000) . rasmussen (1992) introduces clustering from an information-retrieval perspective . anderberg (1973) provides a general introduction to clustering for applications . in addition to euclidean-distance and cosine-similarity , kullback-leibler-divergence is often used in clustering as a measure of how (dis) similar documents and clusters are (xu and croft , 1999 , muresan and harper , 2004 , kurland and lee , 2004) . the cluster-hypothesis is due to jardine and van rijsbergen (1971) who state it as follows : associations between documents convey information about the relevance of documents to requests . croft (1978) , can and ozkarahan (1990) , voorhees (1985a) , salton (1975) , cacheda et al. (2003) , salton (1971a) , singitham et al. (2004) , can et al. (2004) and altingövde et al. (2008) investigate the efficiency-and-effectiveness of cluster-based-retrieval . while some of these studies show improvements in effectiveness , efficiency or both , there is no consensus that cluster-based-retrieval works well consistently across scenarios . cluster-based language modeling was pioneered by liu and croft (2004) . there is good evidence that clustering of search-results improves user-experience and search result quality (hearst and pedersen , 1996 , zamir and etzioni , 1999 , käki , 2005 , toda and kataoka , 2005 , tombros et al. , 2002) , although not as much as search result structuring based on carefully edited category hierarchies (hearst , 2006) . the scatter-gather interface for browsing collections was presented by cutting et al. (1992) . a theoretical-framework for analyzing the properties of scatter/gather and other information-seeking user-interfaces is presented by pirolli (2007) . schütze and silverstein (1997) evaluate lsi (chapter 18) and truncated representations of centroids for efficient - means clustering . the columbia newsblaster system (mckeown et al. , 2002) , a forerunner to the now much more famous and refined google-news (http://news.google.com) , used hierarchical-clustering (chapter 17) to give two levels of news topic granularity . see hatzivassiloglou et al. (2000) for details , and chen and lin (2000) and radev et al. (2001) for related systems . other applications of clustering in information-retrieval are duplicate-detection (yang and callan (2006) , shingling) , novelty-detection (see references in hclstfurther) and metadata discovery on the semantic-web (alonso et al. , 2006) . the discussion of external evaluation-measures is partially based on strehl (2002) . dom (2002) proposes a measure that is better motivated theoretically than nmi . is the number of bits needed to transmit class memberships assuming cluster memberships are known . the rand index is due to rand (1971) . hubert and arabie (1985) propose an adjusted that ranges between and 1 and is 0 if there is only chance-agreement between clusters and classes (similar to in chapter 8 , page 8.2) . basu et al. (2004) argue that the three evaluation-measures nmi , rand index and f-measure give very similar results . stein et al. (2003) propose expected edge-density as an internal measure and give evidence that it is a good predictor of the quality of a clustering . kleinberg (2002) and meila (2005) present axiomatic frameworks for comparing clusterings . authors that are often credited with the invention of the - means algorithm include lloyd (1982) (first distributed in 1957) , ball (1965) , macqueen (1967) , and hartigan and wong (1979) . arthur and vassilvitskii (2006) investigate the worst-case complexity of - means . bradley and fayyad (1998) , pelleg and moore (1999) and davidson and satyanarayana (2003) investigate the convergence-properties of - means empirically and how it depends on initial seed-selection . dhillon and modha (2001) compare - means clusters with svd - based clusters (chapter 18) . the k-medoid algorithm was presented by kaufman and rousseeuw (1990) . the em-algorithm was originally introduced by dempster et al. (1977) . an in-depth treatment of em is (mclachlan and krishnan , 1996) . see section 18.5 (page) for publications on latent analysis , which can also be viewed as soft-clustering . aic is due to akaike (1974) (see also burnham and anderson (2002)) . an alternative to aic is bic , which can be motivated as a bayesian-model-selection procedure (schwarz , 1978) . fraley and raftery (1998) show how to choose an optimal number of clusters based on bic . an application of bic to - means is (pelleg and moore , 2000) . hamerly and elkan (2003) propose an alternative to bic that performs better in their experiments . another influential bayesian-approach for determining the number of clusters (simultaneously with cluster-assignment) is described by cheeseman and stutz (1996) . two methods for determining cardinality without external-criteria are presented by tibshirani et al. (2001) . we only have space here for classical completely unsupervised-clustering . an important current topic of research is how to use prior-knowledge to guide clustering (e.g. , ji and xu (2006)) and how to incorporate interactive-feedback during clustering (e.g. , huang and mitchell (2006)) . fayyad et al. (1998) propose an initialization for em-clustering . for algorithms that can cluster very-large-data-sets in one scan through the data see bradley et al. (1998) . the applications in table 16.1 all cluster documents . other information-retrieval applications cluster words (e.g. , crouch , 1988) , contexts of words (e.g. , schütze and pedersen , 1995) or words and documents simultaneously (e.g. , tishby and slonim , 2000 , zha et al. , 2001 , dhillon , 2001) . simultaneous-clustering of words and documents is an example of co-clustering or biclustering .