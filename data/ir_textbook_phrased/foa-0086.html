5.1.1 discussion obviously these formulas all depend on the alphabet size selected , and this will certainly not be feed across the systems considered . for example , it is not unusual for an ir-system to `` fold case , '' i.e. , to treat upperand lowercase letters interchangeably , but many also preserve this case-information . the capitalization of proper-names will sometimes provide critical clues for appropriate index-terms . similarly , our choice of which characters we use to break the stream into wordlike tokens has consequence . fortunately for the robustness of zipps law , the alphabets typically considered in these analyses are generally large enough that differences between only uppercase or upper - and lowercase alphabets are inconsequential . figure 5,2 , showing how quickly a becomes nearly unity as the size of the character-set grows , also makes it clear why zipf 's simpler hyperbolic form is an adequate approximation . it is also interesting to note a potential connection between zipps law and information theory . mandelbrot [mandelbrot , 1953 ; mandelbrot , 1982] initially attempted to derive zipps law as the solution minimizing the average-cost per unit of information conveyed by a text . george miller seems to have found this effort amusing : mathematical foundations 153 ... the random placement of spaces which leads to zipfs rule is actually the optimal-solution . our monkeys are doing the best possible job of encoding information word-by-word , subject to the constraints we impose on them . if we were as smart as the monkeys we , too , would generate all possible sequences of letters and so make better use of our alphabet . [miller , 1957]