3.3.1 lexical consequences , internal/external perspectives the plot in figure 3.2 is based on word-frequency statistics like those shown in table 3.2 . note that on the log-log plot in figure 3.2 , frequency is a nearly linear inverse function of rank . one way to make the various lexical decisions considered in the last chapter is to consider the effects of various decisions in terms of statistics such as these . table 3.3 shows the statistics for stemmed , nonnoise 72 finding out about table 3.2 ait keywords frequency/rank distribution . rank frequency keyword rank frequency keyword 1 25,438 system 20 4836 algorithm 2 24,745 univers 100 1646 dissert 3 12,107 base 200 971 util 4 11,938 network 300 767 zurich 5 11,930 model 400 624 genet 6 10,303 de 500 474 event 7 8568 knowledg 600 363 definit 8 8320 neural 700 289 underli 9 7465 process 800 234 explicit 10 7293 design 900 196 teach 11 6758 control 1000 171 lisp 12 6308 intellig 1500 89 advis 13 6308 develop 2000 51 compound 14 6243 use 2500 33 praisal 15 6074 learn 3000 24 af 16 5837 applic 4000 13 meshe 17 5617 expert 5000 8 hermeneut 18 5558 approach 6000 4 html 19 5464 comput 6660 3 replai word tokens (shown in monospaced font , e.g. , system) , together with noise words (shown in italics , e.g. , the) . as expected , the noise words occur very frequently . but it is interesting to contrast those very frequent words defined a priori in the negative dictionary with those that occur especially frequently in this particular corpus . in many ways these are excellent candidates for external keywords : characterizations of this corpus 's content , from the `` external '' perspective of general language-use . that is , these are exactly the words (cf. neural-network , base , learn , world , knowledge) that could suggest to a www-browser that the ait corpus might be worth visiting . once `` inside '' the topical domain of ai , however , these same words (cf. system , model , process , design) become as ineffective as other noise words , as internal keywords , discriminating the contents of one ait dissertation from the next . table 33 also shows statistics both with and without stemming . for example , the token system itself appeared only 8632 times ; variations like systems and systematic must account for the other 12,856 . this simple example also demonstrates how issues of phrase-recognition weighting and matching against indices 73 table 3.3 consequences of lexical decisions on word-frequencies unstemrned unstemmed token-frequency frequency token-frequency frequency the 78,428 that 9820 of 50,026 are 9792 and 33,834 leabn 9293 a 31,347 world 8103 to 28,666 la ? 7678 in 21,512 an 7593 system 21,488 8,632 knowledg 7410 5,496 is 18,781 hetobal 7220 3,912 model 14,772 4,796 with 7197 for 14,640 as 6964 de ? 11,923 on 6920 network 10,306 3,965 by 6886 this 10,095 process 6569 2,900 base 9838 design 6362 3,308 (cf. neural-network) and other messy issues (e.g. , the presence of french noise words in some of the dissertation abstracts but not in our english negative dictionary) can arise in even the simplest , `` cleanest '' corpora .