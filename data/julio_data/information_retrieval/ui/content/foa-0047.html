 3.3.4 Language Distribution  We next move beyond characteristics of single keywords to an analysis of the distribution of the entire set of index terms. Any index, whether constructed manually or automatically based on word frequency patterns, is defined by a tension between exhaustivity on the one hand and specificity on the other. An index is exhaustive if it includes many topics. It is specific if users can precisely identify their information needs.  Unfortunately, these two intuitively reasonable desiderata are in some sense at odds with one another, as suggested by Figure 3.4. The best explanation of this trade-off is in terms of precision and recall WEIGHTING AND MATCHING AGAINST INDICES       79  (cf. Section 4.3.4): High recall is easiest when an index is exhaustive but is not very specific; high precision is best accomplished when the index is not very exhaustive but is highly specific. If we assume that the same index must serve many users, each with varying expectations regarding the precision and recall of their retrieval, the best index will be at some balance point between these goals.  If we index a document with many keywords, it will be retrieved more often; hence we can expect higher recall, but precision may suffer. Van Rijsbergen has talked about this extreme as a "document" orientation, or representation bias [van Rijsbergen, pp. 24, 29 ]. A documentoriented approach to index-building focuses the system builder's attention on a careful representation of each document, based on an analysis of what it is about.  However, an index's fundamental purpose is to reconcile a corpus's many document descriptions with the many anticipated users' queries. We could equally well analyze the problem from a query-oriented perspective - How well do the query terms discriminate one document from another?  From the users' perspective, we'd like to have these queries match meaningfully onto the vocabulary of our index. From the perspective of the corpus, we'd like to be able to discriminate one document from another. These are very different perspectives on an index, and they reflect a fundamental vocabulary mismatch [FurnasetaL, 1987] between the way users describe their interests and the way documents have been described.  If an indexing vocabulary is specific, then a user should expect that just the right keyword in a magic bullet query will elicit all and only relevant documents. The average number of documents assigned to specific keywords should be low. In an exhaustive indexing, the many aspects of a document will each be reflected by expressive keywords; on average many keywords will be assigned to a document:  Ikw\  Exhaustivity  oc   { ó- } \docj  The important observation is that these two averages must be taken across different distributions. We already know from Zipf s law that the 80      FINDING OUT ABOUT  Documents  Keyword distribution  ndex  NDoc  Document corpus  FIGURE 3.5 Indexing Graph  number of occurrences varies dramatically from one keyword to another. Once we make an assumption about how keywords occur within separate documents, we can derive the distribution of keywords across documents. However, the distribution of keywords assigned to documents can be expected to be much more uniform; documents are about a nearly uniform or constant number of topics. Figure 3.5 represents the index as a graph, where edges connect keyword nodes on the left with document nodes on the right. The Index graph is a bipartite graph, with its nodes divided into two subsets (keywords and documents) and nodes in one set having connections only with those in the other. If we assume that the total number of edges must remain constant, we can assume that the total area under both distributions is the same. The quantity capturing the exhaustivity/specificity trade-off is therefore the ratio of Vocab to corpus size NDoc  Although this analysis is crude, it does highlight two important features of every index. First, in most applications NDoc is fixed and Vocab is a matter of discretion, a free variable that can be tuned to increase or decrease specificity and exhaustivity. Second, certainly in WEIGHTING AND MATCHING AGAINST INDICES       81  most modern applications (i.e., with the huge disk volumes now common), NDoc ^gt; Vocab. This is one of the most important ways in which experimental collections (including AIT) differ from real corpora. A useful indexing vocabulary can be expected to be of a relatively constant size, Vocab ´ 103 to 105gt; while corpora sizes are likely to vary dramatically, NDoczt 104tol09.  Along similar lines, it is always useful to think about what this means in the context of the WWW, where the notion of a closed corpus disappears. The WWW is an organic, constantly growing set of documents; our vocabulary for describing it is more constrained.  Several other basic features of an index are shown in Figure 3.5. The flipped histogram along the left side is meant to reflect the Zipfian distribution of keywords, with the most frequent keywords beginning at the top. Recall that this distribution captures the total number of word occurrences, regardless of how these occurrences are distributed across interdocument boundaries. A second distribution is also sketched, suggesting how the number of documents versus word occurrences might be distributed; we can expect these two quantities to be at least loosely correlated. The distinction between intra- and interdocument word frequencies is a topic we'll return to in Section 3.3.7.   