 4.4.1 History  The first use of n-grams dates to World War II when it was used by cryptographers. Fletcher Pratt states that "with the backing of bigram and trigram tables any cryptographer can dismember an simple substitution cipher" (Pratt-42). Use of bigrams was described by Adamson as a method for conflating terms (Adamson-74). It does not follow the normal definition of stemming because what is produced by creating n-grams are word fragments versus semantically meaningful word stems. It is this characteristic of mapping longer words into shorter n-gram fragments that seems more appropriately classified as a data structure process than a stemming process.  Another major use of n-grams (in particular trigrams) is in spelling error detection and correction (AngeIl-83, McIllroy-82, Morris-75, Peterson-80, Thorelli-62, Wang-77, and Zamora-81). Most approaches look at the statistics on probability of occurrence of n-grams (trigrams in most approaches) in the English vocabulary and indicate any word that contains non-existent to seldom used 11gram s as a potential erroneous word. Damerau specified four categories of spelling errors (Damerau-64) as shown in Figure 4.8. Using the classification scheme, Zamora showed trigram analysis provided a viable data structure for identifying misspellings and transposed characters. This impacts information systems as a possible basis for identifying potential input errors for correction as a procedure within the normalization process (see Chapter 1). Frequency of occurrence of ngram patterns also can be used for identifying the language of an item (Damashek95, Cohen-95). Data Structure                                                                                          37  Error Category Single Character Insertion Single Character Deletion Single Character Substitution Transposition of two adjacent characters  Figure 4.8 Categories of Spelling Errors  In information retrieval, trigrams have been used for text compression (Wisn-87) and to manipulate the length of index terms (Will-79, Schek-78, Schuegraf-76). D'Amore and Mah (D'Amore-85) used a variety of different 11gram s as index elements for inverted file systems they implemented- They have also been the core data structure to encode profiles for the Logicon LMDS system (Yochum-95) used for Selective Dissemination of Information. For retrospective search, the Acquaintance System uses n-grams to store the searchable document file (Damashek-95, Huffman-95) for retrospective search of large textual databases.   