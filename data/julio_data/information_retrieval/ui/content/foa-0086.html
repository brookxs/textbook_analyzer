 5.1.1 Discussion  Obviously these formulas all depend on the alphabet size selected, and this will certainly not be feed across the systems considered. For example, it is not unusual for an IR system to "fold case," i.e., to treat upperand lowercase letters interchangeably, but many also preserve this case information. The capitalization of proper names will sometimes provide critical clues for appropriate index terms. Similarly, our choice of which characters we use to break the stream into wordlike tokens has consequence.  Fortunately for the robustness of ZipPs law, the alphabets typically considered in these analyses are generally large enough that differences between only uppercase or upper- and lowercase alphabets are inconsequential. Figure 5,2, showing how quickly a becomes nearly unity as the size of the character set grows, also makes it clear why Zipf's simpler hyperbolic form is an adequate approximation.  It is also interesting to note a potential connection between ZipPs law and information theory. Mandelbrot [Mandelbrot, 1953; Mandelbrot, 1982] initially attempted to derive ZipPs law as the solution minimizing the average cost per unit of information conveyed by a text. George Miller seems to have found this effort amusing: MATHEMATICAL FOUNDATIONS       153  ... the random placement of spaces which leads to ZipFs rule is actually the optimal solution. Our monkeys are doing the best possible job of encoding information word-by-word, subject to the constraints we impose on them. If we were as smart as the monkeys we, too, would generate all possible sequences of letters and so make better use of our alphabet. [Miller, 1957]   