 5.3.2    Query Expansion Through Local Context Analysis The local clustering techniques discussed above are based on the set of documents retrieved for the original query and use the top ranked documents for clustering neighbor terms (or stems). Such a clustering is based on term (stems were considered above) co-occurrence inside documents. Terms which are the best neighbors of each query term are then used to expand the original query q. A distinct approach is to search for term correlations in the whole collection ó an approach called global analysis. Global techniques usually involve the building of a thesaurus which identifies term relationships in the whole collection. The terms are treated as concepts and the thesaurus is viewed as a concept relationship structure. Thesauri are expensive to build but, besides providing support for query expansion, are useful as a browsing tool as demonstrated by some search engines in the Web. The building of a thesaurus usually considers the use of small contexts and phrase structures instead of simply adopting the context provided by a whole document. Furthermore, with modern variants of global analysis, terms which are closest to the whole query (and not to individual query terms) are selected for query expansion. The application of ideas from global analysis (such as small contexts and phrase structures) to the local set of documents retrieved is a recent idea which we now discuss. Local context analysis [838] combines global and local analysis and works as follows. First, the approach is based on the use of noun groups (i.e., a single noun, two adjacent nouns, or three adjacent nouns in the text), instead of simple keywords, as document concepts. For query expansion, concepts are selected froiri the top ranked documents (as in local analysis) based on their co-occurrence with query terms (no stemming). However, instead of documents, passages (i.e., a text window of fixed size) are used for determining co-occurrence (as in global analysis). More specifically, the local context analysis procedure operates in three steps. ï First, retrieve the top n ranked passages using the original query.   This is accomplished by breaking up the documents initially retrieved by the 130        QUERY OPERATIONS query in fixed length passages (for instance, of size 300 words) and ranking these passages as if they were documents. ï  Second, for each concept c in the top ranked passages, the similarity sirn(q)c) between the whole query q (not individual query terms) and the concept c is computed using a variant of tf-idf ranking. ï  Third, the top m ranked concepts (according to sim(q,c)) are added to the original query q. To each added concept is assigned a weight given by 1 ó 0.9 x i/m where i is the position of the concept in the final concept ranking. The terms in the original query q might be stressed by assigning a weight equal to 2 to each of them. Of these three steps, the second one is the most complex and the one which we now discuss. The similarity sim(q, c) between each related concept c and the original query q is computed as follows.  where n is the number of top ranked passages considered. The function /(c, ki) quantifies the correlation between the concept c and the query term fcj and is given by where pfij is the frequency of term k2 in the j-th passage and pfCiJ is the frequency of the concept c in the j-th passage. Notice that this is the standard correlation measure defined for association clusters (by Equation 5.5) but adapted for passages. The inverse document frequency factors are computed as idjx    =    mar(l,ó  where Ar is the number of passages in the collection, npt is the number of passages containing the term kv and npc is the number of passages containing the concept c. The factor 5 is a constant parameter which avoids a value equal to zero for sirn(q,c) (which is useful, for instance, if the approach is to be used with probabilistic frameworks such as that provided by belief networks). Usually, 8 is a small factor with values close to 0.1 (10% of the maximum of 1). Finally, the idft factor in the exponent is introduced to emphasize infrequent query terms. The procedure above for computing sirniq.c) is a non-trivial variant of tf-idf ranking.  Furthermore, it lias been adjusted for operation with TREC data AUTOMATIC GLOBAL ANALYSIS        131 and did not work so well with a different collection. Thus, it is important to have in mind that tuning might be required for operation with a different collection. We also notice that the correlation measure adopted with local context analysis is of type association. However, we already know that a correlation of type metric is expected to be more effective. Thus, it remains to be tested whether the adoption of a metric correlation factor (for the function /(c, fe^)) makes any difference with local context analysis.  