 3.3.1      Indexing by Term  When the terms of the original item are used as a basis of the index process, there are two major techniques for creation of the index: statistical and natural language. Statistical techniques can be based upon vector models and probabilistic models with a special case being Bayesian models. They are classified as statistical because their calculation of weights use statistical information such as the frequency of occurrence of words and their distributions in the searchable database. Natural language techniques also use some statistical information, but perform more complex parsing to define the final set of index concepts.  Often weighted systems are discussed as vectorized information systems. This association comes from the SMART system at Cornell University created by Dr. Gerald Salton (Salton-73, Salton-83). The system emphasizes weights as a foundation for information detection and stores these weights in a vector form. Each vector represents a document and each position in a vector represents a different unique word (processing token) in the database. The value assigned to each position is the weight of that term in the document. A value of zero indicates that the word was not In the document. The system and its associated research results have been evolving for over 30 years. Queries can be translated into the vector form. Search is accomplished by calculating the distance between the query vector and the document vectors.  In addition to a vector model, the other dominant approach uses a probabilistic model. The model that has been most successful in this area is the Bayesian approach. This approach is natural to information systems and is based upon the theories of evidential reasoning (drawing conclusions from evidence). Bayesian approaches have long been applied to information systems (Maron-60). The Bayesian approach could be applied as part of index term weighting, but usually is applied as part of the retrieval process by calculating the relationship between an item and a specific query. A Bayesian network is a directed acyclic graph in which each node represents a random variable and the arcs between the nodes represent a probabilistic dependence between the node and  its parents 62                                                                                                Chapter 3  (Howard-81, Pearl-88).   Figure 3.3 shows the basic weighting approach for index terms or associations between query terms and index terms.  Figure 3.3 Two-level Bayesian network  The nodes C] and C2 represent "the item contains concept C," and the F nodes represent "the item has feature (e.g., words) Fy." The network could also be interpreted as C representing concepts in a query and F representing concepts in an item. The goal is to calculate the probability of Q given Fy. To perform that calculation two sets of probabilities are needed:  1.    The prior probability P(Q) that an item is relevant to concept C  2.    The conditional probability P(Fjj/Q) that the features Fy where] = 1, m are present in an item given that the item contains topic Q.  The automatic indexing task is to calculate the posterior probability P(C,/F,i, ... ,Fim), the probability that the item contains concept C, given the presence of features F,j. The Bayes inference formula that is used is:  P(C/Flh ..., Fta) = P(C,) P(F,,,..., FJCdnhn .Âª , F!m).  If the goal is to provide ranking as the result of a search by the posteriors, the Bayes rule can be simplified to a linear decision rule:  where I(Flk) is an indicator variable that equals ! only if Flk is present in the item (equals zero otherwise) and w is a coefficient corresponding to a specific feature/concept pair. A careful choice of w produces a ranking in decreasing order that is equivalent to the order produced by the posterior probabilities. Interpreting the coefficients, w, as weights corresponding to each feature (e.g., index term) and the function g as the sum of the weights of the features, the result of applying the formula is a set of term weights (Fung-95). Cataloging and Indexing                                                                              63  Another approach to defining indexes to items is via use of natural language processing. The DR-LINK (Document Retrieval through Linguistic Knowledge) system processes items at the morphological, lexical, semantic, syntactic, and discourse levels (Liddy-93, Weiner-95). Each level uses information from the previous level to perform its additional analysis. The discourse level is abstracting information beyond the sentence level and can determine abstract concepts using pre-defined models of event relationships. This allows the indexing to include specific term as well as abstract concepts such as time (e.g., differentiates between a company was sold versus a company will be sold). Normal automatic indexing does a poor job at identifying and extracting "verbs" and relationships between objects based upon the verbs.   