 8.6.1    String Matching Allowing Errors This problem (called "approximate string matching')   can be stated as follows: given a short pattern P of length m, a long text T of length n, and a maximum allowed number of errors fc, find all the text positions where the pattern occurs with at most k errors. This statement corresponds to the Levenshtein distance. With minimal modifications it is adapted to searching whole wrords matching the pattern with k errors. This problem is newer than exact string matching, although there are already a number of solutions. We sketch the main approaches. Dynamic Programming The classical solution to approximate string matching is based on dynamic programming.   A matrix C[0..m,0..nj is filled column by column, where C[?\jj PATTERN MATCHING         217 represents the minimum number of errors needed to match Pi..$ to a suffix of Ti,,j. This is computed as follows C[0J] = 0 C[t,0] = i C[iJ]    =    if (Pi = Tj) then C[i-lJ~ I] else 1 + min(C[i - lJ],C[i,j - l],C[i - 1,j - 1]) where a match is reported at text positions j such that C[m,j] lt; k (the final positions of the occurrences are reported). Therefore, the algorithm is O(mn) time. Since only the previous column of the matrix is needed, it can be implemented in O(m) space. Its preprocessing time is O(m) . Figure 8.21 illustrates this algorithm. In recent years several algorithms have been presented that achieve O(kn) time in the worst case or even less in the average case, by taking advantage of the properties of the dynamic programming matrix (e.g., values in neighbor cells differ at most by one). Automaton It is interesting to note that the problem can be reduced to a non-deterministic finite automaton (NFA). Consider the NFA for k = 2 errors shown in Figure 8.22. Each row denotes the number of errors seen. The first one 0, the second one 1, and so on. Every column represents matching the pattern up to a given position. At each iteration, a new text character is read and the automaton changes its states. Horizontal arrows represent matching a character, vertical arrows represent insertions into the pattern, solid diagonal arrows represent replacements, and dashed diagonal arrows represent deletions in the pattern (they are ^-transitions). The automaton accepts a text position as the end of a match s	u	r	g	e	r	y 0	0	0	0	0	0	0	0 s	i	0	1	1	1	1	1	i u	2	1	0	1	2	2	2	2 r	3	2	1	0	1	2	2	3 V	4	3	2	1	1	2	3	3 e	5	4	3	2	2	1	2	3 y	6	5	4	3	3	2	2	2 Figure   8.21    The dynamic programming algorithm search  'survey'   in  the text 'surgery" with two errors. Bold entries indicate matching positions. 218        INDEXING AND SEARCHING 1 error 2 errors Figure 8.22 An NFA for approximate string matching of the pattern 'survey' with two errors. The shaded states are those active after reading the text 'surgery'. Unla-belled transitions match anv character. with k errors whenever the (fc -f l)-th rightmost state is active. It is not hard to see that once a state in the automaton is active, all the states of the same column and higher rows are active too. Moreover, at a given text character, if we collect the smallest active rows at each column, we obtain the current column of the dynamic programming algorithm. Figure 8.22 illustrates this (compare the figure with Figure 8.21). One solution is to make this automaton deterministic (DFA). Although the search phase is O(7i), the DFA can be huge. An alternative solution is based on bit-parallelism and is explained next. Bit-Parallelism Bit-parallelism has been used to parallelize the computation of the dynamic programming matrix (achieving average complexity O(kn/w)) and to parallelize the computation of the NFA (without converting it to deterministic), obtaining O(knwlw) time in the worst case. Such algorithms achieve O(n) search time for short patterns and are currently the fastest ones in many cases, running at 6 to 111 Mb per second on our reference machine. Filtering Finally, oilier approaches first filter the text, reducing the area where1 dynamic programming needs to be used. These algorithms achieve 'sublinear* expected time in many causes for low error ratios (i.e., not all text characters are inspected. PATTERN MATCHING        219 O(kn\oga{m)/m) is a typical figure), although the nitration is not effective for more errors. Filtration is based on the fact that some portions of the pattern must appear with no errors even in an approximate occurrence. The fastest algorithm for low error levels is based on filtering: if the pattern is split into /c +1 pieces, any approximate occurrence must contain at least one of the pieces with no errors, since k errors cannot alter all the k + 1 pieces. Hence, the search begins with a multipattern exact search for the pieces and it later verifies the areas that may contain a match (using another algorithm).  