 Interactive search formulation  A user confronted with an automatic retrieval system is unlikely to be able to express his information need in one go. He is more likely to want to indulge in a trial-and-error process in which he formulates his query in the light of what the system can tell him about his query. The kind of information that he is likely to want to use for the reformulation of his query is:  (1) the frequency of occurrence in the data base of his search terms;  (2) the number of documents likely to be retrieved by his query;  (3) alternative and related terms to be the ones used in his search;  (4) a small sample of the citations likely to be retrieved; and  (5) the terms used to index the citations in (4).  All this can be conveniently provided to a user during his search session by an interactive retrieval system. If he discovers that one of his search terms occurs very frequently he may wish to make it more specific by consulting a hierarchic dictionary which will tell him what his options are. Similarly, if his query is likely to retrieve too many documents he can make it more specific.  The sample of citations and their indexing will give him some idea of what kind of documents are likely to be retrieved and thus some idea of how effective his search terms have been in expressing his information need. He may modify his query in the light of this sample retrieval. This process in which the user modifies his query based on actual search results could be described as a form of feedback.  Examples, both operational and experimental, of systems providing mechanisms of this kind are MEdigital libraryINE[11] and MEDUSA[12] both based on the MEdigital libraryARS system. Another interesting sophisticated experimental system is that described by Oddy[13].  We now look at a mathematical approach to the use of feedback where the system automatically modifies the query.   