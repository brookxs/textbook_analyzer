 7.2.2 Hypothesis Spaces  However they are selected, the features discussed in the previous section must now be composed into hypotheses concerning how we might describe documents. There is an extraordinary range of alternatives represented here. Some of these are shown in Figure 7.3.  Decision trees are formed by asking a question about individual features and using the answers to these questions to navigate through a series of tests until documents are ultimately classified at the leaves. Weighted, linear combinations of the features can also be formed. Neural networks are best viewed as nonlinear compositions of weighted features [Crestani, 1993; Crestani, 1994; Gallant, 1991; Kwok, 1995; Wong et al, 1993]. Boolean formulas can be formed from sentences using simple conjunctive or disjunctive combinations. Our focus here will be on Bayesian networks, which attempt to represent probabilistic relationships among the features.  In any of these cases, machine learning techniques must be sensitive to their inductive bias. That is, given a fixed amount of data, we must ADAPTIVE INFORMATION RETRIEVAL       263  Decision trees  Inductive     Small  bias:               trees  Linear combinations  Neural networks  Few, small              Smooth  weights              mappings  FIGURE 7.3 Inductive Bias  Boolean formulas  Small con/disjuncts  Bayesian networks  Sparse,  acyclic  have some a priori preference for some kinds of hypotheses over others. For example, decision tree learning algorithms [Quinlan, 1993] prefer small trees and neural networks prefer smooth mappings [Mitchell, 1997].  A common feature of all of these learning algorithms is a general preference for parsimony, or simplicity. This preference is typically attributed first to William of Occam (ca. 1330). Occam's Razor has been used since then to cleave simpler hypotheses from more complex ones.  Another motivation for the parsimony bias has been realized more recently within machine learning: Simple hypotheses are more likely to accurately go beyond the data used to train them to classify other unseen data. That is, very complicated hypotheses have a tendency to over-fit to the training data given a learning algorithm, but the good fit they can accomplish on this set is not matched when the same classification is done on new data. The issues involved in evaluating a classifier's performance are an important topic within machine learning [Mitchell, 1997].   