 The model  We start by examining the structure which it is reasonable to assume for the measurement of effectiveness. Put in other words, we examine the conditions that the factors determining effectiveness can be expected to satisfy. We limit the discussion here to two factors, namely precision and recall, although this is no restriction, different factors could be analysed, and, as will be indicated later, more than two factors can simplify the analysis.  If R is the set of possible recall values and P is the set of possible precision values then we are interested in the set R x P with a relation on it. We shall refer to this as a relational structure and denote it lt;R x P, gt;= gt; where gt;= is the binary relation on R x P. (We shall use the same symbol for less than or equal to, the context will make clear what the domain is.) All we are saying here is that for any given point (R, P) we wish to be able to say whether it indicates more, less or equal effectiveness than that indicated by some other point. The kind of order relation is a weak order. To be more precise:  Definition 1. The relational structure lt;R x P, gt;= gt; is a weak order if and only if for e1, e2, e3 [[propersubset]] R x P the following axioms are satisfied:  (1) Connectedness: either e1 gt;= e2 or e2 gt;= e1  (2) Transitivity: if e1 gt;= e2 and e2 gt;= e3 then e1 gt;= e3  We insist that if two pairs can be ordered both ways then (R1, P1) ~ (R2, P2), i.e. equivalent not necessarily equal. The transitivity condition is obviously desirable.  We now turn to a second condition which is commonly called independence. This notion captures the idea that the two components contribute their effects independently to the effectiveness.  Definition 2. A relation gt;= on R x P is independent if and only if, for R1, R2 [[propersubset]] R, (R1, P) gt;= (R2, P ) for some P [[propersubset]] P implies (R1, P' ) gt;= (R2, P' ) for every P' [[propersubset]] P; and for P1, P2 [[propersubset]] P, (R, P1) gt;= (R, P 2) for some R [[propersubset]] R implies (R', P1) gt;= (R', P 2) for every R '[[propersubset]] R.  All we are saying here is, given that at a constant recall (precision) we find a difference in effectiveness for two values of precision (recall) then this difference cannot be removed or reversed by changing the constant value.  We now come to a condition which is not quite as obvious as the preceding ones. To make it more meaningful I shall need to use a diagram, Figure 7.12, which represents the ordering we have got so far with definitions 1 and 2. The lines l1 and l2 are lines of equal effectiveness that is any two points (R, P ), (R', P' ) [[propersubset]]li are such that (R, P) ~ (R ', P ') (where ~ indicates equal effectiveness). Now let us assume that we have the points on l1 and l2 a but wish to deduce the relative ordering in between these two lines. One may think of this as an interpolation procedure.  Definition 3 (Thomsen condition). For every R1, R2 , R3 [[propersubset]] R and P1, P2, P3 [[propersubset]] P, (R1, P3) ~ (R3, P 2) and (R3, P1) ~ (R2, P 3) imply that (R1, P1) ~ (R2, P 2).  Intuitively this can b e reasoned as follows. The intervals R1 R3 and P2 P 3 are equivalent since an increase in the R-factor by R1 R3 and an increase in the P-factor by P2 P3 starting from (R1 , P3) lead to the same effectiveness (points on l2). It therefore follows that a decrease in each factor starting from equal effectiveness, in this case the two points (R3, R1) and (R2 , P3) on l1, should lead to equal effectiveness.  The fourth condition is one concerned with the continuity of each component. It makes precise what intuitively we would expect when considering the existence of intermediate values.  Definition 4 (Restricted Solvability). A relation gt;= on R x P satisfies restricted solvability provided that:  (1) whenever R, `R, R [[propersubset]] R and P, P' [[propersubset]] P for which (`R, P') gt;= (R, P) gt;= (R, P') then there exists R [[propersubset]] R s.t. (R, P') ~ (R, P);  (2) a similar condition holds on the second component.  In other words we are ensuring that the equation (R', P') ~ (R, P) is soluble for R' provided that there exist `R, R such that (`R, P') gt;= (R, P') gt;= (R, P'). An assumption of continuity of the precision and recall factors would ensure this.  The fifth condition is not limiting in any way but needs to be stated. It requires, in a precise way, that each component is essential.  Definition 5. Component R is essential if and only if there exist R1, R2 [[propersubset]] R and P1 [[propersubset]] P such that it is not the case that (R1, P1) ~ (R2, P1). A similar definition holds for P.  Thus we require that variation in one while leaving the other constant gives a variation in effectiveness.  Finally we need a technical condition which will not be explained here, that is the Archimedean property for each component. It merely ensures that the intervals on a component are comparable. For details the reader is referred to Krantz et al.  We now have six conditions on the relational structure lt;R x P, gt;= gt; which in the theory of measurement are necessary and sufficient conditions* for it to be an additive conjoint structure. This is enough for us to state the main representation theorem. It is a theorem asserting that if a given relational structure satisfies certain conditions (axioms), then a homomorphism into the real numbers is often referred to as a scale. Measurement may therefore be regarded as the construction of homomorphisms for empirical relational structures of interest into numerical relational structures that are useful.  In our case we can therefore expect to find real-valued functions [[Phi]]1 on R and [[Phi]]2 on P and a function F from Re x Re into Re, 1:1 in each variable, such that, for all R, R' [[propersubset]] R and P, P' [[propersubset]] P we have:  (R, P) gt;= (R', P') lt;=gt; F [[[Phi]]1 (R ), [[Phi]]2 (P )] gt;= F [[[Phi]]1 (R' ), [[Phi]]2 (P' )]  (Note that although the same symbol gt;= is used, the first is a binary relation on R x P, the second is the usual one on Re, the set of reals.)  In other words there are numerical scales [[Phi]]i on the two components and a rule F for combining them such that the resultant measure preserves the qualitative ordering of effectiveness. When such a representation exists we say that the structure is decomposable. In this representation the components (R and P) contribute to the effectiveness measure independently. It is not true that all relational structures are decomposable. What is true, however, is that non-decomposable structures are extremely difficult to analyse.  A further simplification of the measurement function may be achieved by requiring a special kind of non-interaction of the components which has become known as additive independence. This requires that the equation for decomposable structures is reduced to:  (R, P) gt;= (R', P' ) lt;=gt; [[Phi]]1 (R ) + [[Phi]]2 (P ) gt;= [[Phi]]1 (R' ) + [[Phi]]2 (P' )  where F is simply the addition function. An example of a non-decomposable structure is given by:  (R, P) gt;= (R', P') lt;=gt; [[Phi]]1 (R ) + [[Phi]]2 (P ) + [[Phi]]1 (R ) [[Phi]]2 (P ) gt;= [[Phi]]1 (R' ) + [[Phi]]2 (P' ) +  + [[Phi]]1 (R' )[[Phi]]2 (P' )  * It can be shown that (starting at the other end) given an additively independent representation the properties defined in 1 and 3, and the Archimedean property are necessary. The structural conditions 4 and 5 are sufficient.  Here the term [[Phi]]1 [[Phi]]2 is referred to as the interaction term, its absence accounts for the non-interaction in the previous condition.  We are now in a position to state the main representation theorem.   