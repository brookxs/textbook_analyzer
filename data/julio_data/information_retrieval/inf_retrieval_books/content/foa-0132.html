 6.5.2 Spreading Activation Search  The facts that keywords can be associated with documents or with one another, that documents become associated by citations, and so on led early IR pioneers such as Doyle and Stiles to adopt simple association as a unifying relation connecting many objects of the FOA inquiry [Doyle, 1960; Doyle, 1961; Doyle, 1962; Stiles, 1961; Maron, 1982b; Giuliano, 1963; Findler, 1979]. Integrating information across semantic networks of such associative relations has been an important example of knowledge representation within AI since the memory models of Collins and Qullian [Collins and Quillian, 1972]. In its simplest form, a simple quantity known as activity is allowed to propagate through a network like that shown in Figure 6.18 from several sources. Spreading 226      FINDING OUT ABOUT  Goal  FIGURE 6.18 Spreading Activation Search  activation search is the name for a broad range of techniques that find solutions (for example, a path from Start to Goal in Figure 6.18) by controlling the propagation of activity through associative networks like this [Preece, 1981; Salton and Buckley, 1988a; Cohen and Kjeldsen, 1987].  The Adaptive Information Retrieval (AIR) system was a prototype search engine built as part of my dissertation at the University of Michigan in the mid-1980s [Belew, 1986; Belew, 1989]. This research was one of several systems applying connectionist (neural network) learning methods to the IR search engine problem [Mozer, 1988; Bein and Smolensky, 1988; Doszkocs et al.? 1990; Belew, 1987b].  Basic Representation  In AIR, each new document first causes a corresponding document node to be generated. An author node is then generated (if it doesn't already exist) for each author of the document. Two links are then created between the document and each of its keywords (one in each direction), and two more between the document and each of its authors. Weights are assigned to these links according to an inverse frequency weighting scheme: The sum of the weights on all links going out of a node is forced to be a constant; in our system that constant is one. Figure 6.19 shows the subnet corresponding to the book Parallel Models ofAssociative INFERENCE BEYOND THE INDEX      227  [Hinton and Anderson 1984]  FIGURE 6.19 Subnet Corresponding to Each Document  Memory, by G. E. Hinton and J. A. Anderson [Hinton and Anderson,  1984].  The initial network is constructed from the superposition of many such documents' representations. Most of the experiments described in this report used a network constructed from 1600 documents, forming a network of approximately 5000 nodes. This is a trivial corpus that uses relatively crude lexical analysis and keyword weighting ideas. However, AIR requires only that the initial automatic indexing assign some weighted set of tentative keywords to each document.  There is one property of the inverse weighting scheme on which AIR does depend, however. A network built using this keyword weighting scheme, together with similar constraints on the weights assigned to author links, has the satisfying property of'conserving activity. That is, if a unit of activity is put into a node and the total outgoing associativity from that node is one, the amount of activity in the system will neither increase nor diminish. This is helpful in controlling the spreading activation dynamics of the network during querying. 228      FINDING OUT ABOUT  Querying and Retrieval  Users begin a session with AIR by describing their information need, using a very simple query language. An initial query is composed of one or more clauses. Each clause can refer to one of the three types of "features" represented in AIR's network: keywords, documents, or authors, and all but the first clause can be negated. This query causes activity to be placed on nodes in AIR's network corresponding to the features named in the query This activity is allowed to propagate throughout the network, and the system's response is the set of nodes that become most active during this propagation.  The traditional result of a query is only documents. AIR also provides keywords and authors. Keywords retrieved in this manner are considered related terms that users may use to pursue their searches. Retrieved authors are considered to be closely linked to the subject of interest. There are many ways in which a user might find related terms and centrally involved authors, a valuable information product in their own right.  Figure 6.20 shows AIR's response to a typical query:  (OTERM "ASSOCIATIVE")(:AUTH "ANDERSON, J. A."))  This is the network of keywords, documents, and authors considered relevant to this query. The nodes are drawn as a tripartite graph with keywords on the top level, documents in the middle, and authors on the bottom. Associative links that helped to cause a node to become retrieved (and only those links) are also displayed. Heavier lines imply stronger associative weights. AIR uses directed links, and this directionality is represented by the concavity of the arcs; a clockwise convention is used. For example, a link from a document node (in the middle level) to a keyword node (in the top level) goes clockwise, around to the left.  Actually, this is only a picture of the final state of the system's retrieval. The network is actually drawn incrementallyy with the first nodes to become significantly active being drawn first and in the middle of the pane. As additional nodes become active at significant levels, they are drawn farther out along the three horizontal axes and the links through which they became active are drawn as well. This dynamic display has at INFERENCE BEYOND THE INDEX      229  Qu´Ogt;  )...);   {{item lt;´saoet´ttv´gt; )( ;´wcn 'ª*wtrsofl, j** gt;  FIGURE 6.20 AIR Interface  least two real advantages. First, the fact that AIR provides the first part of its retrieval almost immediately means that the user is not impatiently waiting for the retrieval to complete (typically 5 to 10 seconds in this implementation). Second, displaying the query's dynamics helps to give the user a tangible feeling of "direct manipulation" [Rose and Belew, 1990]; the user "prods" the network in a certain place and then watches as waves of activity flow outward from that place.  relevance feedback in AIR  Queries subsequent to the first are performed differently. After AIR has  retrieved the network of features, the user responds with relevance feedback, indicating which features are considered (by that user) relevant to the query and which are not. Using a mouse, the user marks features with the symbols:  ©©, Ægt; 9, and 90, indicating that the feature was Very Relevant, Relevant, Irrelevant, or Very Irrelevant, respectively. Not all features  need be commented on (cf. Section 4.1.1). 230      FINDING OUT ABOUT  The system constructs a new query directly from this feedback. First, terms from the previous query are retained. Positively marked features are added to this query, as are the negated versions of features marked negatively. Equal weight is placed on each of these features, except that features marked Very Relevant or Very Irrelevant are counted double.  From the perspective of retrieval, this relevance feedback becomes a form of browsing: Positively marked features are directions the user wants to pursue, and negatively marked features are directions that should be pruned from the search. From the perspective of learning, this relevance feedback is exactly the training signal AIR needs to modify its representations through learning. This unification of learning (i.e., changing representations) and doing (i.e., browsing) was a central component of AIR's design. It means that the collection of feedback is not an additional onerous task for the user, but rather is a natural part of the retrieval process.  Learning in AIR  Nodes marked by the user with positive or negative feedback act as sources of a signal that then propagates backwards along the weighted links. A local learning rule then modifies the weight on links directly or indirectly involved in the query process. Several learning rules were investigated; the experiments reported here used a learning rule that correlated the activity of the presynaptic nodei with the feedback signal experienced by the postsynaptic nodef.  Wjj oc Corr(ni active, rij relevant)  AIR makes a most direct correspondence between the connectionist notion of activity and the IR notion of Pr(ReI) 5.5):  The activity level of nodes at the end of the propagation phase is considered to be a prediction of the probability that this node will be judged relevant to the query presented by the user. INFERENCE BEYOND THE INDEX      231  This interpretation constrained the AIR system design in several ways (e.g., activity is a real number bounded between zero and one, query nodes are activated fully). AIR also allows negative activity, which is interpreted as the probability that a node is not relevant. The next step of the argument is to consider a link weight wab to be the conditional probability that Nodeg is relevant given that Node a is relevant. Next, this definition must be extended inductively to include indirect transitive paths that AIR uses extensively for its retrievals.  The system's interactions with users are then considered experiments. Given a query, AIR predicts which nodes will be considered relevant and the user confirms or disconfirms this prediction. These results update the system's weights (conditional probabilities) to reflect the system's updated estimates. Thus, AIR's representation results from the combination of two completely different sources of evidence: the word frequency statistics underlying its initial indexing and the opinions of its users.  A straightforward mechanism exists to incrementally introduce new documents into AIR's database. Links are established from the new document to all of its initial keywords and to its authors; new keyword and author nodes are created as necessary. The weights on these links are distributed evenly so that they sum to a constant. Because the sum of the (outgoing) weights for all nodes is to remain constant, any associative weight to the new document must come from existing link weights. A new parameter ^CONSERVATIVE*) is introduced to control the weight given these new links at the expense of existing ones. If the network is untrained by users, this parameter can be set to zero to make the effect of an incremental addition exactly the same as if the new document had been part of the initial collection. In a trained network, setting CONSERVATIVE* near unity ensures that the system's experience incorporated in existing link weights is not sacrificed to make the new connections. Also, note that the computation required to place the new document is strictly local: Only the links directly adjacent to the new document's immediate neighbors must be changed. The major observation about the inclusion of new documents, however, is that there is an immediate "place" for new documents in AIR's existing representation.  A second source of new information to the AIR system comes from users' queries. If a query contains a term unknown to AIR, this term is 232      FINDING OUT ABOUT  held in abeyance and AIR executes the query based on the remaining terms. Then, after the user has designated which of AIR's responses are relevant to this query, a new node corresponding to the new query term is created and becomes subjected to the same learning rule used for all other nodes.  Although easily incorporating new documents and new query terms is a valuable property for any IR system, from the perspective of machine learning these are examples of simple rote learning, and they are necessarily dependent on the specifics of the IR task domain. The main focus of the AIR system is the use of general-purpose connectionist learning techniques that, once the initial document network is constructed, are quite independent of the IR task.  Generalized Representation  The standard, interkeyword and interdocument associations typically evaluated as part of keyword and document clustering are part of the broader context of the associative representation used by AIR. The system extends these pairwise clustering relations and the fundamental keyword-document Index relation to include higher-order transitive relations as well. That is, if node A is associated with node B and node B is associated with node C, then node A is also considered to be associated with node C, but to a lesser extent.  Obviously, this transitive assumption is not always valid, and this may be why most IR research does not consider this extension. But AIR is an adaptive system, and one of the critical problems facing any learning system is the generation of plausible hypotheses, i.e., theories that stand a better than average chance of being correct. Transitivity is considered a default assumption, the consequences of which will be subjected to adaptations that favor appropriate transitivities and cull out inappropriate ones.  It is interesting to contrast the adaptive changes made by AIR in response to RelFhk with the document modification strategies of G. Salton and his students [Friedman et aL, 1967; Brauen, 1969] mentioned in Section 4.2.7 (and returned to in Section 7.3). The query-document matches used as the basis of their changes consider only direct, keywordto-document associations while AIR makes use of a much wider web INFERENCE BEYOND THE INDEX      233  of indirect associations. To a first approximation the changes made by AIR to direct keyword-to-document associations are not unlike those proposed by Salton and Brauen (if I'd only known!), but AIR also makes other changes, to more indirect associations.  Salton and Buckley have analyzed the spreading activation search used in some of these systems and concluded that it is inferior to more traditional retrieval methods [Salton and Buckley, 1988a; Salton and Buckley, 1988b]. They point out:  ... the relationships between terms or documents are specified by labeled links between the nodes___the effectiveness  of the procedure is crucially dependent on the availability of a representative node association map. (pp. 4, 5, emphasis added)  In a weighted, associative representation of the semantics of indexing, interdocument and interkeyword clustering links are dropped in favor of a single, homogeneous associative relation. AIR treats all three types of weighted links equally. For example, if interdocument citation data had been available, this information could naturally be included as well; again the semantics of these relations would have been dropped in favor of a simple associative weight. The contrast between the use of spreading activation search in connectionist networks with its use in semantic networks is admittedly a subtle one, but it is also critically important [Rose and Belew, 1989]. One clear difference is that semantic networks typically make logical, deterministic use of labeled links, while connectionist networks like AIR rely on weighted links for probabilistic computations.  Figure 6.21 shows how many of the features discussed here can interact as part of a single retrieval system. This figure comes from Dan Rose's SCALIR (Symbolic and Connectionist Approach to Legal Information Retrieval) system, which was built to investigate the use of both logical, "symbolic" modes of inference and probabalistic, "subsymbolic" ones. This figure shows containment relations between document elements (like those shown in more detail in Figure 6.10), topical connections between keywords, and interdocument citations, all mixed and used as part of spreading activation-based inference. 234      FINDING OUT ABOUT  FIGURE 6.21 Semantic Net of Legal Document Relations From [Rose, 1994]. Reproduced with permission of Lawrence Erlbaum   