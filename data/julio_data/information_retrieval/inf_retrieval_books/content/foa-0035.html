  3.1 Microscopic Semantics and the Statistics of Communication  In the last chapter, we described the FOA process linguistically, in terms of words that occur in documents, morphological features of these words,  structures organizing the sentences of documents, etc. We now want  to treat all of these words - which have meaning to their authors and  to us reading them - as a meaningless stream of data: word after word after word. (Imagine it coming from some SETI radio telescope, eavesdropping on the communication of some other planet!) We will now seek patterns and trends common to this data, using the same sorts of statistical tricks that physicists typically use on their data streams. What  60 WEIGHTING AND MATCHING AGAINST INDICES       61   TABLE 3.1 English Letter Frequencies  Letter         Frequency Letter Frequency  E .120 F .024  T .085 M .024  A .077 W .022  I .076 Y .022  N .067 P .020  O .067 B .017  s .067 G .017  R .059 V .012  H .050 K .007  D .042 Q .005  L .042 J .004  U .037 X .004  C .032 z .002  can we learn from looking at the statistics of our data stream, treating  text as meaningless and attempting ; to infer a new notion of meaning  from those statistics?  But now let's narrow our focus, all the way down to the bits and characters used to represent the corpus as, for example, a file on a physical device, like a hard disk. Imagine that you are an archaeologist trying to study some civilization that left this evidence behind. How might you interpret this modern Rosetta Stone?  Let's ignore those issues relating to basic ASCII encoding. That is, suppose we have special knowledge of a character set. Then the frequency of these characters' occurrences would already give us a great deal of information. Anyone who has studied simple cipher techniques (or played Scrabble) knows that a table of most frequently used letters (cf. Table 3.1 [Welsh, 1988]) can be used to break simple codes.  In this chapter we will move another level above characters. We will consider morphological transformations we can perform on character sequences that help us to identify root words. We will briefly mention phrases by which multiple words can be joined into simple phrasal units.  At each level we will ask very similar questions: What is our unit of analysis; i.e., what are we counting? Then, what does the distribution of frequency occurrences across this level of features tell us about the pattern of their use? What can we tell about the meaning of these features, based on such statistics [Francis and Kucera, 1982]? 62       FINDING OUT ABOUT  In fact, many influential thinkers have looked at such patterns among symbols. Going back to some of the most ancient writings suggests that statistical analyses of the original Hebrew characters and their positions within the two-dimensional array of the page reveals new "codes" [Witztum et aL, 1994; Drosnin, 1997].  Donald Knuth, one of computer science's most renowned theoreticians, has analyzed an apparently random verse (Chapter 3, verse 16) from 59 of the Bible's books and used these verses as the basis of stratified sampling of the approximately 30,000 Biblical verses [Knuth, 1990]. He found, for example, that the 3:16 verses were particularly rich in occurrences of YHWH, the ancient Hebrew name for God. Personally, Knuth considered this analysis the source for "historical and spiritual insights," as part of a Bible study class he led. But speaking scientifically, how can we find meaning in text, and how are such attempts to be distinguished from the kinds of "Ouija board" numerology criticized by Menaud in the quotation opening this chapter?   