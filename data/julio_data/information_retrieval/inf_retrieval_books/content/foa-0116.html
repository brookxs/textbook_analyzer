 6.1.5 Analyzing WWW Adj acency  To a computer scientist, the WWW looks much like the directed graphs (digraph) we have studied in data structure classes for decades. It's big, it's dynamic, we have special questions about it, etc., but many of the same analyses we would apply to any digraph are good starting points for the WWW. A useful first step is to define the adjacency matrix A connecting all the documents dj of the WWW:  Ajj = 1    if 4 cites dj                              (6.1)  Ai} = 0     otherwise                                (6.2) 196      FINDING OUT ABOUT  For example, the Google search engine5 imagines the WWW graph as the basis of a Markov process, where the probability of jumping from one page is uniform across all of its anchor/citations.  If e is defined to be this (small) probability, the stationary distribution of this Markov process provides some insight into how likely a browsing user would be to find him or herself on a particular page. NEC's CiteSeer6 is another example of how useful citation information can be as part of a tool for searching computer science literature.  A more extensive analysis [Chakrabarti et al., 1998b; Kleinberg, 1998] has analyzed the WWW, looking especially for methods that extract authoritative pages from the vast numbers of other pages the WWW also contains. The first component of this method corresponds approximately to the notion of impact discussed in Section 6.1.1.  ... the fundamental difficulty lies in what could be called the Abundance Problem: The number of pages that could reasonably be returned as "relevant" is far too large for a human user to digest. Thus, to provide effective methods for automated search under these constraints, one does not necessarily need stronger versions of classical information retrieval notions such as relevance; rather one needs a method of providing a user, from a large set of relevant pages, a small collection of the most "authoritative" or "definitive" ones___  Unfortunately, "authority" is perhaps an even more nebulous concept than "relevance," again highly subject to human judgment___  We claim that an environment such as the WWW is explicitly annotated with precisely the type of human judgment that we need in order to formulate a notion of authority. Specifically, the creation of a link in the WWW represents a concrete indication of the following type of judgment: the creator of page p, by including a link to page q, has in some measure conferred authority on q. [Chakrabarti et al., 1998b, p. 2]  Second, they define hub documents to be ones that are particularly exhaustive in their reference to other pages. This is roughly analogous to review papers also mentioned in Section 6.1.1. To a first approximation,  * www.google.com/ h clteseer.na.nec.com/cs INFERENCE BEYOND THE INDEX      197  authoritative pages are those with high in-degree while hubs are those with high out-degree. But Kleinberg imposes an important additional constraint: A community of hubs and authority pages must be mutually self-referential. The thinking underlying Kleinberg's method is provocative:  Authoritative pages relevant to the initial query should not only have large in-degree; since they are all authorities on a common topic, there should also be considerable overlap in the sets of pages that point to them. Thus, in addition to highly authoritative pages, we expect to find what could be called hub pages: these are pages that have links to multiple relevant authoritative pages. It is these hub pages that "pull together" authorities on a common topic, and allow us to throw out unrelated pages of large in-degree. Hubs and authorities exhibit what could be called a mutually reinforcing relationship: a good hub is a page that points to many good authorities; a good authority is a page that is pointed to by many good hubs. [Kleinberg, 1998, p. 4]  Two quantities, x and y, are associated with each document, corresponding to how good an authority or hub, respectively, the document is, based on the adjacency matrix A:  Xi = Authority(ij)                                (6.3)  y{ = Hubness(df)                                 (6.4)  x= {xi)                                           (6.5)  Y = (Yi)                                              (6.6)  x and y values are iteratively updated by premultiplication with the adjacency matrix or its transpose:  xt+i = A y                             (67)  jt+l = Axf                                      (6.8)  It is also important to renormalize these vectors to unit length after each update.  Under reasonable assumptions* this update procedure is guaranteed to converge on values with x* being the principal eigenvector of ATA 198      FINDING OUT ABOUT  FIGURE 6.5 Citation-Expanded Hitlist  and y* the principal eigenvector of A AT:  x* =codATA)                                   (6.9)  y* = coi(AAT)                                (6.10)  Using this notation, the similarity of documents dx and dj can be conveniently measured in terms of cocitation as the (z, j) entry of A A T*  While we can conceive of applying these techniques to the graph corresponding to the entire WWW, the computational time and space required still makes such an analysis intractable. Kleinberg et al. typically recommend applying this adjacency analysis to a subset of pages pulled together by a query against some search engine. In their experiments, they augment this initial hitlist with documents that either point to or are pointed to from documents in the hitlist itself, as shown in Figure 6.5.  Note that the values for authority and hub on which this analysis converges correspond to the first, primary eigenvector. Using these values to identify high hub and anchor nodes gives rise to the first, primary community of documents in the graph. Another interesting application of adjacency analysis is to consider communities other than the one corresponding to the first, largest eigenvalue. A particularly striking application of this analysis concerns bimodal queries: Consider results arising from a query ABORTION, shown in Table 6.3. After first identifying  * Kleinberg also notes that the complementary measure ATA corresponds to the earlier, bibllornetric construct of bibliographic coupling [Kessler, 1963]. INFERENCE BEYOND THE INDEX      199  TABLE 6.3 Authority Nodes Elicited by ABORTION Query, Associated with Second Eigenvector  x2                                                URL                                                                    Title  .321     wwiw.caral.org/abortion.html                                               Abortion and Reproductive  Rights Internet Resources  .219     www.plannedparenthood.org/                                              Welcome to Planned Parenthood  .195     www.gynpages.com/                                                            Abortion Clinics Online  .172     www.oneworld.org/ippf/                                                      IPPF Home Page  .162     www.prochoice.org/naf/                                                       The National Abortion Federation  .161     www. lm. com/Imann/femirnst/abortion. html  -.197     www.awinc.com/partners/bc/commpass/lifenet/                Life WEB  lifenet.htm  - .169     www.worldvillage.com/wv/square/chapel/xwalk/html/      Healing after Abortion  peter.htm  - ,164     www.nebula.net/maeve/hfelink.html  - .150     members.aol.com/pladvocate/  -. 144     www.clark.net/pub/jeffd/factbot.html                                 The Right Side of the Web  - .144     www.catholic.net/H3rperUews/get/abortion.html  a community of pages extensively citing both pro-choice and pro-life documents, the second eigenvector 002 clearly separates pages associated with pro-choice organizations (with relatively high positive values) and pro-life (with negative values).*  Another important feature of this analysis is that it depends on only first-order adjacency information. That is, while it is always easy to find all of the documents pointed to by a target document simply by inspecting the document for its anchors, the in-neighborhood of a document can be identified through direct inspection of other documents. This means, for example, that search engine crawlers that look at every single document can, as part of their normal search, simultaneously collect this adjacency data.   