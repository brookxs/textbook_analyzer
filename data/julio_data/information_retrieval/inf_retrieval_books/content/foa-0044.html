 3.3.1 Lexical Consequences, Internal/External Perspectives  The plot in Figure 3.2 is based on word-frequency statistics like those  shown in Table 3.2. Note that on the log-log plot in Figure 3.2, frequency  is a nearly linear inverse function of rank.  One way to make the various lexical decisions considered in the last chapter is to consider the effects of various decisions in terms of statistics such as these. Table 3.3 shows the statistics for stemmed, nonnoise 72       FINDING OUT ABOUT  TABLE 3.2 AIT Keywords Frequency/Rank Distribution.  Rank Frequency Keyword Rank Frequency Keyword  1 25,438 system 20 4836 algorithm  2 24,745 univers 100 1646 dissert  3 12,107 base 200 971 util  4 11,938 network 300 767 Zurich  5 11,930 model 400 624 genet  6 10,303 de 500 474 event  7 8568 knowledg 600 363 definit  8 8320 neural 700 289 underli  9 7465 process 800 234 explicit  10 7293 design 900 196 teach  11 6758 control 1000 171 lisp  12 6308 intellig 1500 89 advis  13 6308 develop 2000 51 compound  14 6243 use 2500 33 praisal  15 6074 learn 3000 24 af  16 5837 applic 4000 13 meshe  17 5617 expert 5000 8 hermeneut  18 5558 approach 6000 4 html  19 5464 comput 6660 3 replai  word tokens (shown in monospaced font, e.g., SYSTEM), together with noise words (shown in italics, e.g., the). As expected, the noise words occur very frequently. But it is interesting to contrast those very frequent words defined a priori in the negative dictionary with those that occur especially frequently in this particular corpus. In many ways these are excellent candidates for external keywords: characterizations of this corpus's content, from the "external" perspective of general language use. That is, these are exactly the words (cf. NEURAL NETWORK, BASE, LEARN, WORLD, KNOWLEDGE) that could suggest to a WWW browser that the AIT corpus might be worth visiting. Once "inside" the topical domain of AI, however, these same words (cf. SYSTEM, MODEL, PROCESS, DESIGN) become as ineffective as other noise words, as internal keywords, discriminating the contents of one AIT dissertation from the next.  Table 33 also shows statistics both with and without stemming. For example, the token SYSTEM itself appeared only 8632 times; variations like SYSTEMS and SYSTEMATIC must account for the other 12,856. This simple example also demonstrates how issues of phrase recognition WEIGHTING AND MATCHING AGAINST INDICES       73   TABLE 3.3 Consequences of Lexical Decisions on Word Frequencies    Unstemrned   Unstemmed  Token Frequency Frequency Token Frequency Frequency  the 78,428  that 9820   of 50,026  are 9792   and 33,834  LEABN 9293   a 31,347  WORLD 8103   to 28,666  la? 7678   in 21,512  an 7593   SYSTEM 21,488 8,632 KNOWLEDG 7410 5,496  is 18,781  HETOBAL 7220 3,912  MODEL 14,772 4,796 with 7197   for 14,640  as 6964   de? 11,923  on 6920   NETWORK           10,306 3,965 by 6886   this 10,095  PROCESS 6569 2,900  BASE 9838  DESIGN 6362 3,308  (cf. NEURAL NETWORK) and other messy issues (e.g., the presence of French noise words in some of the dissertation abstracts but not in our English negative dictionary) can arise in even the simplest, "cleanest" corpora.   