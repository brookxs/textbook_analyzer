 3.8 Summary  We've covered enormous ground in this chapter. We began by wondering just what it might mean to try to understand communicative acts, like the publication of a document or the posing of a question or query. We looked in some detail at one of the most fundamental characteristics of texts, Zipf's law, and found it to be, in fact, quite meaningless! But the next level of features, tokens like those produced by the machinery of Chapter 2, supported a rich analysis of the index, as a balance between the vocabularies of the documents' authors and searchers' subsequent queries. The vector space provides a concrete model of potential keyword vocabularies and what it might mean to match within this space. Finally, we considered an efficient implementation of nearly complete matching. In the next chapter we will consider the problem of evaluating how well all these techniques work in practice.  However, there are gaps in this story that are so obvious we don't even need to measure them. Some of the gaps involve implementation issues that can be critical, especially when faced with very large corpora [Harper and Walker, 1992]. Parallel implementation techniques, for example, those pioneered on "massively parallel'* SIMD (single instruction/multiple data) Connection Machines, become important in this respect [Salton and Buckley, 1988c; Stanfill and Kahle, 1986a; Stone, 1987]. In the modern age of multiple search engines each indexing (only partially overlapping versions [Lawrence and Giles, 1998]) of the WWW techniques for fusing multiple hitlists into a single list for the same user suggests another level of parallelism in the FOA task [Voorhees et al., 1995]. 102      FINDING OUT ABOUT  However, linguists, in particular, must have more serious, implementation-independent concerns. Imagine that you are someone who has studied the range of human languages and who appreciates both their wide variety and equally remarkable commonalities. You would be appalled at the violence we have done to the syntactic structure of language. For linguists, Finding Out About documents by counting their words must seem like trying to understand Beijing by listening to a single microphone poised high over the city: You can pick up on a few basic trends (like when most people are awake), but most of the texture is missing!  DOG BITES MAN and MAM BITES DOG clearly mean two different things. Word order obviously conveys meaning beyond that brought by the three words. And the problem doesn't end with word order. Look how different the meaning of these phrases are:  ï NEUTRALIZATION" OF THE PRESENT  ï REPRESENTING NEUTRONS  ï REPRESENTATIONS, NOT NEUTRONS  despite the fact that all of them (conceivably) reduce to the same set of indexable tokens! Note especially how critical the same "noise" words thrown away on statistical grounds (in Chapter 2) are when analyzing a sentence's syntactic structure.  The attempt to understand the phenomena of meaning by looking for patterns in word frequency statistics alone is reminiscent of the tea leaves and entrails of this chapter's opening quote. Still, the success of many WWW search engines that use very little beyond this kind of gross analysis suggests that there is much more information in the statistics than traditional, syntactically focused linguists might have believed.   