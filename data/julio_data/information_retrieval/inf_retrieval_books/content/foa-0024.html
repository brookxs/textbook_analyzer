 2.2 Interdocument Parsing  The first step is to break the corpus - an arbitrary "pile of text" - into individually retrievable documents. This demands that we be specific about the format of the corpus and that we decide how it is to be divided into individual documents. For all operating systems we will consider, this problem can be defined more precisely in terms of paths, directories, files, and positions within files. For any application in which the corpus can be described by the path to its root, these tools will translate directories, files, and documents-within-files into a homogeneous corpus. Of course, there are some situations (e.g., when documents are maintained within a database) that cannot be captured in these terms, but these primitives do allow a wide range of corpora to be specified.  Our model will assume that many documents may be contained within a single file and that each document occupies a contiguous region within the file. EXTRACTING LEXICAL FEATURES       41  Issues concerning structure within a single document are closely related to assumptions we may or may not be able to make about the length of the documents in question. Our assumptions about how long a typical document is will recur throughout this book. It is obvious, for example, that different document browsers are necessary if we need to browse through an entire book rather than look at a single paragraph. Less obvious is that the fundamental weighting algorithms used by our indexing techniques will depend very sensitively on the number of tokens contained in each document.  In this textbook we will focus primarily on two particular test corpora, AI theses (AIT) and email; these are discussed in more detail in Section 2.4. Each of these has natural notions of the individual document: In the case of the AIT it is the thesis's abstract, and for email it is the entire message. In both cases, more refined notions of document (the individual paragraphs within the abstract or within the email message) are possible.  With these assumptions, we can define our corpus simply with two files: one specifying full path information for each file, and a second specifying where within these files each message resides. A large portion of the task of navigating a directory full of files and visiting each of them can be accomplished using the dirent.^ This utility allows the recursive descent through all directories from a specified root, visiting every file contained therein.  In many cases, the files we will be indexing have a great deal of syntactic structural information above and beyond the meaningful text itself. For example, our email will often contain a great deal of mail header information, as (loosely.) specified in RFC822J Many text-formatting languages, for example, TjX, XML, and HTML, now produce documents with a well-defined syntax. If, for example, the documents are written in HTML, we don't want to index pseudo-words like lt;H1gt;. In many of these situations, filters exist that can extract just the meaningful text from surrounding header or format information; DeTeX1 is an example of a useful filter for removing EJTeX andT^X markup. Use of such utilities spares us the task of parsing this elaborate structure, but it also means that more elaborate solutions for maintaining the difference between the document's index and the document's presentation must be addressed.  What is dirent?  What is RFC8S2?  1 www. cs.purdue.edu/trinkle/detex/lndex.html 42       FINDING OUT ABOUT  Advisor Committee University Department  Proxy text  This is a sample of some text.  It might be from an email message, a dissertation, or anything else.  We simply assume it is a string of characters about a paragraph in length.  FIGURE 2.1 Parsing Email and AIT to Common Specifications  The basic data elements to be parsed from our two examples, email and AIT, are shown in Figure 2.1.   