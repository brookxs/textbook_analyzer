 7.3.1 Widrow-Hoff  The Widrow-Hoff (a.k.a. least mean squared (LMS)) algorithm is the  best-understood and principled approach to training a linear system to minimize this squared error loss [Widrow and Hoff, I960]. It does this  by making a small move (scaled by the parameter 77) in the direction of the gradient of error. This gradient is defined exactly by the derivative of Equation 7.5 with respect to the document vector:  (7.6) 266      FINDING OUT ABOUT  It is also important to remember that changes made to a single document in response to a single query can make no guarantees about improved performance with respect to other documents and other queries. For example, two documents might both be moved closer to a query (as proposed by Brauen and Rocchio) but their relative rankings may not change at all!   