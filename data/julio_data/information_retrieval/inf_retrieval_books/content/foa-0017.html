 1.5.1 Automatically Selecting Keywords  We begin by considering the document at its most mechanical level, as a string of characters. Our first candidates for keywords will be tokens, things broken by white space. That is, each token in the document could be considered one of its keywords.  How good is this simple solution? Suppose users ask for documents about CARS and the document we are currently indexing has the string CAR. It seems reasonable to assume that users are interested in this document, despite the fact that the query happens to contain the plural form CARS while the document contains the singular CAR. For many queries we might like to consider occurrences of the words CAR and CARS, or even RETRIEVAL and RETRIEVE, as roughly interchangeable with one another; the suffixes do not affect meaning dramatically. And of course our problem doesn't end with plurals; we could make similar arguments concerning past-tense -ED endings and -ING participles.  This simple solution also depends too much on where spaces occur. Consider the German noun GESCHWIIsroiGKEITSBESCRAJSIiaiMG, corresponding to the English phrase SPEED LIMIT. In many ways, the fact that English happens to put a white space between the words while German does not is not semantically critical to the meaning of these descriptors or the documents in which they might occur. Such morphological features - used to mark relatively superficial, surfacestructure features (such as tense or singular versus plural) - can be considered less important to the meaning. And differences between German and English are trivial when they are compared to Asian texts, where the relationship between characters and words is radically different.  What about hyphenation? Use of the word DATABASE, the phrase DATA BASE, and the hyphenated phrase DATA-BASE is highly variable, depending on author preference and current practice at the time and place of publication. Yet we would hope that all occurrences of any of these tokens would be treated as references to approximately the same semantic category. Similarly, we hope that the end-of-line hyphenation 28       FINDING OUT ABOUT  (breaking long words at syllable boundaries) would not create two keywords when we would expect only one. But simply adding "-" to the set of white space characters defining tokens would make CLINTON-DOLE and A-Z keywords, too!  Hyphenation is concerned with the situation in which a potential keyword is broken up by punctuation; what about those situations where a space also breaks up a semantic unit? SPEED LIMIT seems semantically cohesive, but what algorithm could distinguish it from other bigrams (consecutive pairs of words) that happen to occur sequentially? The problem only becomes that much more complicated if we attempt to consider longer noun phrases like APPLES AND ORANGES or BACK PROPAGATION NEURAL NETWORK, let alone more complicated syntactic compounds such as verb phrases, clauses, or sentences. Identifying phrases is an important and active area of research from the perspectives of both IR and computational linguistics.  Summarizing, we will take a token to be our default keyword because this is straightforward. More sophisticated solutions will handle hyphenation, multiword phrases, subtoken stems, and so on (cf. Section 2.3.1).   