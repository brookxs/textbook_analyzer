<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Exercises</title> 
  <meta name="description" content="Exercises" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="previous" href="references-and-further-reading-14.html" /> 
  <link rel="up" href="vector-space-classification-1.html" /> 
  <link rel="next" href="support-vector-machines-and-machine-learning-on-documents-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html3798" href="support-vector-machines-and-machine-learning-on-documents-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html3792" href="vector-space-classification-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html3788" href="references-and-further-reading-14.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html3794" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html3796" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html3799" href="support-vector-machines-and-machine-learning-on-documents-1.html">Support vector machines and</a> 
  <b> Up:</b> 
  <a name="tex2html3793" href="vector-space-classification-1.html">Vector space classification</a> 
  <b> Previous:</b> 
  <a name="tex2html3789" href="references-and-further-reading-14.html">References and further reading</a> &nbsp; 
  <b> <a name="tex2html3795" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html3797" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h1><a name="SECTION001980000000000000000"> Exercises</a> </h1> 
  <p> </p> 
  <div align="CENTER"> 
   <p><a name="fig:diffsimilarities"></a><a name="p:diffsimilarities"></a></p> 
   <img width="556" height="245" border="0" src="img1247.png" alt="\begin{figure}
% latex2html id marker 20737
\psset{unit=0.4cm}
\begin{pspicture}...
...2 \ \ 2)^T$, $\vec{b} = (4 \ \ 4)^T$, and $\vec{c} = (8
\ \ 6)^T$.}
\end{figure}" /> 
  </div> 
  <p> <b>Exercises.</b> </p> 
  <ul> 
   <li><a name="ex:diffsimex"></a> <a name="p:diffsimex"></a> In Figure <a href="#fig:diffsimilarities">14.13</a> , which of the three vectors <img width="11" height="32" align="MIDDLE" border="0" src="img1248.png" alt="$\vec{a}$" />, <img width="12" height="41" align="MIDDLE" border="0" src="img1249.png" alt="$\vec{b}$" />, and <img width="11" height="32" align="MIDDLE" border="0" src="img1250.png" alt="$\vec{c}$" /> is (i) most similar to <img width="13" height="32" align="MIDDLE" border="0" src="img701.png" alt="$\vec{x}$" /> according to dot product similarity, (ii) most similar to <img width="13" height="32" align="MIDDLE" border="0" src="img701.png" alt="$\vec{x}$" /> according to cosine similarity, (iii) closest to <img width="13" height="32" align="MIDDLE" border="0" src="img701.png" alt="$\vec{x}$" /> according to Euclidean distance? <p> </p></li> 
   <li><a name="ex:reutersvcat"></a> <a name="p:reutersvcat"></a> Download Reuters-21578 and train and test Rocchio and kNN classifiers for the classes acquisitions, corn, crude, earn, grain, interest, money-fx, ship, trade, and wheat. Use the ModApte split. You may want to use one of a number of software packages that implement Rocchio classification and kNN classification, for example, the Bow toolkit (<a href="bibliography-1.html#mccallum96bow">McCallum, 1996</a>). <p> </p></li> 
   <li>Download 20 Newgroups (page <a href="standard-test-collections-1.html#p:20newsgroups">8.2</a> ) and train and test Rocchio and kNN classifiers for its 20 classes. <p> </p></li> 
   <li>Show that the decision boundaries in Rocchio classification are, as in kNN, given by the Voronoi tessellation. <p> </p></li> 
   <li><a name="ex:cheapeuclidean"></a> Computing the distance between a dense centroid and a sparse vector is <img width="47" height="33" align="MIDDLE" border="0" src="img1251.png" alt="$\Theta(M)$" /> for a naive implementation that iterates over all <img width="20" height="32" align="MIDDLE" border="0" src="img186.png" alt="$M$" /> dimensions. Based on the equality 
    <!-- MATH
 $\sum (x_i-\mu_i)^2 = 1.0+\sum \mu_i^2 - 2\sum x_i \mu_i$
 --> <img width="249" height="36" align="MIDDLE" border="0" src="img1252.png" alt="$\sum (x_i-\mu_i)^2 = 1.0+\sum \mu_i^2 - 2\sum x_i \mu_i$" /> and assuming that <img width="36" height="36" align="MIDDLE" border="0" src="img1253.png" alt="$\sum \mu_i^2$" /> has been precomputed, write down an algorithm that is 
    <!-- MATH
 $\Theta( M_{a})$
 --> <img width="53" height="33" align="MIDDLE" border="0" src="img1254.png" alt="$\Theta( M_{a})$" /> instead, where <img width="27" height="32" align="MIDDLE" border="0" src="img919.png" alt="$ M_{a}$" /> is the number of distinct terms in the test document. <p> </p></li> 
   <li><a name="ex:tessellatelargek"></a>Prove that the region of the plane consisting of all points with the same <img width="11" height="31" align="MIDDLE" border="0" src="img20.png" alt="$k$" /> nearest neighbors is a convex polygon. <p> </p></li> 
   <li><a name="ex:knndim2dim3"></a> <a name="p:knndim2dim3"></a> Design an algorithm that performs an efficient 1NN search in 1 dimension (where efficiency is with respect to the number of documents <img width="17" height="32" align="MIDDLE" border="0" src="img62.png" alt="$N$" />). What is the time complexity of the algorithm? <p> </p></li> 
   <li><a name="ex:knndim2"></a>Design an algorithm that performs an efficient 1NN search in 2 dimensions with at most polynomial (in <img width="17" height="32" align="MIDDLE" border="0" src="img62.png" alt="$N$" />) preprocessing time. <p> </p></li> 
   <li><a name="ex:knndimtmplabel"></a> Can one design an exact efficient algorithm for 1NN for very large <img width="20" height="32" align="MIDDLE" border="0" src="img186.png" alt="$M$" /> along the ideas you used to solve the last exercise? <p> </p></li> 
   <li><a name="ex:exrocchiolinear"></a> <a name="p:exrocchiolinear"></a> Show that Equation&nbsp;<a href="linear-versus-nonlinear-classifiers-1.html#rocchiolinear">145</a> defines a hyperplane with 
    <!-- MATH
 $\vec{w}=
\vec{\mu}(c_1)-\vec{\mu}(c_2)$
 --> <img width="132" height="33" align="MIDDLE" border="0" src="img1171.png" alt="$\vec{w}=
\vec{\mu}(c_1)-\vec{\mu}(c_2)$" /> and 
    <!-- MATH
 $b=0.5*(|\vec{\mu}(c_1)
|^2-|\vec{\mu}(c_2) |^2)$
 --> <img width="209" height="36" align="MIDDLE" border="0" src="img1172.png" alt="$b=0.5*(\vert\vec{\mu}(c_1)
\vert^2-\vert\vec{\mu}(c_2) \vert^2)$" />. <p> </p> 
    <div align="CENTER"> 
     <a name="fig:simplenonsep"></a> 
     <a name="p:simplenonsep"></a> 
     <a name="20798"></a> 
     <table> 
      <caption align="BOTTOM"> 
       <strong>Figure 14.14:</strong> A simple non-separable set of points. 
      </caption> 
      <tbody> 
       <tr> 
        <td></td> 
       </tr> 
      </tbody> 
     </table> 
    </div> <p> </p></li> 
   <li>We can easily construct non-separable data sets in high dimensions by embedding a non-separable set like the one shown in Figure <a href="#fig:simplenonsep">14.14</a> . Consider embedding Figure <a href="#fig:simplenonsep">14.14</a> in 3D and then perturbing the 4 points slightly (i.e., moving them a small distance in a random direction). Why would you expect the resulting configuration to be linearly separable? How likely is then a non-separable set of <img width="58" height="32" align="MIDDLE" border="0" src="img1256.png" alt="$m \ll M$" /> points in <img width="20" height="32" align="MIDDLE" border="0" src="img186.png" alt="$M$" />-dimensional space? <p> </p></li> 
   <li><a name="ex:separablehigh"></a> <a name="p:separablehigh"></a> Assuming two classes, show that the percentage of non-separable assignments of the vertices of a hypercube decreases with dimensionality <img width="20" height="32" align="MIDDLE" border="0" src="img186.png" alt="$M$" /> for <img width="50" height="32" align="MIDDLE" border="0" src="img1257.png" alt="$M&gt;1$" />. For example, for <img width="50" height="32" align="MIDDLE" border="0" src="img1258.png" alt="$M=1$" /> the proportion of non-separable assignments is 0, for <img width="50" height="32" align="MIDDLE" border="0" src="img1138.png" alt="$M=2$" />, it is <img width="38" height="31" align="MIDDLE" border="0" src="img1259.png" alt="$2/16$" />. One of the two non-separable cases for <img width="50" height="32" align="MIDDLE" border="0" src="img1138.png" alt="$M=2$" /> is shown in Figure <a href="#fig:simplenonsep">14.14</a> , the other is its mirror image. Solve the exercise either analytically or by simulation. <p> </p></li> 
   <li>Although we point out the similarities of Naive Bayes with linear vector space classifiers, it does not make sense to represent count vectors (the document representations in NB) in a continuous vector space. There is however a formalization of NB that is analogous to Rocchio. Show that NB assigns a document to the class (represented as a parameter vector) whose <a name="20807"></a>Kullback-Leibler (KL) divergence (Section <a href="extended-language-modeling-approaches-1.html#sec:extended-lm">12.4</a> , page <a href="extended-language-modeling-approaches-1.html#p:kullback">12.4</a> ) to the document (represented as a count vector as in Section&nbsp;<a href="a-variant-of-the-multinomial-model-1.html#sec:variantmultinomial">13.4.1</a> (page&nbsp;<a href="a-variant-of-the-multinomial-model-1.html#p:variantmultinomial"><img align="BOTTOM" border="1" alt="[*]" src="http://nlp.stanford.edu/IR-book/html/icons/crossref.png" /></a>), normalized to sum to 1) is smallest. <p> </p></li> 
  </ul> 
  <p> </p> 
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html3798" href="support-vector-machines-and-machine-learning-on-documents-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html3792" href="vector-space-classification-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html3788" href="references-and-further-reading-14.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html3794" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html3796" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html3799" href="support-vector-machines-and-machine-learning-on-documents-1.html">Support vector machines and</a> 
  <b> Up:</b> 
  <a name="tex2html3793" href="vector-space-classification-1.html">Vector space classification</a> 
  <b> Previous:</b> 
  <a name="tex2html3789" href="references-and-further-reading-14.html">References and further reading</a> &nbsp; 
  <b> <a name="tex2html3795" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html3797" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>  
 </body>
</html>