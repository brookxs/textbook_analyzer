<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Heaps' law: Estimating the number of terms</title> 
  <meta name="description" content="Heaps' law: Estimating the number of terms" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="next" href="zipfs-law-modeling-the-distribution-of-terms-1.html" /> 
  <link rel="previous" href="statistical-properties-of-terms-in-information-retrieval-1.html" /> 
  <link rel="up" href="statistical-properties-of-terms-in-information-retrieval-1.html" /> 
  <link rel="next" href="zipfs-law-modeling-the-distribution-of-terms-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html1695" href="zipfs-law-modeling-the-distribution-of-terms-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html1689" href="statistical-properties-of-terms-in-information-retrieval-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html1683" href="statistical-properties-of-terms-in-information-retrieval-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html1691" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html1693" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html1696" href="zipfs-law-modeling-the-distribution-of-terms-1.html">Zipf's law: Modeling the</a> 
  <b> Up:</b> 
  <a name="tex2html1690" href="statistical-properties-of-terms-in-information-retrieval-1.html">Statistical properties of terms</a> 
  <b> Previous:</b> 
  <a name="tex2html1684" href="statistical-properties-of-terms-in-information-retrieval-1.html">Statistical properties of terms</a> &nbsp; 
  <b> <a name="tex2html1692" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html1694" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h2><a name="SECTION001011000000000000000"> Heaps' law: Estimating the number of terms</a> </h2> 
  <p> </p> 
  <div align="CENTER"> 
   <p><a name="fig:heaps"></a><a name="p:heaps"></a></p> 
   <img width="403" height="370" align="BOTTOM" border="0" src="img236.png" alt="\includegraphics[width=9cm]{art/heapsmall.eps}" /> Heaps' law.Vocabulary size 
   <img width="20" height="32" align="MIDDLE" border="0" src="img186.png" alt="$M$" /> as a function of collection size 
   <img width="15" height="32" align="MIDDLE" border="0" src="img123.png" alt="$T$" /> (number of tokens) for Reuters-RCV1. For these data, the dashed line 
   <!-- MATH
 $\log_{10} M = 0.49*\log_{10} T + 1.64$
 --> 
   <img width="219" height="31" align="MIDDLE" border="0" src="img233.png" alt="$\log_{10} M = 0.49*\log_{10} T + 1.64$" /> is the best least-squares fit. Thus, 
   <!-- MATH
 $k = 10^{1.64} \approx 44$
 --> 
   <img width="109" height="38" align="MIDDLE" border="0" src="img234.png" alt="$k = 10^{1.64} \approx 44$" /> and 
   <img width="62" height="31" align="MIDDLE" border="0" src="img235.png" alt="$b= 0.49$" />. 
  </div> 
  <p> A better way of getting a handle on <img width="20" height="32" align="MIDDLE" border="0" src="img186.png" alt="$M$" /> is <a name="5939"></a> <i>Heaps' law</i> , which estimates vocabulary size as a function of collection size: <br /> </p> 
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
M = k T^b
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody> 
     <tr valign="MIDDLE"> 
      <td align="CENTER" nowrap=""><img width="62" height="24" border="0" src="img237.png" alt="\begin{displaymath}
M = k T^b
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (1)</td> 
     </tr> 
    </tbody> 
   </table> 
   <br clear="ALL" /> 
  </div> 
  <p></p> where 
  <img width="15" height="32" align="MIDDLE" border="0" src="img123.png" alt="$T$" /> is the number of tokens in the collection. Typical values for the parameters 
  <img width="11" height="31" align="MIDDLE" border="0" src="img20.png" alt="$k$" /> and 
  <img width="12" height="31" align="MIDDLE" border="0" src="img137.png" alt="$b$" /> are: 
  <!-- MATH
 $30 \leq k \leq 100$
 --> 
  <img width="95" height="31" align="MIDDLE" border="0" src="img238.png" alt="$30 \leq k \leq 100$" /> and 
  <img width="54" height="31" align="MIDDLE" border="0" src="img239.png" alt="$b
\approx 0.5$" />. The motivation for Heaps' law is that the simplest possible relationship between collection size and vocabulary size is linear in log-log space and the assumption of linearity is usually born out in practice as shown in Figure 
  <a href="#fig:heaps">5.1</a> for Reuters-RCV1. In this case, the fit is excellent for 
  <!-- MATH
 $T>10^5=100{,}000$
 --> 
  <img width="133" height="36" align="MIDDLE" border="0" src="img240.png" alt="$T&gt;10^5=100{,}000$" />, for the parameter values 
  <img width="62" height="31" align="MIDDLE" border="0" src="img235.png" alt="$b= 0.49$" /> and 
  <img width="50" height="31" align="MIDDLE" border="0" src="img241.png" alt="$k=44$" />. For example, for the first 1,000,020 tokens Heaps' law predicts 38,323 terms: 
  <br /> 
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
44 \times 1{,}000{,}020^{0.49} \approx 38{,}323.
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody> 
     <tr valign="MIDDLE"> 
      <td align="CENTER" nowrap=""><img width="191" height="26" border="0" src="img242.png" alt="\begin{displaymath}
44 \times 1{,}000{,}020^{0.49} \approx 38{,}323.
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (2)</td> 
     </tr> 
    </tbody> 
   </table> 
   <br clear="ALL" /> 
  </div> 
  <p></p> The actual number is 38,365 terms, very close to the prediction. 
  <p> The parameter <img width="11" height="31" align="MIDDLE" border="0" src="img20.png" alt="$k$" /> is quite variable because vocabulary growth depends a lot on the nature of the collection and how it is processed. Case-folding and stemming reduce the growth rate of the vocabulary, whereas including numbers and spelling errors increase it. Regardless of the values of the parameters for a particular collection, Heaps' law suggests that (i)&nbsp;the dictionary size continues to increase with more documents in the collection, rather than a maximum vocabulary size being reached, and (ii)&nbsp;the size of the dictionary is quite large for large collections. These two hypotheses have been empirically shown to be true of large text collections (Section <a href="references-and-further-reading-5.html#sec:icompresssecfurther">5.4</a> ). So dictionary compression is important for an effective information retrieval system. </p> 
  <p> <a name="5952"></a> <a name="5953"></a> </p> 
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html1695" href="zipfs-law-modeling-the-distribution-of-terms-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html1689" href="statistical-properties-of-terms-in-information-retrieval-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html1683" href="statistical-properties-of-terms-in-information-retrieval-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html1691" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html1693" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html1696" href="zipfs-law-modeling-the-distribution-of-terms-1.html">Zipf's law: Modeling the</a> 
  <b> Up:</b> 
  <a name="tex2html1690" href="statistical-properties-of-terms-in-information-retrieval-1.html">Statistical properties of terms</a> 
  <b> Previous:</b> 
  <a name="tex2html1684" href="statistical-properties-of-terms-in-information-retrieval-1.html">Statistical properties of terms</a> &nbsp; 
  <b> <a name="tex2html1692" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html1694" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>  
 </body>
</html>