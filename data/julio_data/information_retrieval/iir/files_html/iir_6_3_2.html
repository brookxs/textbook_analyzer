<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Queries as vectors</title> 
  <meta name="description" content="Queries as vectors" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="next" href="computing-vector-scores-1.html" /> 
  <link rel="previous" href="dot-products-1.html" /> 
  <link rel="up" href="the-vector-space-model-for-scoring-1.html" /> 
  <link rel="next" href="computing-vector-scores-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html1980" href="computing-vector-scores-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html1974" href="the-vector-space-model-for-scoring-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html1968" href="dot-products-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html1976" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html1978" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html1981" href="computing-vector-scores-1.html">Computing vector scores</a> 
  <b> Up:</b> 
  <a name="tex2html1975" href="the-vector-space-model-for-scoring-1.html">The vector space model</a> 
  <b> Previous:</b> 
  <a name="tex2html1969" href="dot-products-1.html">Dot products</a> &nbsp; 
  <b> <a name="tex2html1977" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html1979" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h2><a name="SECTION001132000000000000000"></a> <a name="sec:queryvector"></a> <a name="p:queryvector"></a> <br /> Queries as vectors </h2> 
  <p> There is a far more compelling reason to represent documents as vectors: we can also view a <em>query</em> as a vector. Consider the query <img width="29" height="32" align="MIDDLE" border="0" src="img170.png" alt="$q=$" /> jealous gossip. This query turns into the unit vector 
   <!-- MATH
 $\vec{v}(q)=(0,0.707,0.707)$
 --> <img width="162" height="33" align="MIDDLE" border="0" src="img434.png" alt="$\vec{v}(q)=(0,0.707,0.707)$" /> on the three coordinates of Figures&nbsp;<a href="dot-products-1.html#tab:3termfreqs">6.12</a> and <a href="dot-products-1.html#tab:3tfidfs">6.13</a>. The key idea now: to assign to each document <img width="12" height="31" align="MIDDLE" border="0" src="img354.png" alt="$d$" /> a score equal to the dot product <br /> </p> 
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
\vec{v}(q)\cdot\vec{v}(d).
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody> 
     <tr valign="MIDDLE"> 
      <td align="CENTER" nowrap=""><img width="74" height="28" border="0" src="img435.png" alt="\begin{displaymath}\vec{v}(q)\cdot\vec{v}(d).\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (26)</td> 
     </tr> 
    </tbody> 
   </table> 
   <br clear="ALL" /> 
  </div> 
  <p></p> 
  <p> In the example of Figure&nbsp;<a href="dot-products-1.html#tab:3tfidfs">6.13</a>, <em>Wuthering Heights</em> is the top-scoring document for this query with a score of 0.509, with <em>Pride and Prejudice</em> a distant second with a score of 0.085, and <em>Sense and Sensibility</em> last with a score of 0.074. This simple example is somewhat misleading: the number of dimensions in practice will be far larger than three: it will equal the vocabulary size <img width="20" height="32" align="MIDDLE" border="0" src="img186.png" alt="$M$" />. </p> 
  <p> To summarize, by viewing a query as a ``bag of words'', we are able to treat it as a very short document. As a consequence, we can use the cosine similarity between the query vector and a document vector as a measure of the score of the document for that query. The resulting scores can then be used to select the top-scoring documents for a query. Thus we have <br /> </p> 
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
\mbox{score}(q,d)= \frac{\vec{V}(q)\cdot \vec{V}(d)}{|\vec{V}(q)| |\vec{V}(d)|}.
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody> 
     <tr valign="MIDDLE"> 
      <td align="CENTER" nowrap=""><a name="eqn:cosinescore"></a><img width="190" height="50" border="0" src="img436.png" alt="\begin{displaymath}
\mbox{score}(q,d)= \frac{\vec{V}(q)\cdot \vec{V}(d)}{\vert\vec{V}(q)\vert \vert\vec{V}(d)\vert}.
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (27)</td> 
     </tr> 
    </tbody> 
   </table> 
   <br clear="ALL" /> 
  </div> 
  <p></p> A document may have a high cosine score for a query even if it does not contain all query terms. Note that the preceding discussion does not hinge on any specific weighting of terms in the document vector, although for the present we may think of them as either tf or tf-idf weights. In fact, a number of weighting schemes are possible for query as well as document vectors, as illustrated in Example&nbsp; 
  <a href="#workedeg:weightings">6.3.2</a> and developed further in Section 
  <a href="variant-tf-idf-functions-1.html#sec:variantsintfidf">6.4</a> . 
  <p> Computing the cosine similarities between the query vector and each document vector in the collection, sorting the resulting scores and selecting the top <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" /> documents can be expensive -- a single similarity computation can entail a dot product in tens of thousands of dimensions, demanding tens of thousands of arithmetic operations. In Section <a href="efficient-scoring-and-ranking-1.html#sec:heuristics">7.1</a> we study how to use an inverted index for this purpose, followed by a series of heuristics for improving on this. </p> 
  <p> <b>Worked example.</b> <a name="workedeg:weightings"></a>We now consider the query best car insurance on a fictitious collection with 
   <!-- MATH
 $N=1{,}000{,}000$
 --> <img width="104" height="32" align="MIDDLE" border="0" src="img437.png" alt="$N=1{,}000{,}000$" /> documents where the document frequencies of auto, best, car and insurance are respectively 5000, 50000, 10000 and 1000. </p> 
  <p> </p> 
  <table cellpadding="3" border="1"> 
   <tbody> 
    <tr> 
     <td align="LEFT">term</td> 
     <td align="CENTER" colspan="4">query</td> 
     <td align="CENTER" colspan="3">document</td> 
     <td align="LEFT">product</td> 
    </tr> 
    <tr> 
     <td align="LEFT">&nbsp;</td> 
     <td align="RIGHT">tf</td> 
     <td align="RIGHT">df</td> 
     <td align="RIGHT">idf</td> 
     <td align="LEFT"> 
      <!-- MATH
 $\mbox{w}_{t,q}$
 --> <img width="31" height="32" align="MIDDLE" border="0" src="img438.png" alt="$\mbox{w}_{t,q}$" /></td> 
     <td align="RIGHT">tf</td> 
     <td align="LEFT">wf</td> 
     <td align="LEFT"> 
      <!-- MATH
 $\mbox{w}_{t,d}$
 --> <img width="32" height="32" align="MIDDLE" border="0" src="img439.png" alt="$\mbox{w}_{t,d}$" /></td> 
     <td align="LEFT">&nbsp;</td> 
    </tr> 
    <tr> 
     <td align="LEFT">auto</td> 
     <td align="RIGHT">0</td> 
     <td align="RIGHT">5000</td> 
     <td align="RIGHT">2.3</td> 
     <td align="LEFT">0</td> 
     <td align="RIGHT">1</td> 
     <td align="LEFT">1</td> 
     <td align="LEFT">0.41</td> 
     <td align="LEFT">0</td> 
    </tr> 
    <tr> 
     <td align="LEFT">best</td> 
     <td align="RIGHT">1</td> 
     <td align="RIGHT">50000</td> 
     <td align="RIGHT">1.3</td> 
     <td align="LEFT">1.3</td> 
     <td align="RIGHT">0</td> 
     <td align="LEFT">0</td> 
     <td align="LEFT">0</td> 
     <td align="LEFT">0</td> 
    </tr> 
    <tr> 
     <td align="LEFT">car</td> 
     <td align="RIGHT">1</td> 
     <td align="RIGHT">10000</td> 
     <td align="RIGHT">2.0</td> 
     <td align="LEFT">2.0</td> 
     <td align="RIGHT">1</td> 
     <td align="LEFT">1</td> 
     <td align="LEFT">0.41</td> 
     <td align="LEFT">0.82</td> 
    </tr> 
    <tr> 
     <td align="LEFT">insurance</td> 
     <td align="RIGHT">1</td> 
     <td align="RIGHT">1000</td> 
     <td align="RIGHT">3.0</td> 
     <td align="LEFT">3.0</td> 
     <td align="RIGHT">2</td> 
     <td align="LEFT">2</td> 
     <td align="LEFT">0.82</td> 
     <td align="LEFT">2.46</td> 
    </tr> 
   </tbody> 
  </table> 
  <p> In this example the weight of a term in the query is simply the idf (and zero for a term not in the query, such as auto); this is reflected in the column header 
   <!-- MATH
 $\mbox{w}_{t,q}$
 --> <img width="31" height="32" align="MIDDLE" border="0" src="img438.png" alt="$\mbox{w}_{t,q}$" /> (the entry for auto is zero because the query does not contain the termauto). For documents, we use tf weighting with no use of idf but with Euclidean normalization. The former is shown under the column headed wf, while the latter is shown under the column headed 
   <!-- MATH
 $\mbox{w}_{t,d}$
 --> <img width="32" height="32" align="MIDDLE" border="0" src="img439.png" alt="$\mbox{w}_{t,d}$" />. Invoking (<a href="tf-idf-weighting-1.html#eqn:docscore">23</a>) now gives a net score of 
   <!-- MATH
 $0+0+0.82+2.46 = 3.28$
 --> <img width="184" height="32" align="MIDDLE" border="0" src="img440.png" alt="$0+0+0.82+2.46 = 3.28$" />. <b>End worked example.</b> </p> 
  <p> </p> 
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html1980" href="computing-vector-scores-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html1974" href="the-vector-space-model-for-scoring-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html1968" href="dot-products-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html1976" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html1978" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html1981" href="computing-vector-scores-1.html">Computing vector scores</a> 
  <b> Up:</b> 
  <a name="tex2html1975" href="the-vector-space-model-for-scoring-1.html">The vector space model</a> 
  <b> Previous:</b> 
  <a name="tex2html1969" href="dot-products-1.html">Dot products</a> &nbsp; 
  <b> <a name="tex2html1977" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html1979" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>  
 </body>
</html>