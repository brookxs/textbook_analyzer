<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Exercises</title> 
  <meta name="description" content="Exercises" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="previous" href="references-and-further-reading-16.html" /> 
  <link rel="up" href="flat-clustering-1.html" /> 
  <link rel="next" href="hierarchical-clustering-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html4299" href="hierarchical-clustering-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html4293" href="flat-clustering-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html4289" href="references-and-further-reading-16.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html4295" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html4297" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html4300" href="hierarchical-clustering-1.html">Hierarchical clustering</a> 
  <b> Up:</b> 
  <a name="tex2html4294" href="flat-clustering-1.html">Flat clustering</a> 
  <b> Previous:</b> 
  <a name="tex2html4290" href="references-and-further-reading-16.html">References and further reading</a> &nbsp; 
  <b> <a name="tex2html4296" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html4298" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h1><a name="SECTION002170000000000000000"> Exercises</a> </h1> 
  <p> <b>Exercises.</b> </p> 
  <ul> 
   <li><a name="ex:miclustering"></a> <a name="p:miclustering"></a> Let <img width="17" height="32" align="MIDDLE" border="0" src="img1536.png" alt="$\Omega$" /> be a clustering that exactly reproduces a class structure <img width="16" height="32" align="MIDDLE" border="0" src="img969.png" alt="$\mathbb{C}$" /> and <img width="22" height="35" align="MIDDLE" border="0" src="img1537.png" alt="$\Omega'$" /> a clustering that further subdivides some clusters in <img width="17" height="32" align="MIDDLE" border="0" src="img1536.png" alt="$\Omega$" />. Show that 
    <!-- MATH
 $I(\Omega;\mathbb{C})=I(\Omega';\mathbb{C})$
 --> <img width="136" height="35" align="MIDDLE" border="0" src="img1538.png" alt="$I(\Omega;\mathbb{C})=I(\Omega';\mathbb{C})$" />. <p> </p></li> 
   <li><a name="ex:nmibound"></a> Show that 
    <!-- MATH
 $I(\Omega; \mathbb{C}) \leq [H(\Omega)+
H(\mathbb{C} )]/2$
 --> <img width="207" height="33" align="MIDDLE" border="0" src="img1539.png" alt="$I(\Omega; \mathbb{C}) \leq [H(\Omega)+
H(\mathbb{C} )]/2$" />. <p> </p></li> 
   <li>Mutual information is symmetric in the sense that its value does not change if the roles of clusters and classes are switched: 
    <!-- MATH
 $I(\Omega;\mathbb{C})
=
I(
\mathbb{C}
;
\Omega
)$
 --> <img width="131" height="33" align="MIDDLE" border="0" src="img1540.png" alt="$
I(\Omega;\mathbb{C})
=
I(
\mathbb{C}
;
\Omega
)
$" />. Which of the other three evaluation measures are symmetric in this sense? <p> </p></li> 
   <li>Compute RSS for the two clusterings in Figure <a href="k-means-1.html#fig:clustfg5">16.7</a> . <p> </p></li> 
   <li><a name="ex:emptyclusters"></a> <a name="p:emptyclusters"></a> (i) Give an example of a set of points and three initial centroids (which need not be members of the set of points) for which 3-means converges to a clustering with an empty cluster. (ii) Can a clustering with an empty cluster be the global optimum with respect to RSS? <p> </p></li> 
   <li>Download Reuters-21578. Discard documents that do not occur in one of the 10 classes acquisitions, corn, crude, earn, grain, interest, money-fx, ship, trade, and wheat. Discard documents that occur in two of these 10 classes. (i) Compute a <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means clustering of this subset into 10 clusters. There are a number of software packages that implement <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means, such as WEKA (<a href="bibliography-1.html#witten05data">Witten and Frank, 2005</a>) and R (<a href="bibliography-1.html#r05r">R Development Core Team, 2005</a>). (ii) Compute purity, normalized mutual information, <img width="19" height="32" align="MIDDLE" border="0" src="img522.png" alt="$F_1$" /> and RI for the clustering with respect to the 10 classes. (iii) Compile a confusion matrix (Table <a href="classification-with-more-than-two-classes-1.html#tab:confusion">14.5</a> , page <a href="classification-with-more-than-two-classes-1.html#p:confusion">14.5</a> ) for the 10 classes and 10 clusters. Identify classes that give rise to false positives and false negatives. <p> </p></li> 
   <li><a name="ex:rssmonotonic"></a> <a name="p:rssmonotonic"></a> Prove that 
    <!-- MATH
 $\mbox{RSS}_{min}(K)$
 --> <img width="77" height="33" align="MIDDLE" border="0" src="img1466.png" alt="$\mbox{RSS}_{min}(K)$" /> is monotonically decreasing in <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />. <p> </p></li> 
   <li>There is a soft version of <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means that computes the fractional membership of a document in a cluster as a monotonically decreasing function of the distance <img width="15" height="32" align="MIDDLE" border="0" src="img345.png" alt="$ \Delta $" /> from its centroid, e.g., as <img width="30" height="38" align="MIDDLE" border="0" src="img1541.png" alt="$e^{-\Delta}$" />. Modify reassignment and recomputation steps of hard <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means for this soft version. <p> </p></li> 
   <li>In the last iteration in Table <a href="model-based-clustering-1.html#tab:clusttb4">16.3</a> , document&nbsp;6 is in cluster&nbsp;2 even though it was the initial seed for cluster&nbsp;1. Why does the document change membership? <p> </p></li> 
   <li>The values of the parameters <img width="28" height="32" align="MIDDLE" border="0" src="img1497.png" alt="$q_{mk}$" /> in iteration 25 in Table <a href="model-based-clustering-1.html#tab:clusttb4">16.3</a> are rounded. What are the exact values that EM will converge to? <p> </p></li> 
   <li>Perform a <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means clustering for the documents in Table <a href="model-based-clustering-1.html#tab:clusttb4">16.3</a> . After how many iterations does <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means converge? Compare the result with the EM clustering in Table <a href="model-based-clustering-1.html#tab:clusttb4">16.3</a> and discuss the differences. <p> </p></li> 
   <li><a name="ex:emforgaussian"></a>Modify the expectation and maximization steps of EM for a Gaussian mixture. The maximization step computes the maximum likelihood parameter estimates <img width="19" height="32" align="MIDDLE" border="0" src="img1495.png" alt="$\alpha_k$" />, <img width="20" height="32" align="MIDDLE" border="0" src="img1442.png" alt="$\vec{\mu}_k$" />, and <img width="21" height="32" align="MIDDLE" border="0" src="img1542.png" alt="$\Sigma_k$" /> for each of the clusters. The expectation step computes for each vector a soft assignment to clusters (Gaussians) based on their current parameters. Write down the equations for Gaussian mixtures corresponding to and <a href="model-based-clustering-1.html#eqn:emexpectation">202</a> . <p> </p></li> 
   <li><a name="ex:kmeansgaussian"></a>Show that <img width="15" height="32" align="MIDDLE" border="0" src="img30.png" alt="$K$" />-means can be viewed as the limiting case of EM for Gaussian mixtures if variance is very small and all covariances are 0. <p> </p></li> 
   <li>The <a name="25210"></a> <i>within-point scatter</i> of a clustering is defined as 
    <!-- MATH
 $\sum_k \frac{1}{2} \sum_{\vec{x}_i \in \omega_k} \sum_{\vec{x}_j \in \omega_k}  |\vec{x}_i - \vec{x}_j|^2$
 --> <img width="201" height="39" align="MIDDLE" border="0" src="img1543.png" alt="$
\sum_k \frac{1}{2} \sum_{\vec{x}_i \in \omega_k} \sum_{\vec{x}_j \in \omega_k} \vert\vec{x}_i - \vec{x}_j\vert^2
$" />. Show that minimizing RSS and minimizing within-point scatter are equivalent. <p> </p></li> 
   <li><a name="ex:deriveaic"></a>Derive an AIC criterion for the multivariate Bernoulli mixture model from Equation&nbsp;<a href="cluster-cardinality-in-k-means-1.html#aicbic1">196</a>. <p> </p></li> 
  </ul> 
  <p> </p> 
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html4299" href="hierarchical-clustering-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html4293" href="flat-clustering-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html4289" href="references-and-further-reading-16.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html4295" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html4297" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html4300" href="hierarchical-clustering-1.html">Hierarchical clustering</a> 
  <b> Up:</b> 
  <a name="tex2html4294" href="flat-clustering-1.html">Flat clustering</a> 
  <b> Previous:</b> 
  <a name="tex2html4290" href="references-and-further-reading-16.html">References and further reading</a> &nbsp; 
  <b> <a name="tex2html4296" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html4298" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>  
 </body>
</html>