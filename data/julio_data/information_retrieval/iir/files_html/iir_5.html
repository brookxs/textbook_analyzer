<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Index compression</title> 
  <meta name="description" content="Index compression" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="next" href="scoring-term-weighting-and-the-vector-space-model-1.html" /> 
  <link rel="previous" href="index-construction-1.html" /> 
  <link rel="up" href="irbook.html" /> 
  <link rel="next" href="statistical-properties-of-terms-in-information-retrieval-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html1655" href="statistical-properties-of-terms-in-information-retrieval-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html1649" href="irbook.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html1643" href="references-and-further-reading-4.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html1651" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html1653" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html1656" href="statistical-properties-of-terms-in-information-retrieval-1.html">Statistical properties of terms</a> 
  <b> Up:</b> 
  <a name="tex2html1650" href="irbook.html">irbook</a> 
  <b> Previous:</b> 
  <a name="tex2html1644" href="references-and-further-reading-4.html">References and further reading</a> &nbsp; 
  <b> <a name="tex2html1652" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html1654" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h1><a name="SECTION001000000000000000000"></a><a name="ch:icompress"></a> <br /> Index compression </h1> 
  <p> <a name="5835"></a>Chapter <a href="boolean-retrieval-1.html#ch:intro">1</a> introduced the dictionary and the inverted index as the central data structures in information retrieval (IR). In this chapter, we employ a number of compression techniques for dictionary and inverted index that are essential for efficient IR systems. </p> 
  <p> One benefit of compression is immediately clear. We need less disk space. As we will see, compression ratios of 1:4 are easy to achieve, potentially cutting the cost of storing the index by 75%. </p> 
  <p> There are two more subtle benefits of compression. The first is increased use of caching. Search systems use some parts of the dictionary and the index much more than others. For example, if we cache the postings list of a frequently used query term <img width="10" height="32" align="MIDDLE" border="0" src="img67.png" alt="$t$" />, then the computations necessary for responding to the one-term query <img width="10" height="32" align="MIDDLE" border="0" src="img67.png" alt="$t$" /> can be entirely done in memory. With compression, we can fit a lot more information into main memory. Instead of having to expend a disk seek when processing a query with <img width="10" height="32" align="MIDDLE" border="0" src="img67.png" alt="$t$" />, we instead access its postings list in memory and decompress it. As we will see below, there are simple and efficient decompression methods, so that the penalty of having to decompress the postings list is small. As a result, we are able to decrease the response time of the IR system substantially. Because memory is a more expensive resource than disk space, increased speed owing to caching - rather than decreased space requirements - is often the prime motivator for compression. </p> 
  <p> The second more subtle advantage of compression is faster transfer of data from disk to memory. Efficient decompression algorithms run so fast on modern hardware that the total time of transferring a compressed chunk of data from disk and then decompressing it is usually less than transferring the same chunk of data in uncompressed form. For instance, we can reduce input/output (I/O) time by loading a much smaller compressed postings list, even when you add on the cost of decompression. So, in most cases, the retrieval system runs faster on compressed postings lists than on uncompressed postings lists. </p> 
  <p> <a name="5837"></a> If the main goal of compression is to conserve disk space, then the speed of compression algorithms is of no concern. But for improved cache utilization and faster disk-to-memory transfer, decompression speeds must be high. The compression algorithms we discuss in this chapter are highly efficient and can therefore serve all three purposes of index compression.<a name="5838"></a> </p> 
  <p> In this chapter, we define a <a name="5839"></a> <i>posting</i> as a docID in a postings list. For example, the postings list (6; 20, 45, 100), where 6 is the termID of the list's term, contains three postings. As discussed in Section&nbsp;<a href="positional-indexes-1.html#sec:positional-index">2.4.2</a> (page&nbsp;<a href="positional-indexes-1.html#p:positional-index"><img align="BOTTOM" border="1" alt="[*]" src="http://nlp.stanford.edu/IR-book/html/icons/crossref.png" /></a>), postings in most search systems also contain frequency and position information; but we will only consider simple docID postings here. See Section <a href="references-and-further-reading-5.html#sec:icompresssecfurther">5.4</a> for references on compressing frequencies and positions. </p> 
  <p> This chapter first gives a statistical characterization of the distribution of the entities we want to compress - terms and postings in large collections (Section <a href="statistical-properties-of-terms-in-information-retrieval-1.html#sec:statproperties">5.1</a> ). We then look at compression of the dictionary, using the dictionary-as-a-string method and blocked storage (Section <a href="dictionary-compression-1.html#sec:dictcompression">5.2</a> ). Section <a href="postings-file-compression-1.html#sec:postingscompression">5.3</a> describes two techniques for compressing the postings file, variable byte encoding and <img width="14" height="32" align="MIDDLE" border="0" src="img12.png" alt="$\gamma $" /> encoding. </p> 
  <p> <a name="5847"></a> <br /></p> 
  <hr /> 
  <!--Table of Child-Links--> 
  <a name="CHILD_LINKS"><strong>Subsections</strong></a> 
  <ul> 
   <li><a name="tex2html1657" href="statistical-properties-of-terms-in-information-retrieval-1.html">Statistical properties of terms in information retrieval</a> 
    <ul> 
     <li><a name="tex2html1658" href="heaps-law-estimating-the-number-of-terms-1.html">Heaps' law: Estimating the number of terms</a> </li> 
     <li><a name="tex2html1659" href="zipfs-law-modeling-the-distribution-of-terms-1.html">Zipf's law: Modeling the distribution of terms</a> </li> 
    </ul> <br /> </li> 
   <li><a name="tex2html1660" href="dictionary-compression-1.html">Dictionary compression</a> 
    <ul> 
     <li><a name="tex2html1661" href="dictionary-as-a-string-1.html">Dictionary as a string</a> </li> 
     <li><a name="tex2html1662" href="blocked-storage-1.html">Blocked storage</a> </li> 
    </ul> <br /> </li> 
   <li><a name="tex2html1663" href="postings-file-compression-1.html">Postings file compression</a> 
    <ul> 
     <li><a name="tex2html1664" href="variable-byte-codes-1.html">Variable byte codes</a> </li> 
     <li><a name="tex2html1665" href="gamma-codes-1.html">Gamma codes</a> </li> 
    </ul> <br /> </li> 
   <li><a name="tex2html1666" href="references-and-further-reading-5.html">References and further reading</a> </li> 
  </ul> 
  <!--End of Table of Child-Links--> 
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html1655" href="statistical-properties-of-terms-in-information-retrieval-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html1649" href="irbook.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html1643" href="references-and-further-reading-4.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html1651" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html1653" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html1656" href="statistical-properties-of-terms-in-information-retrieval-1.html">Statistical properties of terms</a> 
  <b> Up:</b> 
  <a name="tex2html1650" href="irbook.html">irbook</a> 
  <b> Previous:</b> 
  <a name="tex2html1644" href="references-and-further-reading-4.html">References and further reading</a> &nbsp; 
  <b> <a name="tex2html1652" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html1654" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>  
 </body>
</html>