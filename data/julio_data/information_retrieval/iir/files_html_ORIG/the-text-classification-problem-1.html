<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>The text classification problem</title> 
  <meta name="description" content="The text classification problem" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="next" href="naive-bayes-text-classification-1.html" /> 
  <link rel="previous" href="text-classification-and-naive-bayes-1.html" /> 
  <link rel="up" href="text-classification-and-naive-bayes-1.html" /> 
  <link rel="next" href="naive-bayes-text-classification-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html3447" href="naive-bayes-text-classification-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html3441" href="text-classification-and-naive-bayes-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html3435" href="text-classification-and-naive-bayes-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html3443" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html3445" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html3448" href="naive-bayes-text-classification-1.html">Naive Bayes text classification</a> 
  <b> Up:</b> 
  <a name="tex2html3442" href="text-classification-and-naive-bayes-1.html">Text classification and Naive</a> 
  <b> Previous:</b> 
  <a name="tex2html3436" href="text-classification-and-naive-bayes-1.html">Text classification and Naive</a> &nbsp; 
  <b> <a name="tex2html3444" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html3446" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h1><a name="SECTION001810000000000000000"></a> <a name="sec:classificationproblem"></a> <a name="p:classificationproblem"></a> <br /> The text classification problem </h1> 
  <p> <a name="16083"></a>In text classification, we are given a description 
   <!-- MATH
 $\onedoc
\in \mathbb{X}$
 --> <img width="46" height="31" align="MIDDLE" border="0" src="img853.png" alt="$\onedoc
\in \mathbb{X}$" /> of a document, where <img width="17" height="32" align="MIDDLE" border="0" src="img854.png" alt="$\mathbb{X}$" /> is the <a name="16086"></a> <a name="16087"></a> <i>document space</i> ; and a fixed set of <a name="16089"></a> <i>classes</i> 
   <!-- MATH
 $\mathbb{C} = \{ c_1,c_2,\ldots,c_J \}$
 --> <img width="137" height="33" align="MIDDLE" border="0" src="img855.png" alt="$\mathbb{C} = \{ c_1,c_2,\ldots,c_J \}$" />. <a name="16092"></a> Classes are also called <a name="16093"></a> <i>categories</i> or <a name="16095"></a> <i>labels</i> . Typically, the document space <img width="17" height="32" align="MIDDLE" border="0" src="img854.png" alt="$\mathbb{X}$" /> is some type of high-dimensional space, and the classes are human defined for the needs of an application, as in the examples China and documents that talk about multicore computer chips above. We are given a <a name="16100"></a> <i>training set</i> <a name="p:documentset"></a> 
   <!-- MATH
 $\docsetlabeled$
 --> <img width="18" height="32" align="MIDDLE" border="0" src="img856.png" alt="$\docsetlabeled$" /> of labeled documents 
   <!-- MATH
 $\onedoclabeled$
 --> <img width="40" height="33" align="MIDDLE" border="0" src="img857.png" alt="$\onedoclabeled$" />, where 
   <!-- MATH
 $\onedoclabeled \in \mathbb{X} \times \mathbb{C}$
 --> <img width="104" height="33" align="MIDDLE" border="0" src="img858.png" alt="$\onedoclabeled \in \mathbb{X} \times \mathbb{C}$" />. For example: <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
\onedoclabeled=\langle\mbox{Beijing joins the World Trade Organization},\class{China}\rangle
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="413" height="28" border="0" src="img859.png" alt="\begin{displaymath}
\onedoclabeled=\langle\mbox{Beijing joins the World Trade Organization},\class{China}\rangle
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (111)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> for the one-sentence document Beijing joins the World Trade Organization and the class (or label) China. 
  <p> Using a <a name="16111"></a> <a name="16112"></a> <i>learning method</i> or <a name="16114"></a> <i>learning algorithm</i> , we then wish to learn a classifier <a name="16116"></a> <a name="16117"></a> or <a name="16119"></a> <i>classification function</i> <a name="p:gammafunction"></a> <img width="14" height="32" align="MIDDLE" border="0" src="img12.png" alt="$\gamma $" /> that maps documents to classes: </p>
  <p> <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
\gamma: \mathbb{X} \rightarrow \mathbb{C}
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><a name="p:gammadef"></a><a name="eqn:gammadef"></a><img width="73" height="48" border="0" src="img860.png" alt="\begin{displaymath}\gamma: \mathbb{X} \rightarrow \mathbb{C}
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (112)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> 
  <p> This type of learning is called <a name="16128"></a> <a name="p:supervised"></a> <a name="16130"></a> <i>supervised learning</i> because a supervisor (the human who defines the classes and labels training documents) serves as a teacher directing the learning process. We denote the supervised learning method by <img width="13" height="32" align="MIDDLE" border="0" src="img861.png" alt="$\Gamma$" /> and write 
   <!-- MATH
 $\Gamma(\docsetlabeled) = \gamma$
 --> <img width="73" height="33" align="MIDDLE" border="0" src="img862.png" alt="$\Gamma(\docsetlabeled) = \gamma$" />. The learning method <img width="13" height="32" align="MIDDLE" border="0" src="img861.png" alt="$\Gamma$" /> takes the training set 
   <!-- MATH
 $\docsetlabeled$
 --> <img width="18" height="32" align="MIDDLE" border="0" src="img856.png" alt="$\docsetlabeled$" /> as input and returns the learned classification function <img width="14" height="32" align="MIDDLE" border="0" src="img12.png" alt="$\gamma $" />. </p>
  <p> Most names for learning methods <img width="13" height="32" align="MIDDLE" border="0" src="img861.png" alt="$\Gamma$" /> are also used for classifiers <img width="14" height="32" align="MIDDLE" border="0" src="img12.png" alt="$\gamma $" />. We talk about the Naive Bayes (NB) <i>learning method</i> <img width="13" height="32" align="MIDDLE" border="0" src="img861.png" alt="$\Gamma$" /> when we say that ``Naive Bayes is robust,'' meaning that it can be applied to many different learning problems and is unlikely to produce classifiers that fail catastrophically. But when we say that ``Naive Bayes had an error rate of 20%,'' we are describing an experiment in which a particular NB <i>classifier</i> <img width="14" height="32" align="MIDDLE" border="0" src="img12.png" alt="$\gamma $" /> (which was produced by the NB learning method) had a 20% error rate in an application. </p>
  <p> Figure <a href="#fig:setupstatclass">13.1</a> shows an example of text classification from the Reuters-RCV1 collection, introduced in Section <a href="blocked-sort-based-indexing-1.html#sec:constructlarge">4.2</a> , page <a href="blocked-sort-based-indexing-1.html#p:rcv1">4.2</a> . There are six classes (UK, China, ..., sports), each with three training documents. We show a few mnemonic words for each document's content. The training set provides some typical examples for each class, so that we can learn the classification function <img width="14" height="32" align="MIDDLE" border="0" src="img12.png" alt="$\gamma $" />. Once we have learned <img width="14" height="32" align="MIDDLE" border="0" src="img12.png" alt="$\gamma $" />, we can apply it to the <a name="16140"></a> <a name="16141"></a> <i>test set</i> (or <a name="16143"></a> <i>test data</i> ), for example, the new document first private Chinese airline whose class is unknown. In Figure <a href="#fig:setupstatclass">13.1</a> , the classification function assigns the new document to class 
   <!-- MATH
 $\gamma(\onedoc) =$
 --> <img width="54" height="33" align="MIDDLE" border="0" src="img863.png" alt="$\gamma(\onedoc) = $" /> China, which is the correct assignment. </p>
  <p> The classes in text classification often have some interesting structure such as the hierarchy in Figure <a href="#fig:setupstatclass">13.1</a> . There are two instances each of region categories, industry categories, and subject area categories. A hierarchy can be an important aid in solving a classification problem; see Section <a href="large-and-difficult-category-taxonomies-1.html#sec:difficult-textclassification">15.3.2</a> for further discussion. Until then, we will make the assumption in the text classification chapters that the classes form a set with no subset relationships between them. </p>
  <p> </p>
  <div align="CENTER">
   <a name="fig:setupstatclass"></a>
   <a name="p:setupstatclass"></a>
   <a name="17760"></a> 
   <table> 
    <caption align="BOTTOM">
     <strong>Figure 13.1:</strong> Classes, training set, and test set in text classification 
     <a name="16242"></a>.
    </caption> 
    <tbody>
     <tr>
      <td><img width="551" height="267" border="0" src="img864.png" alt="\begin{figure}\par
\psset{unit=0.8cm}
\par
\begin{pspicture}(-3,-6)(13,3)
\par
\...
...8)(3.05,2.3)(1.75,1.15)
\rput[c](10.9,0.0)
\par
\end{pspicture}\par
\end{figure}" /></td>
     </tr> 
    </tbody>
   </table> 
  </div> 
  <p> Definition&nbsp;eqn:gammadef stipulates that a document is a member of exactly one class. This is not the most appropriate model for the hierarchy in Figure <a href="#fig:setupstatclass">13.1</a> . For instance, a document about the 2008 Olympics should be a member of two classes: the China class and the sports class. This type of classification problem is referred to as an <a name="16250"></a> <i>any-of</i> problem and we will return to it in Section&nbsp;<a href="classification-with-more-than-two-classes-1.html#sec:more-than-two-classes">14.5</a> (page&nbsp;<a href="classification-with-more-than-two-classes-1.html#p:more-than-two-classes"><img align="BOTTOM" border="1" alt="[*]" src="http://nlp.stanford.edu/IR-book/html/icons/crossref.png" /></a>). For the time being, we only consider <a name="16254"></a> <i>one-of</i> problems where a document is a member of exactly one class. </p>
  <p> Our goal in text classification is high accuracy on test data or <i>new data</i> - for example, the newswire articles that we will encounter tomorrow morning in the multicore chip example. It is easy to achieve high accuracy on the training set (e.g., we can simply memorize the labels). But high accuracy on the training set in general does not mean that the classifier will work well on new data in an application. When we use the training set to learn a classifier for test data, we make the assumption that training data and test data are similar or from <i>the same distribution</i>. We defer a precise definition of this notion to <a name="16258"></a> Section&nbsp;<a href="the-bias-variance-tradeoff-1.html#sec:secbiasvariance">14.6</a> (page&nbsp;<a href="the-bias-variance-tradeoff-1.html#p:secbiasvariance"><img align="BOTTOM" border="1" alt="[*]" src="http://nlp.stanford.edu/IR-book/html/icons/crossref.png" /></a>). </p>
  <p> </p>
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html3447" href="naive-bayes-text-classification-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html3441" href="text-classification-and-naive-bayes-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html3435" href="text-classification-and-naive-bayes-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html3443" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html3445" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html3448" href="naive-bayes-text-classification-1.html">Naive Bayes text classification</a> 
  <b> Up:</b> 
  <a name="tex2html3442" href="text-classification-and-naive-bayes-1.html">Text classification and Naive</a> 
  <b> Previous:</b> 
  <a name="tex2html3436" href="text-classification-and-naive-bayes-1.html">Text classification and Naive</a> &nbsp; 
  <b> <a name="tex2html3444" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html3446" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>   
 </body>
</html>