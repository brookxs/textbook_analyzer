<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Dropping common terms: stop words</title> 
  <meta name="description" content="Dropping common terms: stop words" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="next" href="normalization-equivalence-classing-of-terms-1.html" /> 
  <link rel="previous" href="tokenization-1.html" /> 
  <link rel="up" href="determining-the-vocabulary-of-terms-1.html" /> 
  <link rel="next" href="normalization-equivalence-classing-of-terms-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html1117" href="normalization-equivalence-classing-of-terms-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html1111" href="determining-the-vocabulary-of-terms-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html1105" href="tokenization-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html1113" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html1115" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html1118" href="normalization-equivalence-classing-of-terms-1.html">Normalization (equivalence classing of</a> 
  <b> Up:</b> 
  <a name="tex2html1112" href="determining-the-vocabulary-of-terms-1.html">Determining the vocabulary of</a> 
  <b> Previous:</b> 
  <a name="tex2html1106" href="tokenization-1.html">Tokenization</a> &nbsp; 
  <b> <a name="tex2html1114" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html1116" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h2><a name="SECTION00722000000000000000"></a> <a name="sec:stopwords"></a> <a name="p:stopwords"></a> <br /> Dropping common terms: stop words </h2> 
  <p> </p>
  <div align="CENTER">
   <a name="fig:stoplist"></a>
   <a name="p:stoplist"></a>
   <a name="2228"></a> 
   <table> 
    <caption align="BOTTOM">
     <strong>Figure 2.5:</strong> A stop list of 25 semantically non-selective words which are common in Reuters-RCV1.
    </caption> 
    <tbody>
     <tr>
      <td><img width="431" height="51" border="0" src="img95.png" alt="\begin{figure}\begin{tabular}{llllllllll}
a &amp; an &amp; and &amp; are &amp; as &amp; at &amp; be &amp; by...
... &amp; on &amp; that &amp; the \\
to &amp; was &amp; were &amp; will &amp; with
\end{tabular}
\end{figure}" /></td>
     </tr> 
    </tbody>
   </table> 
  </div> 
  <p> Sometimes, some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called <a name="2232"></a> <i>stop words</i> . The general strategy for determining a stop list is to sort the terms by <a name="2234"></a> <i>collection frequency</i> (the total number of times each term appears in the document collection), and then to take the most frequent terms, often hand-filtered for their semantic content relative to the domain of the documents being indexed, as a <a name="2236"></a> <i>stop list</i> , the members of which are then discarded during indexing. An example of a stop list is shown in Figure <a href="#fig:stoplist">2.5</a> . Using a stop list significantly reduces the number of postings that a system has to store; we will present some statistics on this in Chapter <a href="index-compression-1.html#ch:icompress">5</a> (see Table <a href="statistical-properties-of-terms-in-information-retrieval-1.html#tab:icompresstb5">5.1</a> , page <a href="statistical-properties-of-terms-in-information-retrieval-1.html#p:icompresstb5">5.1</a> ). And a lot of the time not indexing stop words does little harm: keyword searches with terms like the and by don't seem very useful. However, this is not true for phrase searches. The phrase query ``President of the United States'', which contains two stop words, is more precise than President AND ``United States''. The meaning of flights to London is likely to be lost if the word to is stopped out. A search for Vannevar Bush's article As we may think will be difficult if the first three words are stopped out, and the system searches simply for documents containing the word think. Some special query types are disproportionately affected. Some song titles and well known pieces of verse consist entirely of words that are commonly on stop lists (To be or not to be, Let It Be, I don't want to be, ...). </p>
  <p> The general trend in IR systems over time has been from standard use of quite large stop lists (200-300 terms) to very small stop lists (7-12 terms) to no stop list whatsoever. Web search engines generally do not use stop lists. Some of the design of modern IR systems has focused precisely on how we can exploit the statistics of language so as to be able to cope with common words in better ways. We will show in Section&nbsp;<a href="postings-file-compression-1.html#sec:postingscompression">5.3</a> (page&nbsp;<a href="postings-file-compression-1.html#p:postingscompression"><img align="BOTTOM" border="1" alt="[*]" src="http://nlp.stanford.edu/IR-book/html/icons/crossref.png" /></a>) how good compression techniques greatly reduce the cost of storing the postings for common words. idf then discusses how standard term weighting leads to very common words having little impact on document rankings. Finally, Section&nbsp;<a href="impact-ordering-1.html#sec:impactordered">7.1.5</a> (page&nbsp;<a href="impact-ordering-1.html#p:impactordered"><img align="BOTTOM" border="1" alt="[*]" src="http://nlp.stanford.edu/IR-book/html/icons/crossref.png" /></a>) shows how an IR system with impact-sorted indexes can terminate scanning a postings list early when weights get small, and hence common words do not cause a large additional processing cost for the average query, even though postings lists for stop words are very long. So for most modern IR systems, the additional cost of including stop words is not that big - neither in terms of index size nor in terms of query processing time. </p>
  <p> </p>
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html1117" href="normalization-equivalence-classing-of-terms-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html1111" href="determining-the-vocabulary-of-terms-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html1105" href="tokenization-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html1113" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html1115" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html1118" href="normalization-equivalence-classing-of-terms-1.html">Normalization (equivalence classing of</a> 
  <b> Up:</b> 
  <a name="tex2html1112" href="determining-the-vocabulary-of-terms-1.html">Determining the vocabulary of</a> 
  <b> Previous:</b> 
  <a name="tex2html1106" href="tokenization-1.html">Tokenization</a> &nbsp; 
  <b> <a name="tex2html1114" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html1116" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>   
 </body>
</html>