<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Deriving a ranking function for query terms</title> 
  <meta name="description" content="Deriving a ranking function for query terms" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="next" href="probability-estimates-in-theory-1.html" /> 
  <link rel="previous" href="the-binary-independence-model-1.html" /> 
  <link rel="up" href="the-binary-independence-model-1.html" /> 
  <link rel="next" href="probability-estimates-in-theory-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html3086" href="probability-estimates-in-theory-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html3080" href="the-binary-independence-model-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html3074" href="the-binary-independence-model-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html3082" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html3084" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html3087" href="probability-estimates-in-theory-1.html">Probability estimates in theory</a> 
  <b> Up:</b> 
  <a name="tex2html3081" href="the-binary-independence-model-1.html">The Binary Independence Model</a> 
  <b> Previous:</b> 
  <a name="tex2html3075" href="the-binary-independence-model-1.html">The Binary Independence Model</a> &nbsp; 
  <b> <a name="tex2html3083" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html3085" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h2><a name="SECTION001631000000000000000"> Deriving a ranking function for query terms</a> </h2> 
  <p> Given a query <img width="12" height="32" align="MIDDLE" border="0" src="img161.png" alt="$q$" />, we wish to order returned documents by descending <img width="97" height="33" align="MIDDLE" border="0" src="img685.png" alt="$P(R=1\vert d,q)$" />. Under the BIM, this is modeled as ordering by 
   <!-- MATH
 $P(R=1|\vec{x},\vec{q})$
 --> <img width="98" height="33" align="MIDDLE" border="0" src="img705.png" alt="$P(R=1\vert\vec{x},\vec{q})$" />. Rather than estimating this probability directly, because we are interested only in the ranking of documents, we work with some other quantities which are easier to compute and which give the same ordering of documents. In particular, we can rank documents by their odds of relevance (as the odds of relevance is monotonic with the probability of relevance). This makes things easier, because we can ignore the common denominator in Rxq-bayes, giving: <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
O(R|\vec{x},\vec{q})
= \frac{P(R=1|\vec{x},\vec{q})}{P(R=0|\vec{x},\vec{q})}
= \frac{\frac{P(R=1|\vec{q})P(\vec{x}|R=1,\vec{q})}{P(\vec{x}|\vec{q})}}{\frac{P(R=0|\vec{q})P(\vec{x}|R=0,\vec{q})}{P(\vec{x}|\vec{q})}}
 = \frac{P(R=1|\vec{q})}{P(R=0|\vec{q})}\cdot \frac{P(\vec{x}|R=1,\vec{q})}{P(\vec{x}|R=0,\vec{q})}
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><a name="odds1"></a><img width="541" height="66" border="0" src="img706.png" alt="\begin{displaymath}
O(R\vert\vec{x},\vec{q})
= \frac{P(R=1\vert\vec{x},\vec{q})}...
...rac{P(\vec{x}\vert R=1,\vec{q})}{P(\vec{x}\vert R=0,\vec{q})}
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (66)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> 
  <p> The left term in the rightmost expression of Equation&nbsp;<a href="#odds1">66</a> is a constant for a given query. Since we are only ranking documents, there is thus no need for us to estimate it. The right-hand term does, however, require estimation, and this initially appears to be difficult: How can we accurately estimate the probability of an entire term incidence vector occurring? It is at this point that we make the <a name="14059"></a><a name="14060"></a> <i>Naive Bayes conditional independence assumption</i> that the presence or absence of a word in a document is independent of the presence or absence of any other word (given the query): <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
\frac{P(\vec{x}|R=1,\vec{q})}{P(\vec{x}|R=0,\vec{q})} = \prod_{t=1}^M
\frac{P(x_t|R=1,\vec{q})}{P(x_t|R=0,\vec{q})}
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="243" height="52" border="0" src="img707.png" alt="\begin{displaymath}
\frac{P(\vec{x}\vert R=1,\vec{q})}{P(\vec{x}\vert R=0,\vec{q...
...t=1}^M
\frac{P(x_t\vert R=1,\vec{q})}{P(x_t\vert R=0,\vec{q})}
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (67)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> So: 
  <br /> 
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
O(R|\vec{x},\vec{q}) = O(R|\vec{q}) \cdot \prod_{t=1}^M
\frac{P(x_t|R=1,\vec{q})}{P(x_t|R=0,\vec{q})}
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="273" height="52" border="0" src="img708.png" alt="\begin{displaymath}
O(R\vert\vec{x},\vec{q}) = O(R\vert\vec{q}) \cdot \prod_{t=1}^M
\frac{P(x_t\vert R=1,\vec{q})}{P(x_t\vert R=0,\vec{q})}
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (68)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> Since each 
  <img width="18" height="32" align="MIDDLE" border="0" src="img709.png" alt="$x_t$" /> is either 0 or 1, we can separate the terms to give: 
  <br /> 
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
O(R|\vec{x},\vec{q}) = O(R|\vec{q}) \cdot
\prod_{t: x_t=1}
\frac{P(x_t=1|R=1,\vec{q})}{P(x_t=1|R=0,\vec{q})} \cdot
\prod_{t: x_t=0}
\frac{P(x_t=0|R=1,\vec{q})}{P(x_t=0|R=0,\vec{q})}
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="497" height="51" border="0" src="img710.png" alt="\begin{displaymath}
O(R\vert\vec{x},\vec{q}) = O(R\vert\vec{q}) \cdot
\prod_{t: ...
...0}
\frac{P(x_t=0\vert R=1,\vec{q})}{P(x_t=0\vert R=0,\vec{q})}
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (69)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> Henceforth, let 
  <!-- MATH
 $p_t = P(x_t=1|R=1,\vec{q})$
 --> 
  <img width="169" height="33" align="MIDDLE" border="0" src="img711.png" alt="$p_t = P(x_t=1\vert R=1,\vec{q})$" /> be the probability of a term appearing in a document relevant to the query, and 
  <!-- MATH
 $u_t = P(x_t = 1|R=0,\vec{q})$
 --> 
  <img width="169" height="33" align="MIDDLE" border="0" src="img712.png" alt="$u_t = P(x_t = 1\vert R=0,\vec{q})$" /> be the probability of a term appearing in a nonrelevant document. These quantities can be visualized in the following contingency table where the columns add to 1: 
  <br /> 
  <img width="503" height="71" align="BOTTOM" border="0" src="img713.png" alt="\begin{example}
\begin{tabular}[t]{\vert cc\vert cc\vert}
\hline
&amp; document &amp; r...
...m absent &amp; $x_t = 0$\ &amp; $1-p_t$\ &amp; $1-u_t$\ \\ \hline
\end{tabular}\end{example}" /> 
  <br /> 
  <p> Let us make an additional simplifying assumption that terms not occurring in the query are equally likely to occur in relevant and nonrelevant documents: that is, if <img width="47" height="32" align="MIDDLE" border="0" src="img714.png" alt="$q_t = 0$" /> then <img width="55" height="32" align="MIDDLE" border="0" src="img715.png" alt="$p_t = u_t$" />. (This assumption can be changed, as when doing relevance feedback in Section <a href="probabilistic-approaches-to-relevance-feedback-1.html#sec:probrf">11.3.4</a> .) Then we need only consider terms in the products that appear in the query, and so, <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
O(R|\vec{q},\vec{x}) = O(R|\vec{q}) \cdot
\prod_{t: x_t = q_t =1}
\frac{p_t}{u_t} \cdot
\prod_{t: x_t=0,q_t=1}
\frac{1-p_t}{1-u_t}
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="347" height="50" border="0" src="img716.png" alt="\begin{displaymath}
O(R\vert\vec{q},\vec{x}) = O(R\vert\vec{q}) \cdot
\prod_{t: ...
...rac{p_t}{u_t} \cdot
\prod_{t: x_t=0,q_t=1}
\frac{1-p_t}{1-u_t}
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (70)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> The left product is over query terms found in the document and the right product is over query terms not found in the document. 
  <p> We can manipulate this expression by including the query terms found in the document into the right product, but simultaneously dividing through by them in the left product, so the value is unchanged. Then we have: <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
O(R|\vec{q},\vec{x}) = O(R|\vec{q}) \cdot
\prod_{t: x_t = q_t =1}
\frac{p_t(1-u_t)}{u_t(1-p_t)} \cdot
\prod_{t: q_t=1}
\frac{1-p_t}{1-u_t}
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="372" height="52" border="0" src="img717.png" alt="\begin{displaymath}
O(R\vert\vec{q},\vec{x}) = O(R\vert\vec{q}) \cdot
\prod_{t: ...
...1-u_t)}{u_t(1-p_t)} \cdot
\prod_{t: q_t=1}
\frac{1-p_t}{1-u_t}
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (71)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> The left product is still over query terms found in the document, but the right product is now over all query terms. That means that this right product is a constant for a particular query, just like the odds 
  <img width="54" height="33" align="MIDDLE" border="0" src="img718.png" alt="$O(R\vert\vec{q})$" />. So the only quantity that needs to be estimated to rank documents for relevance to a query is the left product. We can equally rank documents by the logarithm of this term, since log is a monotonic function. The resulting quantity used for ranking is called the 
  <a name="14121"></a> 
  <i>Retrieval Status Value</i> (RSV) in this model: 
  <br /> 
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
RSV_d = \log \prod_{t: x_t = q_t =1} \frac{p_t(1-u_t)}{u_t(1-p_t)} =
\sum_{t: x_t = q_t =1} \log \frac{p_t(1-u_t)}{u_t(1-p_t)}
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="392" height="52" border="0" src="img719.png" alt="\begin{displaymath}
RSV_d = \log \prod_{t: x_t = q_t =1} \frac{p_t(1-u_t)}{u_t(1...
...)} =
\sum_{t: x_t = q_t =1} \log \frac{p_t(1-u_t)}{u_t(1-p_t)}
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (72)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> 
  <p> So everything comes down to computing the <img width="37" height="32" align="MIDDLE" border="0" src="img720.png" alt="$RSV$" />. Define <img width="16" height="32" align="MIDDLE" border="0" src="img721.png" alt="$c_t$" />: <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
c_t = \log \frac{p_t(1-u_t)}{u_t(1-p_t)} = \log \frac{p_t}{(1-p_t)} + \log \frac{1-u_t}{u_t}
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><a name="odds-ratio-ct"></a><img width="327" height="45" border="0" src="img722.png" alt="\begin{displaymath}
c_t = \log \frac{p_t(1-u_t)}{u_t(1-p_t)} = \log \frac{p_t}{(1-p_t)} + \log \frac{1-u_t}{u_t}
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (73)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> The 
  <img width="16" height="32" align="MIDDLE" border="0" src="img721.png" alt="$c_t$" /> terms are log odds ratios for the terms in the query. We have the odds of the term appearing if the document is relevant (
  <img width="84" height="33" align="MIDDLE" border="0" src="img723.png" alt="$p_t/(1-p_t)$" />) and the odds of the term appearing if the document is nonrelevant (
  <img width="83" height="33" align="MIDDLE" border="0" src="img724.png" alt="$u_t/(1-u_t)$" />). The 
  <a name="14140"></a> 
  <i>odds ratio</i> is the ratio of two such odds, and then we finally take the log of that quantity. The value will be 0 if a term has equal odds of appearing in relevant and nonrelevant documents, and positive if it is more likely to appear in relevant documents. The 
  <img width="16" height="32" align="MIDDLE" border="0" src="img721.png" alt="$c_t$" /> quantities function as term weights in the model, and the document score for a query is 
  <!-- MATH
 $RSV_d =
\sum_{x_t=q_t=1} c_t$
 --> 
  <img width="139" height="32" align="MIDDLE" border="0" src="img725.png" alt="$RSV_d =
\sum_{x_t=q_t=1} c_t$" />. Operationally, we sum them in accumulators for query terms appearing in documents, just as for the vector space model calculations discussed in Section&nbsp;
  <a href="efficient-scoring-and-ranking-1.html#sec:heuristics">7.1</a> (page&nbsp;
  <a href="efficient-scoring-and-ranking-1.html#p:heuristics"><img align="BOTTOM" border="1" alt="[*]" src="http://nlp.stanford.edu/IR-book/html/icons/crossref.png" /></a>). We now turn to how we estimate these 
  <img width="16" height="32" align="MIDDLE" border="0" src="img721.png" alt="$c_t$" /> quantities for a particular collection and query. 
  <p> </p>
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html3086" href="probability-estimates-in-theory-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html3080" href="the-binary-independence-model-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html3074" href="the-binary-independence-model-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html3082" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html3084" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html3087" href="probability-estimates-in-theory-1.html">Probability estimates in theory</a> 
  <b> Up:</b> 
  <a name="tex2html3081" href="the-binary-independence-model-1.html">The Binary Independence Model</a> 
  <b> Previous:</b> 
  <a name="tex2html3075" href="the-binary-independence-model-1.html">The Binary Independence Model</a> &nbsp; 
  <b> <a name="tex2html3083" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html3085" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>   
 </body>
</html>