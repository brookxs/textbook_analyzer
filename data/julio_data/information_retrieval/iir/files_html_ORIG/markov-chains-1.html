<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Markov chains</title> 
  <meta name="description" content="Markov chains" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="next" href="the-pagerank-computation-1.html" /> 
  <link rel="previous" href="pagerank-1.html" /> 
  <link rel="up" href="pagerank-1.html" /> 
  <link rel="next" href="definition-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html5025" href="definition-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html5019" href="pagerank-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html5013" href="pagerank-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html5021" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html5023" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html5026" href="definition-1.html">Definition:</a> 
  <b> Up:</b> 
  <a name="tex2html5020" href="pagerank-1.html">PageRank</a> 
  <b> Previous:</b> 
  <a name="tex2html5014" href="pagerank-1.html">PageRank</a> &nbsp; 
  <b> <a name="tex2html5022" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html5024" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h2><a name="SECTION002621000000000000000"></a> <a name="sec:markov"></a> <a name="p:markov"></a> <br /> Markov chains </h2> A Markov chain is a 
  <em>discrete-time stochastic process:</em> a process that occurs in a series of time-steps in each of which a random choice is made. A Markov chain consists of 
  <img width="17" height="32" align="MIDDLE" border="0" src="img62.png" alt="$N$" /> 
  <em>states</em>. Each web page will correspond to a state in the Markov chain we will formulate. 
  <p> A Markov chain is characterized by an <img width="51" height="32" align="MIDDLE" border="0" src="img1555.png" alt="$N \times N$" /> <em>transition probability matrix</em> <img width="14" height="32" align="MIDDLE" border="0" src="img115.png" alt="$P$" /><a name="transition-notation"></a> each of whose entries is in the interval <img width="36" height="33" align="MIDDLE" border="0" src="img356.png" alt="$[0,1]$" />; the entries in each row of <img width="14" height="32" align="MIDDLE" border="0" src="img115.png" alt="$P$" /> add up to 1. The Markov chain can be in one of the <img width="17" height="32" align="MIDDLE" border="0" src="img62.png" alt="$N$" /> states at any given time-step; then, the entry <img width="21" height="32" align="MIDDLE" border="0" src="img1895.png" alt="$P_{ij}$" /> tells us the probability that the state at the next time-step is <img width="9" height="31" align="MIDDLE" border="0" src="img9.png" alt="$j$" />, conditioned on the current state being <img width="8" height="31" align="MIDDLE" border="0" src="img8.png" alt="$i$" />. Each entry <img width="21" height="32" align="MIDDLE" border="0" src="img1895.png" alt="$P_{ij}$" /> is known as a transition probability and depends only on the current state <img width="8" height="31" align="MIDDLE" border="0" src="img8.png" alt="$i$" />; this is known as the Markov property. Thus, by the Markov property, <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
\forall i,j, P_{ij}\in[0,1]
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="102" height="30" border="0" src="img1896.png" alt="\begin{displaymath}\forall i,j, P_{ij}\in[0,1]\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (251)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> and 
  <br /> 
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
\forall i, \sum_{j=1}^N P_{ij}=1.
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><a name="eqnstochastic"></a><img width="95" height="56" border="0" src="img1897.png" alt="\begin{displaymath}
\forall i, \sum_{j=1}^N P_{ij}=1.\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (252)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> A matrix with non-negative entries that satisfies Equation&nbsp;
  <a href="#eqnstochastic">252</a> is known as a 
  <a name="32267"></a> 
  <i>stochastic matrix</i> . A key property of a stochastic matrix is that it has a 
  <a name="32269"></a> 
  <i>principal left eigenvector</i> corresponding to its largest eigenvalue, which is 1. 
  <p> In a Markov chain, the probability distribution of next states for a Markov chain depends only on the current state, and not on how the Markov chain arrived at the current state. Figure <a href="#fig:figmarkov">21.2</a> shows a simple Markov chain with three states. From the middle state A, we proceed with (equal) probabilities of 0.5 to either B or C. From either B or C, we proceed with probability 1 to A. The transition probability matrix of this Markov chain is then </p>
  <p> <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
\left(
  \begin{array}{ccc}
    0 & 0.5 & 0.5 \\
    1 & 0 & 0 \\
    1 & 0 & 0 \\
  \end{array}
\right)
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="114" height="64" border="0" src="img1898.png" alt="\begin{displaymath}
\left(
\begin{array}{ccc}
0 &amp; 0.5 &amp; 0.5 \\
1 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 0 \\
\end{array}\right)
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (253)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> 
  <p> </p>
  <div align="CENTER">
   <a name="fig:figmarkov"></a>
   <a name="p:figmarkov"></a>
   <a name="32294"></a> 
   <table> 
    <caption align="BOTTOM">
     <strong>Figure 21.2:</strong> A simple Markov chain with three states; the numbers on the links indicate the transition probabilities.
    </caption> 
    <tbody>
     <tr>
      <td><img width="200" height="51" border="0" src="img1899.png" alt="\begin{figure}\begin{picture}(700,80)\thicklines
\put(150,40){\circle{25}}
\p...
...{0.5}
\put(190,35){\vector(-1,0){30}}
\put(175,25){1}
\end{picture}
\end{figure}" /></td>
     </tr> 
    </tbody>
   </table> 
  </div> 
  <p> A Markov chain's probability distribution over its states may be viewed as a <a name="32298"></a> <i>probability vector</i> : a vector all of whose entries are in the interval <img width="36" height="33" align="MIDDLE" border="0" src="img356.png" alt="$[0,1]$" />, and the entries add up to 1. An <img width="17" height="32" align="MIDDLE" border="0" src="img62.png" alt="$N$" />-dimensional probability vector each of whose components corresponds to one of the <img width="17" height="32" align="MIDDLE" border="0" src="img62.png" alt="$N$" /> states of a Markov chain can be viewed as a probability distribution over its states. For our simple Markov chain of Figure <a href="#fig:figmarkov">21.2</a> , the probability vector would have 3 components that sum to 1. </p>
  <p> We can view a random surfer on the web graph as a Markov chain, with one state for each web page, and each transition probability representing the probability of moving from one web page to another. The teleport operation contributes to these transition probabilities. The adjacency matrix <img width="17" height="32" align="MIDDLE" border="0" src="img167.png" alt="$A$" /><a name="adjacency-notation"></a> of the web graph is defined as follows: if there is a hyperlink from page <img width="8" height="31" align="MIDDLE" border="0" src="img8.png" alt="$i$" /> to page <img width="9" height="31" align="MIDDLE" border="0" src="img9.png" alt="$j$" />, then <img width="55" height="32" align="MIDDLE" border="0" src="img1900.png" alt="$A_{ij}=1$" />, otherwise <img width="55" height="32" align="MIDDLE" border="0" src="img1901.png" alt="$A_{ij}=0$" />. We can readily derive the transition probability matrix <img width="14" height="32" align="MIDDLE" border="0" src="img115.png" alt="$P$" /> for our Markov chain from the <img width="51" height="32" align="MIDDLE" border="0" src="img1555.png" alt="$N \times N$" /> matrix <img width="17" height="32" align="MIDDLE" border="0" src="img167.png" alt="$A$" />: </p>
  <ol> 
   <li>If a row of <img width="17" height="32" align="MIDDLE" border="0" src="img167.png" alt="$A$" /> has no 1's, then replace each element by 1/N. For all other rows proceed as follows. </li> 
   <li>Divide each 1 in <img width="17" height="32" align="MIDDLE" border="0" src="img167.png" alt="$A$" /> by the number of 1's in its row. Thus, if there is a row with three 1's, then each of them is replaced by <img width="30" height="31" align="MIDDLE" border="0" src="img1902.png" alt="$1/3$" />. </li> 
   <li>Multiply the resulting matrix by <img width="40" height="32" align="MIDDLE" border="0" src="img1893.png" alt="$1-\alpha$" />. </li> 
   <li>Add <img width="37" height="31" align="MIDDLE" border="0" src="img1903.png" alt="$\alpha/N$" /> to every entry of the resulting matrix, to obtain <img width="14" height="32" align="MIDDLE" border="0" src="img115.png" alt="$P$" />. </li> 
  </ol> 
  <p> We can depict the probability distribution of the surfer's position at any time by a probability vector <img width="13" height="32" align="MIDDLE" border="0" src="img701.png" alt="$\vec{x}$" />. At <img width="39" height="32" align="MIDDLE" border="0" src="img1904.png" alt="$t=0$" /> the surfer may begin at a state whose corresponding entry in <img width="13" height="32" align="MIDDLE" border="0" src="img701.png" alt="$\vec{x}$" /> is 1 while all others are zero. By definition, the surfer's distribution at <img width="40" height="32" align="MIDDLE" border="0" src="img1905.png" alt="$t=1$" /> is given by the probability vector <img width="23" height="32" align="MIDDLE" border="0" src="img1906.png" alt="$\vec{x}P$" />; at <img width="40" height="32" align="MIDDLE" border="0" src="img1907.png" alt="$t=2$" /> by 
   <!-- MATH
 $(\vec{x}P)P=\vec{x}P^2$
 --> <img width="95" height="36" align="MIDDLE" border="0" src="img1908.png" alt="$(\vec{x}P)P=\vec{x}P^2$" />, and so on. We will detail this process in Section <a href="the-pagerank-computation-1.html#sec:prank">21.2.2</a> . We can thus compute the surfer's distribution over the states at any time, given only the initial distribution and the transition probability matrix <img width="14" height="32" align="MIDDLE" border="0" src="img115.png" alt="$P$" />. </p>
  <p> If a Markov chain is allowed to run for many time steps, each state is visited at a (different) frequency that depends on the structure of the Markov chain. In our running analogy, the surfer visits certain web pages (say, popular news home pages) more often than other pages. We now make this intuition precise, establishing conditions under which such the visit frequency converges to fixed, steady-state quantity. Following this, we set the PageRank of each node <img width="12" height="32" align="MIDDLE" border="0" src="img615.png" alt="$v$" /> to this steady-state visit frequency and show how it can be computed. </p>
  <p> <br /></p>
  <hr /> 
  <!--Table of Child-Links--> 
  <a name="CHILD_LINKS"><strong>Subsections</strong></a> 
  <ul> 
   <li>
    <ul> 
     <li><a name="tex2html5027" href="definition-1.html">Definition:</a> </li>
    </ul></li>
  </ul> 
  <!--End of Table of Child-Links--> 
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html5025" href="definition-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html5019" href="pagerank-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html5013" href="pagerank-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html5021" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html5023" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html5026" href="definition-1.html">Definition:</a> 
  <b> Up:</b> 
  <a name="tex2html5020" href="pagerank-1.html">PageRank</a> 
  <b> Previous:</b> 
  <a name="tex2html5014" href="pagerank-1.html">PageRank</a> &nbsp; 
  <b> <a name="tex2html5022" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html5024" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>   
 </body>
</html>