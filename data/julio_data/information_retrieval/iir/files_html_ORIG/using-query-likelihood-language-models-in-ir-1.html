<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<!--Converted with LaTeX2HTML 2002-2-1 (1.71)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<html>
 <head> 
  <title>Using query likelihood language models in IR</title> 
  <meta name="description" content="Using query likelihood language models in IR" /> 
  <meta name="keywords" content="irbook" /> 
  <meta name="resource-type" content="document" /> 
  <meta name="distribution" content="global" /> 
  <meta name="Generator" content="LaTeX2HTML v2002-2-1" /> 
  <meta http-equiv="Content-Style-Type" content="text/css" /> 
  <link rel="STYLESHEET" href="irbook.css" /> 
  <link rel="next" href="estimating-the-query-generation-probability-1.html" /> 
  <link rel="previous" href="the-query-likelihood-model-1.html" /> 
  <link rel="up" href="the-query-likelihood-model-1.html" /> 
  <link rel="next" href="estimating-the-query-generation-probability-1.html" /> 
 </head> 
 <body> 
  <!--Navigation Panel--> 
  <a name="tex2html3328" href="estimating-the-query-generation-probability-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html3322" href="the-query-likelihood-model-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html3316" href="the-query-likelihood-model-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html3324" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html3326" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html3329" href="estimating-the-query-generation-probability-1.html">Estimating the query generation</a> 
  <b> Up:</b> 
  <a name="tex2html3323" href="the-query-likelihood-model-1.html">The query likelihood model</a> 
  <b> Previous:</b> 
  <a name="tex2html3317" href="the-query-likelihood-model-1.html">The query likelihood model</a> &nbsp; 
  <b> <a name="tex2html3325" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html3327" href="index-1.html">Index</a></b> 
  <br /> 
  <br /> 
  <!--End of Navigation Panel--> 
  <h2><a name="SECTION001721000000000000000"></a> <a name="sec:querylikelihoodmodel"></a> <a name="p:querylikelihoodmodel"></a> <br /> Using query likelihood language models in IR </h2> 
  <p> Language modeling is a quite general formal approach to IR, with many variant realizations. The original and basic method for using language models in IR is the <a name="15333"></a> <i>query likelihood model</i> . In it, we construct from each document <img width="12" height="31" align="MIDDLE" border="0" src="img354.png" alt="$d$" /> in the collection a language model <img width="27" height="32" align="MIDDLE" border="0" src="img789.png" alt="$M_d$" />. Our goal is to rank documents by <img width="49" height="33" align="MIDDLE" border="0" src="img812.png" alt="$P(d\vert q)$" />, where the probability of a document is interpreted as the likelihood that it is relevant to the query. Using Bayes rule (as introduced in probirsec), we have: <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
P(d|q) = P(q|d)P(d)/P(q)
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><img width="185" height="28" border="0" src="img813.png" alt="\begin{displaymath}
P(d\vert q) = P(q\vert d)P(d)/P(q)
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (98)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> 
  <img width="35" height="33" align="MIDDLE" border="0" src="img814.png" alt="$P(q)$" /> is the same for all documents, and so can be ignored. The prior probability of a document 
  <img width="36" height="33" align="MIDDLE" border="0" src="img815.png" alt="$P(d)$" /> is often treated as uniform across all 
  <img width="12" height="31" align="MIDDLE" border="0" src="img354.png" alt="$d$" /> and so it can also be ignored, but we could implement a genuine prior which could include criteria like authority, length, genre, newness, and number of previous people who have read the document. But, given these simplifications, we return results ranked by simply 
  <img width="49" height="33" align="MIDDLE" border="0" src="img816.png" alt="$P(q\vert d)$" />, the probability of the query 
  <img width="12" height="32" align="MIDDLE" border="0" src="img161.png" alt="$q$" /> under the language model derived from 
  <img width="12" height="31" align="MIDDLE" border="0" src="img354.png" alt="$d$" />. The Language Modeling approach thus attempts to model the query generation process: Documents are ranked by the probability that a query would be observed as a random sample from the respective document model. 
  <p> The most common way to do this is using the multinomial unigram language model, which is equivalent to a multinomial Naive Bayes model (page <a href="the-bernoulli-model-1.html#p:twomodels">13.3</a> ), where the documents are the classes, each treated in the estimation as a separate ``language''. Under this model, we have that: <a name="p:multinomial"></a> <br /> </p>
  <div align="RIGHT"> 
   <!-- MATH
 \begin{equation}
P(q|M_d) = K_q \prod_{t \in V} P(t|M_d)^{\termf_{t,d}}
\end{equation}
 --> 
   <table width="100%" align="CENTER"> 
    <tbody>
     <tr valign="MIDDLE">
      <td align="CENTER" nowrap=""><a name="p:multinomialfactor"></a><a name="multinomialfactor"></a><a name="eqn:multinomial"></a><img width="221" height="50" border="0" src="img817.png" alt="\begin{displaymath}P(q\vert M_d) = K_q \prod_{t \in V} P(t\vert M_d)^{\termf_{t,d}}
\end{displaymath}" /></td> 
      <td width="10" align="RIGHT"> (99)</td>
     </tr> 
    </tbody>
   </table> 
   <br clear="ALL" />
  </div>
  <p></p> where, again 
  <!-- MATH
 $K_q = L_d!/(\termf_{t_1,d}!\termf_{t_2,d}!\cdots
\termf_{t_M,d}!)$
 --> 
  <img width="225" height="33" align="MIDDLE" border="0" src="img818.png" alt="$K_q = L_d!/(\termf_{t_1,d}!\termf_{t_2,d}!\cdots
\termf_{t_M,d}!)$" /> is the multinomial coefficient for the query 
  <img width="12" height="32" align="MIDDLE" border="0" src="img161.png" alt="$q$" />, which we will henceforth ignore, since it is a constant for a particular query. 
  <p> For retrieval based on a language model (henceforth <a name="15350"></a> <i>LM</i> ), we treat the generation of queries as a random process. The approach is to </p>
  <ol> 
   <li>Infer a LM for each document. </li> 
   <li>Estimate <img width="68" height="33" align="MIDDLE" border="0" src="img819.png" alt="$P(q\vert M_{d_i})$" />, the probability of generating the query according to each of these document models. </li> 
   <li>Rank the documents according to these probabilities. </li> 
  </ol> The intuition of the basic model is that the user has a prototype document in mind, and generates a query based on words that appear in this document. Often, users have a reasonable idea of terms that are likely to occur in documents of interest and they will choose query terms that distinguish these documents from others in the collection.
  <a name="tex2html117" href="footnode.html#foot15596"><sup><img align="BOTTOM" border="1" alt="[*]" src="http://nlp.stanford.edu/IR-book/html/icons/footnote.png" /></sup></a>Collection statistics are an integral part of the language model, rather than being used heuristically as in many other approaches. 
  <p> </p>
  <hr /> 
  <!--Navigation Panel--> 
  <a name="tex2html3328" href="estimating-the-query-generation-probability-1.html"> <img width="37" height="24" align="BOTTOM" border="0" alt="next" src="http://nlp.stanford.edu/IR-book/html/icons/next.png" /></a> 
  <a name="tex2html3322" href="the-query-likelihood-model-1.html"> <img width="26" height="24" align="BOTTOM" border="0" alt="up" src="http://nlp.stanford.edu/IR-book/html/icons/up.png" /></a> 
  <a name="tex2html3316" href="the-query-likelihood-model-1.html"> <img width="63" height="24" align="BOTTOM" border="0" alt="previous" src="http://nlp.stanford.edu/IR-book/html/icons/prev.png" /></a> 
  <a name="tex2html3324" href="contents-1.html"> <img width="65" height="24" align="BOTTOM" border="0" alt="contents" src="http://nlp.stanford.edu/IR-book/html/icons/contents.png" /></a> 
  <a name="tex2html3326" href="index-1.html"> <img width="43" height="24" align="BOTTOM" border="0" alt="index" src="http://nlp.stanford.edu/IR-book/html/icons/index.png" /></a> 
  <br /> 
  <b> Next:</b> 
  <a name="tex2html3329" href="estimating-the-query-generation-probability-1.html">Estimating the query generation</a> 
  <b> Up:</b> 
  <a name="tex2html3323" href="the-query-likelihood-model-1.html">The query likelihood model</a> 
  <b> Previous:</b> 
  <a name="tex2html3317" href="the-query-likelihood-model-1.html">The query likelihood model</a> &nbsp; 
  <b> <a name="tex2html3325" href="contents-1.html">Contents</a></b> &nbsp; 
  <b> <a name="tex2html3327" href="index-1.html">Index</a></b> 
  <!--End of Navigation Panel--> 
  <address> &copy; 2008 Cambridge University Press<br />This is an automatically generated page. In case of formatting errors you may want to look at the <a href="http://informationretrieval.org">PDF edition</a> of the book.<br /> 2009-04-07 </address>   
 </body>
</html>