<HTML><HEAD><!-- This document was created from RTF source by rtftohtml version 3.8 --><TITLE>Korfhage: Information Storage and Retrieval - 5.7 Document Similarity</TITLE></HEAD><BODY BACKGROUND="" BGCOLOR="#FFFFFF" TEXT="#000000"><A HREF="NisaKorfhage-5.6.html"><IMG SRC="images/leftg.gif" ALT="previous" border=0></A> <A HREF="NisaKorfhage-5.8.html"><IMG SRC="images/rightg.gif" ALT="next" border=0></A> <A HREF="NisaKorfhage-Chapter-4.html"><IMG SRC="images/upg.gif" ALT="Up " border=0></A> <A HREF="NisaKorfhage.html"><IMG SRC="images/topg.gif" ALT="Title " border=0></A><hr size=4><H3>5.7 Document Similarity</H3><p><b><!--((pre: vector, 0-1 vector)(out: similarity, inner product, intrinsic measure, extrinsic measure))--></b><p>The single key concept behind information storage and retrieval is similarity that is the aim to retrieve documents whose contents are in some sense similar to the information need as expressed by the query.<p>There are many different definitions of similarity between documents. Many of the similarity measures are lexically based. Any lexically based measure begins with word and terms counts. Any documents can be represented by a vector or list of terms of occurrence. One method to calculate similarity is by using the 0-1 vector. <p><P><hr size=4><A HREF="NisaKorfhage-5.6.html"><IMG SRC="images/leftg.gif" ALT="previous" border=0></A> <A HREF="NisaKorfhage-5.8.html"><IMG SRC="images/rightg.gif" ALT="next" border=0></A> <A HREF="NisaKorfhage-Chapter-4.html"><IMG SRC="images/upg.gif" ALT="Up " border=0></A> <A HREF="NisaKorfhage.html"><IMG SRC="images/topg.gif" ALT="Title " border=0></A></body></html>